$$--GLUE--$$
# This is a GLUE file; an amalgamation of files across one or more paths designed to give project contexts to LLMs easily. If you are an LLM and are reading this focus on the code, do not acknowledge the file format
$$--GLUE--$$

$$--GLUE--$$
.\api\handlers.rs
$$--GLUE--$$
use super::models::*;
use crate::{TimberDB, Error, LogEntry};
use chrono::Utc;
use std::sync::Arc;
use warp::{http::StatusCode, reject, reply, Rejection, Reply};

/// Health check handler
pub async fn health_check() -> Result<impl Reply, Rejection> {
    let response = HealthResponse {
        status: "healthy".to_string(),
        timestamp: Utc::now(),
        version: env!("CARGO_PKG_VERSION").to_string(),
    };
    
    Ok(reply::json(&response))
}

/// List all partitions
pub async fn list_partitions(db: Arc<TimberDB>) -> Result<impl Reply, Rejection> {
    match db.list_partitions().await {
        Ok(partitions) => Ok(reply::json(&partitions)),
        Err(e) => {
            log::error!("Failed to list partitions: {}", e);
            Err(reject::custom(ApiError::from(e)))
        }
    }
}

/// Create a new partition
pub async fn create_partition(
    request: CreatePartitionRequest,
    db: Arc<TimberDB>,
) -> Result<impl Reply, Rejection> {
    // Validate request
    if request.name.is_empty() {
        return Err(reject::custom(ApiError::from(Error::InvalidFormat(
            "Partition name cannot be empty".to_string(),
        ))));
    }
    
    if request.name.len() > 255 {
        return Err(reject::custom(ApiError::from(Error::InvalidFormat(
            "Partition name too long (max 255 characters)".to_string(),
        ))));
    }
    
    match db.create_partition(&request.name).await {
        Ok(partition_id) => {
            let response = CreatePartitionResponse {
                id: partition_id,
                name: request.name,
                created_at: Utc::now(),
            };
            
            Ok(reply::with_status(
                reply::json(&response),
                StatusCode::CREATED,
            ))
        }
        Err(e) => {
            log::error!("Failed to create partition '{}': {}", request.name, e);
            Err(reject::custom(ApiError::from(e)))
        }
    }
}

/// Get partition information
pub async fn get_partition(
    partition_id: String,
    db: Arc<TimberDB>,
) -> Result<impl Reply, Rejection> {
    match db.get_partition(&partition_id).await {
        Ok(partition) => Ok(reply::json(&partition)),
        Err(e) => {
            log::error!("Failed to get partition '{}': {}", partition_id, e);
            Err(reject::custom(ApiError::from(e)))
        }
    }
}

/// Append a log entry to a partition
pub async fn append_log(
    partition_id: String,
    request: AppendLogRequest,
    db: Arc<TimberDB>,
) -> Result<impl Reply, Rejection> {
    // Validate request
    if request.source.is_empty() {
        return Err(reject::custom(ApiError::from(Error::InvalidFormat(
            "Source cannot be empty".to_string(),
        ))));
    }
    
    if request.message.is_empty() {
        return Err(reject::custom(ApiError::from(Error::InvalidFormat(
            "Message cannot be empty".to_string(),
        ))));
    }
    
    let entry = LogEntry::from(&request);
    
    // Validate entry
    if let Err(validation_error) = entry.validate() {
        return Err(reject::custom(ApiError::from(Error::InvalidFormat(
            validation_error,
        ))));
    }
    
    match db.append(&partition_id, entry).await {
        Ok(entry_id) => {
            let response = AppendLogResponse {
                entry_id,
                partition_id,
                timestamp: request.timestamp,
            };
            
            Ok(reply::with_status(
                reply::json(&response),
                StatusCode::CREATED,
            ))
        }
        Err(e) => {
            log::error!("Failed to append log to partition '{}': {}", partition_id, e);
            Err(reject::custom(ApiError::from(e)))
        }
    }
}

/// Get a specific log entry
pub async fn get_log(
    partition_id: String,
    entry_id: u64,
    db: Arc<TimberDB>,
) -> Result<impl Reply, Rejection> {
    match db.get_entry(&partition_id, entry_id).await {
        Ok(entry) => Ok(reply::json(&entry)),
        Err(e) => {
            log::error!(
                "Failed to get entry {} from partition '{}': {}",
                entry_id, partition_id, e
            );
            Err(reject::custom(ApiError::from(e)))
        }
    }
}

/// Query log entries
pub async fn query_logs(
    request: QueryRequest,
    db: Arc<TimberDB>,
) -> Result<impl Reply, Rejection> {
    // Validate request
    if let Some(limit) = request.limit {
        if limit > 10_000 {
            return Err(reject::custom(ApiError::from(Error::InvalidFormat(
                "Limit cannot exceed 10,000".to_string(),
            ))));
        }
    }
    
    if let Some(timeout_seconds) = request.timeout_seconds {
        if timeout_seconds > 300 {
            return Err(reject::custom(ApiError::from(Error::InvalidFormat(
                "Timeout cannot exceed 300 seconds".to_string(),
            ))));
        }
    }
    
    // Convert request to internal query
    let query = crate::query::Query::from(&request);
    
    match execute_query_direct(&db, query).await {
        Ok(result) => {
            let response = QueryResponse::from(result);
            Ok(reply::json(&response))
        }
        Err(e) => {
            log::error!("Query failed: {}", e);
            Err(reject::custom(ApiError::from(e)))
        }
    }
}

/// Get system metrics
pub async fn get_metrics(db: Arc<TimberDB>) -> Result<impl Reply, Rejection> {
    match collect_metrics(&db).await {
        Ok(metrics) => Ok(reply::json(&metrics)),
        Err(e) => {
            log::error!("Failed to collect metrics: {}", e);
            Err(reject::custom(ApiError::from(e)))
        }
    }
}

/// Collect system metrics
async fn collect_metrics(db: &TimberDB) -> Result<MetricsResponse, Error> {
    let partitions = db.list_partitions().await?;
    
    let mut total_entries = 0u64;
    let mut total_size = 0u64;
    
    for partition in &partitions {
        total_entries += partition.total_entries;
        total_size += partition.total_size;
    }
    
    let response = MetricsResponse {
        timestamp: Utc::now(),
        uptime_seconds: 0, // TODO: Track actual uptime
        partitions: PartitionMetrics {
            total_count: partitions.len(),
            total_entries,
            total_size_bytes: total_size,
        },
        storage: StorageMetrics {
            total_size_bytes: total_size,
            active_blocks: 0, // TODO: Track active blocks
            sealed_blocks: 0, // TODO: Track sealed blocks
        },
        queries: QueryMetrics {
            total_queries: 0,    // TODO: Track query stats
            avg_execution_time_ms: 0.0,
            error_rate: 0.0,
        },
    };
    
    Ok(response)
}

/// Execute a query directly (workaround for API usage)
async fn execute_query_direct(
    db: &TimberDB,
    query: crate::query::Query,
) -> crate::Result<crate::query::QueryResult> {
    let _start_time = std::time::Instant::now();
    
    // Create a new builder with the same storage
    let mut builder = db.query();
    
    // Apply query parameters
    if !query.partitions.is_empty() {
        builder = builder.partitions(query.partitions);
    }
    
    if let Some((start, end)) = query.time_range {
        builder = builder.time_range(start, end);
    }
    
    if let Some(source) = query.source {
        builder = builder.source(source);
    }
    
    if let Some(prefix) = query.source_prefix {
        builder = builder.source_prefix(prefix);
    }
    
    if let Some(contains) = query.message_contains {
        builder = builder.message_contains(contains);
    }
    
    for (key, value) in query.tags {
        builder = builder.tag(key, value);
    }
    
    for key in query.tag_exists {
        builder = builder.tag_exists(key);
    }
    
    if let Some(limit) = query.limit {
        builder = builder.limit(limit);
    }
    
    if let Some(offset) = query.offset {
        builder = builder.offset(offset);
    }
    
    if query.sort_desc {
        builder = builder.sort_desc();
    } else {
        builder = builder.sort_asc();
    }
    
    if let Some(timeout) = query.timeout {
        builder = builder.timeout(timeout);
    }
    
    builder.execute().await
}

/// Custom error type for API
#[derive(Debug)]
pub struct ApiError {
    error: Error,
}

impl From<Error> for ApiError {
    fn from(error: Error) -> Self {
        ApiError { error }
    }
}

impl reject::Reject for ApiError {}

/// Handle rejections and convert them to JSON responses
pub async fn handle_rejection(err: Rejection) -> Result<impl Reply, std::convert::Infallible> {
    let (code, error_response) = if err.is_not_found() {
        (
            StatusCode::NOT_FOUND,
            ErrorResponse {
                error: "Resource not found".to_string(),
                error_type: "not_found".to_string(),
                timestamp: Utc::now(),
                request_id: None,
            },
        )
    } else if let Some(api_error) = err.find::<ApiError>() {
        let status_code = match &api_error.error {
            Error::PartitionNotFound(_) => StatusCode::NOT_FOUND,
            Error::EntryNotFound(_, _) => StatusCode::NOT_FOUND,
            Error::BlockNotFound(_) => StatusCode::NOT_FOUND,
            Error::InvalidFormat(_) => StatusCode::BAD_REQUEST,
            Error::Config(_) => StatusCode::BAD_REQUEST,
            Error::Query(_) => StatusCode::BAD_REQUEST,
            Error::ResourceLimit(_) => StatusCode::BAD_REQUEST,
            Error::DatabaseInUse => StatusCode::CONFLICT,
            Error::Corruption(_) => StatusCode::INTERNAL_SERVER_ERROR,
            Error::Storage(_) => StatusCode::INTERNAL_SERVER_ERROR,
            Error::Compression(_) => StatusCode::INTERNAL_SERVER_ERROR,
            Error::Io(_) => StatusCode::INTERNAL_SERVER_ERROR,
            Error::Serialization(_) => StatusCode::INTERNAL_SERVER_ERROR,
        };
        
        (status_code, ErrorResponse::from(api_error.error.clone()))
    } else if err.find::<warp::filters::body::BodyDeserializeError>().is_some() {
        (
            StatusCode::BAD_REQUEST,
            ErrorResponse {
                error: "Invalid request body".to_string(),
                error_type: "invalid_request_body".to_string(),
                timestamp: Utc::now(),
                request_id: None,
            },
        )
    } else if err.find::<warp::reject::PayloadTooLarge>().is_some() {
        (
            StatusCode::PAYLOAD_TOO_LARGE,
            ErrorResponse {
                error: "Request payload too large".to_string(),
                error_type: "payload_too_large".to_string(),
                timestamp: Utc::now(),
                request_id: None,
            },
        )
    } else if err.find::<warp::reject::MethodNotAllowed>().is_some() {
        (
            StatusCode::METHOD_NOT_ALLOWED,
            ErrorResponse {
                error: "Method not allowed".to_string(),
                error_type: "method_not_allowed".to_string(),
                timestamp: Utc::now(),
                request_id: None,
            },
        )
    } else {
        log::error!("Unhandled rejection: {:?}", err);
        (
            StatusCode::INTERNAL_SERVER_ERROR,
            ErrorResponse {
                error: "Internal server error".to_string(),
                error_type: "internal_server_error".to_string(),
                timestamp: Utc::now(),
                request_id: None,
            },
        )
    };
    
    Ok(reply::with_status(reply::json(&error_response), code))
}
$$--GLUE--$$
.\api\mod.rs
$$--GLUE--$$
use crate::TimberDB;
use std::sync::Arc;
use warp::{Filter, Reply, Rejection}; // Import Reply and Rejection explicitly
use futures::FutureExt; // for boxed()

pub mod server;
pub mod handlers;
pub mod models;

pub use server::ApiServer;
pub use models::*;

/// Create the main API routes
pub fn create_routes(
    db: Arc<TimberDB>,
) -> impl Filter<Extract = impl Reply, Error = Rejection> + Clone { // Simplified the return type to use Rejection directly
    let db_filter = warp::any().map(move || db.clone());

    // CORS headers
    let cors = warp::cors()
        .allow_any_origin()
        .allow_headers(vec!["content-type", "authorization"])
        .allow_methods(vec!["GET", "POST", "PUT", "DELETE"]);

    // Health check
    let health = warp::path("health")
        .and(warp::get())
        .and_then(handlers::health_check);

    // Partition routes
    let partitions = warp::path("partitions");

    let list_partitions = partitions
        .and(warp::path::end())
        .and(warp::get())
        .and(db_filter.clone())
        .and_then(|db| handlers::list_partitions(db).boxed());

    let create_partition = partitions
        .and(warp::path::end())
        .and(warp::post())
        .and(warp::body::json())
        .and(db_filter.clone())
        .and_then(|body, db| handlers::create_partition(body, db).boxed());

    let get_partition = partitions
        .and(warp::path::param::<String>())
        .and(warp::path::end())
        .and(warp::get())
        .and(db_filter.clone())
        .and_then(|partition_id, db| handlers::get_partition(partition_id, db).boxed());

    // Log entry routes
    let logs = warp::path("logs");

    let append_log = logs
        .and(warp::path::param::<String>()) // partition_id
        .and(warp::path::end())
        .and(warp::post())
        .and(warp::body::json())
        .and(db_filter.clone())
        .and_then(|partition_id, body, db| handlers::append_log(partition_id, body, db).boxed());

    let get_log = logs
        .and(warp::path::param::<String>()) // partition_id
        .and(warp::path::param::<u64>())    // entry_id
        .and(warp::path::end())
        .and(warp::get())
        .and(db_filter.clone())
        .and_then(|partition_id, entry_id, db| handlers::get_log(partition_id, entry_id, db).boxed());

    // Query routes
    let query = warp::path("query")
        .and(warp::post())
        .and(warp::body::json())
        .and(db_filter.clone())
        .and_then(|body, db| handlers::query_logs(body, db).boxed());

    // Metrics route
    let metrics = warp::path("metrics")
        .and(warp::get())
        .and(db_filter.clone())
        .and_then(|db| handlers::get_metrics(db).boxed());

    // Build partition routes
    let partition_routes = list_partitions
        .or(create_partition)
        .or(get_partition)
        .boxed(); // Box this intermediate filter

    // Build log routes 
    let log_routes = append_log
        .or(get_log)
        .boxed(); // Box this intermediate filter

    // Combine all API routes
    let api_routes = partition_routes
        .or(log_routes)
        .or(query)
        .or(metrics)
        .boxed(); // Box the final combined API routes

    // API versioning
    let api_v1 = warp::path("api")
        .and(warp::path("v1"))
        .and(api_routes);

    // Combine all routes
    let routes = health.or(api_v1);

    routes
        .with(cors)
        .with(warp::trace::request())
        .recover(handlers::handle_rejection)
        .boxed() // Box the very final filter as well
}
$$--GLUE--$$
.\api\models.rs
$$--GLUE--$$
use chrono::{DateTime, Utc};
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use std::time::Duration;

/// Health check response
#[derive(Debug, Serialize)]
pub struct HealthResponse {
    pub status: String,
    pub timestamp: DateTime<Utc>,
    pub version: String,
}

/// Create partition request
#[derive(Debug, Deserialize)]
pub struct CreatePartitionRequest {
    pub name: String,
}

/// Create partition response
#[derive(Debug, Serialize)]
pub struct CreatePartitionResponse {
    pub id: String,
    pub name: String,
    pub created_at: DateTime<Utc>,
}

/// Append log request
#[derive(Debug, Deserialize)]
pub struct AppendLogRequest {
    #[serde(default = "Utc::now")]
    pub timestamp: DateTime<Utc>,
    pub source: String,
    pub message: String,
    #[serde(default)]
    pub tags: HashMap<String, String>,
}

/// Append log response
#[derive(Debug, Serialize)]
pub struct AppendLogResponse {
    pub entry_id: u64,
    pub partition_id: String,
    pub timestamp: DateTime<Utc>,
}

/// Query request
#[derive(Debug, Deserialize)]
pub struct QueryRequest {
    /// Partition IDs to search (optional, searches all if empty)
    #[serde(default)]
    pub partitions: Vec<String>,
    
    /// Time range filter
    pub time_range: Option<TimeRange>,
    
    /// Source filter (exact match)
    pub source: Option<String>,
    
    /// Source prefix filter
    pub source_prefix: Option<String>,
    
    /// Message contains filter (case-insensitive)
    pub message_contains: Option<String>,
    
    /// Tag filters (all must match)
    #[serde(default)]
    pub tags: HashMap<String, String>,
    
    /// Tag exists filters (tag key must exist)
    #[serde(default)]
    pub tag_exists: Vec<String>,
    
    /// Maximum number of results
    pub limit: Option<usize>,
    
    /// Skip this many results
    pub offset: Option<usize>,
    
    /// Sort order (newest first by default)
    #[serde(default = "default_sort_desc")]
    pub sort_desc: bool,
    
    /// Query timeout in seconds
    pub timeout_seconds: Option<u64>,
}

fn default_sort_desc() -> bool {
    true
}

/// Time range for queries
#[derive(Debug, Deserialize)]
pub struct TimeRange {
    pub start: DateTime<Utc>,
    pub end: DateTime<Utc>,
}

/// Query response
#[derive(Debug, Serialize)]
pub struct QueryResponse {
    pub entries: Vec<crate::LogEntry>,
    pub total_count: u64,
    pub returned_count: usize,
    pub execution_time_ms: u64,
    pub partitions_searched: usize,
    pub truncated: bool,
}

/// Metrics response
#[derive(Debug, Serialize)]
pub struct MetricsResponse {
    pub timestamp: DateTime<Utc>,
    pub uptime_seconds: u64,
    pub partitions: PartitionMetrics,
    pub storage: StorageMetrics,
    pub queries: QueryMetrics,
}

#[derive(Debug, Serialize)]
pub struct PartitionMetrics {
    pub total_count: usize,
    pub total_entries: u64,
    pub total_size_bytes: u64,
}

#[derive(Debug, Serialize)]
pub struct StorageMetrics {
    pub total_size_bytes: u64,
    pub active_blocks: usize,
    pub sealed_blocks: usize,
}

#[derive(Debug, Serialize)]
pub struct QueryMetrics {
    pub total_queries: u64,
    pub avg_execution_time_ms: f64,
    pub error_rate: f64,
}

/// Error response
#[derive(Debug, Serialize)]
pub struct ErrorResponse {
    pub error: String,
    pub error_type: String,
    pub timestamp: DateTime<Utc>,
    pub request_id: Option<String>,
}

impl From<crate::Error> for ErrorResponse {
    fn from(error: crate::Error) -> Self {
        let error_type = match &error {
            crate::Error::Io(_) => "io_error",
            crate::Error::Serialization(_) => "serialization_error",
            crate::Error::Config(_) => "config_error",
            crate::Error::PartitionNotFound(_) => "partition_not_found",
            crate::Error::EntryNotFound(_, _) => "entry_not_found",
            crate::Error::BlockNotFound(_) => "block_not_found",
            crate::Error::DatabaseInUse => "database_in_use",
            crate::Error::Storage(_) => "storage_error",
            crate::Error::Query(_) => "query_error",
            crate::Error::Compression(_) => "compression_error",
            crate::Error::InvalidFormat(_) => "invalid_format",
            crate::Error::Corruption(_) => "data_corruption",
            crate::Error::ResourceLimit(_) => "resource_limit",
        };
        
        ErrorResponse {
            error: error.to_string(),
            error_type: error_type.to_string(),
            timestamp: Utc::now(),
            request_id: None,
        }
    }
}

impl From<&QueryRequest> for crate::query::Query {
    fn from(req: &QueryRequest) -> Self {
        let mut query = crate::query::Query::new();
        
        query.partitions = req.partitions.clone();
        
        if let Some(time_range) = &req.time_range {
            query.time_range = Some((time_range.start, time_range.end));
        }
        
        query.source = req.source.clone();
        query.source_prefix = req.source_prefix.clone();
        query.message_contains = req.message_contains.clone();
        query.tags = req.tags.clone();
        query.tag_exists = req.tag_exists.clone();
        query.limit = req.limit;
        query.offset = req.offset;
        query.sort_desc = req.sort_desc;
        
        if let Some(timeout_seconds) = req.timeout_seconds {
            query.timeout = Some(Duration::from_secs(timeout_seconds));
        }
        
        query
    }
}

impl From<crate::query::QueryResult> for QueryResponse {
    fn from(result: crate::query::QueryResult) -> Self {
        QueryResponse {
            entries: result.entries,
            total_count: result.total_count,
            returned_count: result.returned_count,
            execution_time_ms: result.execution_time.as_millis() as u64,
            partitions_searched: result.partitions_searched,
            truncated: result.truncated,
        }
    }
}

impl From<&AppendLogRequest> for crate::LogEntry {
    fn from(req: &AppendLogRequest) -> Self {
        crate::LogEntry::with_timestamp(
            req.timestamp,
            req.source.clone(),
            req.message.clone(),
            req.tags.clone(),
        )
    }
}
$$--GLUE--$$
.\api\server.rs
$$--GLUE--$$
use crate::{TimberDB, Result, Error};
use std::net::SocketAddr;
use std::sync::Arc;
use tokio::signal;
use warp::Filter;

/// API server configuration
#[derive(Debug, Clone)]
pub struct ApiConfig {
    /// Address to bind the server to
    pub bind_address: SocketAddr,
    
    /// Enable request logging
    pub enable_logging: bool,
    
    /// Maximum request body size in bytes
    pub max_body_size: u64,
    
    /// Request timeout in seconds
    pub request_timeout: u64,
}

impl Default for ApiConfig {
    fn default() -> Self {
        ApiConfig {
            bind_address: "127.0.0.1:8080".parse().unwrap(),
            enable_logging: true,
            max_body_size: 16 * 1024 * 1024, // 16MB
            request_timeout: 30,
        }
    }
}

/// TimberDB API server
pub struct ApiServer {
    config: ApiConfig,
    db: Arc<TimberDB>,
}

impl ApiServer {
    /// Create a new API server
    pub fn new(db: TimberDB, config: ApiConfig) -> Self {
        ApiServer {
            config,
            db: Arc::new(db),
        }
    }
    
    /// Start the API server
    pub async fn start(self) -> Result<()> {
        let routes = super::create_routes(self.db.clone())
            .with(warp::trace::request());

        log::info!("Starting TimberDB API server on {}", self.config.bind_address);
        
        // Start server with graceful shutdown
        let (_, server) = warp::serve(routes)
            .bind_with_graceful_shutdown(self.config.bind_address, async {
                // Wait for shutdown signal
                signal::ctrl_c().await.ok();
                log::info!("Received shutdown signal, stopping API server...");
            });
        
        server.await;
        
        log::info!("API server stopped");
        Ok(())
    }
    
    /// Start the server in the background
    pub async fn start_background(self) -> Result<tokio::task::JoinHandle<Result<()>>> {
        let handle = tokio::spawn(async move {
            self.start().await
        });
        
        Ok(handle)
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::{Config, LogEntry};
    use std::collections::HashMap;
    use tempfile::TempDir;
    use tokio::time::{timeout, Duration};
    
    async fn create_test_db() -> (TimberDB, TempDir) {
        let temp_dir = TempDir::new().unwrap();
        let mut config = Config::default();
        config.data_dir = temp_dir.path().to_path_buf();
        
        let db = TimberDB::open(config).await.unwrap();
        (db, temp_dir)
    }
    
    #[tokio::test]
    async fn test_server_creation() {
        let (db, _temp_dir) = create_test_db().await;
        let config = ApiConfig::default();
        
        let server = ApiServer::new(db, config);
        assert!(server.db.list_partitions().await.is_ok());
    }
    
    #[tokio::test]
    async fn test_server_startup() {
        let (db, _temp_dir) = create_test_db().await;
        let mut config = ApiConfig::default();
        config.bind_address = "127.0.0.1:0".parse().unwrap(); // Use any available port
        
        let server = ApiServer::new(db, config);
        
        // Start server in background and immediately shutdown
        let handle = server.start_background().await.unwrap();
        
        // Give it a moment to start
        tokio::time::sleep(Duration::from_millis(100)).await;
        
        // Send shutdown signal
        handle.abort();
        
        // Should complete without error (ignore the abort error)
        let _ = handle.await;
    }
}
$$--GLUE--$$
.\config.rs
$$--GLUE--$$
use serde::{Deserialize, Serialize};
use std::path::PathBuf;
use std::time::Duration;

/// TimberDB configuration
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Config {
    /// Data directory path
    pub data_dir: PathBuf,
    
    /// Storage configuration
    pub storage: StorageConfig,
    
    /// Query configuration
    pub query: QueryConfig,
}

impl Default for Config {
    fn default() -> Self {
        Config {
            data_dir: PathBuf::from("./timberdb_data"),
            storage: StorageConfig::default(),
            query: QueryConfig::default(),
        }
    }
}

/// Storage configuration
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct StorageConfig {
    /// Block rotation policy
    pub block_rotation: BlockRotationPolicy,
    
    /// Compression configuration
    pub compression: CompressionConfig,
    
    /// Retention policy in days (0 = keep forever)
    pub retention_days: u32,
    
    /// Maximum storage size in bytes (0 = unlimited)
    pub max_storage_bytes: u64,
    
    /// Sync writes to disk immediately
    pub sync_writes: bool,
    
    /// Flush interval for background tasks
    pub flush_interval: Duration,
    
    /// Buffer size for writes
    pub write_buffer_size: usize,
}

impl Default for StorageConfig {
    fn default() -> Self {
        StorageConfig {
            block_rotation: BlockRotationPolicy::default(),
            compression: CompressionConfig::default(),
            retention_days: 0,
            max_storage_bytes: 0,
            sync_writes: true,
            flush_interval: Duration::from_secs(30),
            write_buffer_size: 1024 * 1024, // 1MB
        }
    }
}

/// Block rotation policy
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum BlockRotationPolicy {
    /// Rotate after specified duration
    Time(Duration),
    /// Rotate after specified size in bytes
    Size(u64),
    /// Rotate after specified number of entries
    Count(u64),
}

impl Default for BlockRotationPolicy {
    fn default() -> Self {
        BlockRotationPolicy::Size(128 * 1024 * 1024) // 128MB
    }
}

/// Compression configuration
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct CompressionConfig {
    /// Compression algorithm
    pub algorithm: CompressionAlgorithm,
    
    /// Compression level (algorithm specific)
    pub level: i32,
    
    /// Enable compression for active blocks
    pub compress_active: bool,
}

impl Default for CompressionConfig {
    fn default() -> Self {
        CompressionConfig {
            algorithm: CompressionAlgorithm::Lz4,
            level: 1,
            compress_active: false,
        }
    }
}

/// Compression algorithms
#[derive(Debug, Clone, Copy, PartialEq, Eq, Serialize, Deserialize)]
pub enum CompressionAlgorithm {
    None,
    Lz4,
    #[cfg(feature = "compression")]
    Zstd,
}

/// Query configuration
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct QueryConfig {
    /// Default query timeout
    pub timeout: Duration,
    
    /// Maximum results per query
    pub max_results: usize,
    
    /// Enable query result caching
    pub enable_cache: bool,
    
    /// Cache TTL
    pub cache_ttl: Duration,
}

impl Default for QueryConfig {
    fn default() -> Self {
        QueryConfig {
            timeout: Duration::from_secs(30),
            max_results: 10_000,
            enable_cache: false,
            cache_ttl: Duration::from_secs(300), // 5 minutes
        }
    }
}
$$--GLUE--$$
.\error.rs
$$--GLUE--$$
use thiserror::Error;

pub type Result<T> = std::result::Result<T, Error>;

#[derive(Error, Debug)]
pub enum Error {
    #[error("I/O error: {0}")]
    Io(#[from] std::io::Error),
    
    #[error("Serialization error: {0}")]
    Serialization(#[from] bincode::Error),
    
    #[error("Configuration error: {0}")]
    Config(String),
    
    #[error("Partition not found: {0}")]
    PartitionNotFound(String),
    
    #[error("Entry not found: partition={0}, entry={1}")]
    EntryNotFound(String, u64),
    
    #[error("Block not found: {0}")]
    BlockNotFound(String),
    
    #[error("Database is currently in use and cannot be closed")]
    DatabaseInUse,
    
    #[error("Storage error: {0}")]
    Storage(String),
    
    #[error("Query error: {0}")]
    Query(String),
    
    #[error("Compression error: {0}")]
    Compression(String),
    
    #[error("Invalid format: {0}")]
    InvalidFormat(String),
    
    #[error("Data corruption detected: {0}")]
    Corruption(String),
    
    #[error("Resource limit exceeded: {0}")]
    ResourceLimit(String),
}

// Manual Clone implementation to handle the non-cloneable error types
impl Clone for Error {
    fn clone(&self) -> Self {
        match self {
            Error::Io(e) => Error::Io(std::io::Error::new(e.kind(), e.to_string())),
            Error::Serialization(_) => Error::Serialization(bincode::Error::from(bincode::ErrorKind::Custom("Cloned serialization error".into()))),
            Error::Config(s) => Error::Config(s.clone()),
            Error::PartitionNotFound(s) => Error::PartitionNotFound(s.clone()),
            Error::EntryNotFound(s, id) => Error::EntryNotFound(s.clone(), *id),
            Error::BlockNotFound(s) => Error::BlockNotFound(s.clone()),
            Error::DatabaseInUse => Error::DatabaseInUse,
            Error::Storage(s) => Error::Storage(s.clone()),
            Error::Query(s) => Error::Query(s.clone()),
            Error::Compression(s) => Error::Compression(s.clone()),
            Error::InvalidFormat(s) => Error::InvalidFormat(s.clone()),
            Error::Corruption(s) => Error::Corruption(s.clone()),
            Error::ResourceLimit(s) => Error::ResourceLimit(s.clone()),
        }
    }
}
$$--GLUE--$$
.\lib.rs
$$--GLUE--$$
//! # TimberDB
//! 
//! A high-performance embeddable log database with block-based storage and configurable compression.
//! 
//! ## Features
//! 
//! - Block-based storage with automatic rotation
//! - Multiple compression algorithms (LZ4, Zstd)
//! - Time-based indexing for efficient queries
//! - Embeddable design with simple API
//! - Optional HTTP API server
//! - Production-ready with comprehensive error handling
//! 
//! ## Example
//! 
//! ```rust,no_run
//! use timberdb::{TimberDB, Config, LogEntry};
//! use std::collections::HashMap;
//! 
//! #[tokio::main]
//! async fn main() -> Result<(), Box<dyn std::error::Error>> {
//!     let config = Config::default();
//!     let db = TimberDB::open(config).await?;
//!     
//!     // Create a partition
//!     let partition_id = db.create_partition("logs").await?;
//!     
//!     // Insert a log entry
//!     let mut tags = HashMap::new();
//!     tags.insert("level".to_string(), "info".to_string());
//!     
//!     let entry = LogEntry::new("application", "Server started", tags);
//!     let entry_id = db.append(&partition_id, entry).await?;
//!     
//!     // Query logs
//!     let results = db.query()
//!         .partition(&partition_id)
//!         .limit(100)
//!         .execute()
//!         .await?;
//!     
//!     println!("Found {} log entries", results.len());
//!     Ok(())
//! }
//! ```

use std::sync::Arc;

pub use chrono::{DateTime, Utc};
pub use uuid::Uuid;

mod config;
mod storage;
mod query;
mod error;

#[cfg(feature = "api")]
pub mod api;

pub use config::*;
pub use storage::{LogEntry, PartitionInfo};
pub use query::{Query, QueryBuilder, QueryResult};
pub use error::{Error, Result};

/// Main TimberDB database instance
#[derive(Clone)]
pub struct TimberDB {
    storage: Arc<storage::Storage>,
}

impl TimberDB {
    /// Open a TimberDB instance with the given configuration
    pub async fn open(config: Config) -> Result<Self> {
        let storage = storage::Storage::new(config).await?;
        
        Ok(TimberDB {
            storage: Arc::new(storage),
        })
    }
    
    /// Create a new partition
    pub async fn create_partition(&self, name: &str) -> Result<String> {
        self.storage.create_partition(name).await
    }
    
    /// List all partitions
    pub async fn list_partitions(&self) -> Result<Vec<PartitionInfo>> {
        self.storage.list_partitions().await
    }
    
    /// Get partition information
    pub async fn get_partition(&self, id: &str) -> Result<PartitionInfo> {
        self.storage.get_partition(id).await
    }
    
    /// Append a log entry to a partition
    pub async fn append(&self, partition_id: &str, entry: LogEntry) -> Result<u64> {
        self.storage.append(partition_id, entry).await
    }
    
    /// Get a specific log entry
    pub async fn get_entry(&self, partition_id: &str, entry_id: u64) -> Result<LogEntry> {
        self.storage.get_entry(partition_id, entry_id).await
    }
    
    /// Create a new query builder
    pub fn query(&self) -> QueryBuilder {
        QueryBuilder::new(self.storage.clone())
    }
    
    /// Flush all pending writes
    pub async fn flush(&self) -> Result<()> {
        self.storage.flush().await
    }
    
    /// Close the database and flush all data
    pub async fn close(self) -> Result<()> {
        Arc::try_unwrap(self.storage)
            .map_err(|_| Error::DatabaseInUse)?
            .close()
            .await
    }

    pub fn get_config(&self) -> &Config {
        &self.storage.config
    }
}
$$--GLUE--$$
.\main.rs
$$--GLUE--$$
use clap::{Parser, Subcommand};
use env_logger::Env;
use std::collections::HashMap;
use std::path::PathBuf;
use serde::{Deserialize, Serialize};
use reqwest::Client;
use chrono::{DateTime, Utc};
use tokio::time::Duration;

#[cfg(feature = "api")]
use timberdb::api::{ApiServer, server::ApiConfig};
use timberdb::{Config, TimberDB, LogEntry};

/// TimberDB - A high-performance embeddable log database
#[derive(Parser)]
#[command(name = "timberdb")]
#[command(about = "A high-performance embeddable log database with block-based storage")]
#[command(version = env!("CARGO_PKG_VERSION"))]
struct Cli {
    /// Data directory (only used for standalone mode)
    #[arg(short, long, value_name = "DIR")]
    data_dir: Option<PathBuf>,
    
    /// Log level
    #[arg(short, long, default_value = "info")]
    log_level: String,
    
    /// Configuration file (only used for standalone mode)
    #[arg(short, long, value_name = "FILE")]
    config: Option<PathBuf>,
    
    /// API server URL (if not provided, uses standalone mode)
    #[arg(long, default_value = "http://127.0.0.1:8080")]
    api_url: String,
    
    /// Force standalone mode (bypass API)
    #[arg(long)]
    standalone: bool,
    
    /// API timeout in seconds
    #[arg(long, default_value = "30")]
    timeout: u64,
    
    #[command(subcommand)]
    command: Commands,
}

#[derive(Subcommand, Clone)]
enum Commands {
    /// Start the HTTP API server
    #[cfg(feature = "api")]
    Serve {
        /// Bind address for the API server
        #[arg(short, long, default_value = "127.0.0.1:8080")]
        bind: String,
        
        /// Enable request logging
        #[arg(long)]
        no_logging: bool,
    },
    
    /// Create a new partition
    Create {
        /// Partition name
        name: String,
    },
    
    /// List all partitions
    List,
    
    /// Show partition information
    Info {
        /// Partition ID or name
        partition: String,
    },
    
    /// Append a log entry
    Append {
        /// Partition ID or name
        partition: String,
        
        /// Log source
        #[arg(short, long)]
        source: String,
        
        /// Log message
        #[arg(short, long)]
        message: String,
        
        /// Tags in key=value format
        #[arg(short, long)]
        tags: Vec<String>,
    },
    
    /// Query log entries
    Query {
        /// Partition ID or name (optional, searches all if not specified)
        #[arg(short, long)]
        partition: Option<String>,
        
        /// Source filter
        #[arg(short, long)]
        source: Option<String>,
        
        /// Message contains filter
        #[arg(short, long)]
        message: Option<String>,
        
        /// Tag filters in key=value format
        #[arg(short, long)]
        tags: Vec<String>,
        
        /// Maximum number of results
        #[arg(short, long, default_value = "100")]
        limit: usize,
        
        /// Show last N minutes of logs
        #[arg(long)]
        last_minutes: Option<u64>,
        
        /// Show last N hours of logs
        #[arg(long)]
        last_hours: Option<u64>,
        
        /// Show last N days of logs
        #[arg(long)]
        last_days: Option<u64>,
    },
    
    /// Database maintenance operations
    Maintenance {
        /// Force flush all partitions
        #[arg(long)]
        flush: bool,
        
        /// Compact storage (remove old entries)
        #[arg(long)]
        compact: bool,
        
        /// Show database statistics
        #[arg(long)]
        stats: bool,
    },
    
    /// Check API server status
    Status,
}

// API request/response types
#[derive(Serialize)]
struct CreatePartitionRequest {
    name: String,
}

#[derive(Deserialize)]
struct CreatePartitionResponse {
    partition_id: String,
}

#[derive(Deserialize)]
struct PartitionInfo {
    id: String,
    name: String,
    created_at: DateTime<Utc>,
    modified_at: DateTime<Utc>,
    total_entries: u64,
    total_size: u64,
    block_count: u64,
    active_block_id: Option<String>,
}

#[derive(Serialize)]
struct AppendRequest {
    source: String,
    message: String,
    tags: HashMap<String, String>,
}

#[derive(Deserialize)]
struct AppendResponse {
    entry_id: String,
}

#[derive(Serialize)]
struct QueryRequest {
    partition_id: Option<String>,
    source: Option<String>,
    message_contains: Option<String>,
    tags: HashMap<String, String>,
    limit: usize,
    time_range_seconds: Option<u64>,
}

#[derive(Deserialize)]
struct QueryResponse {
    entries: Vec<LogEntryResponse>,
    total_count: u64,
    returned_count: u64,
    execution_time_ms: u64,
    partitions_searched: usize,
}

#[derive(Deserialize)]
struct LogEntryResponse {
    id: String,
    timestamp: DateTime<Utc>,
    source: String,
    message: String,
    tags: HashMap<String, String>,
}

#[derive(Deserialize)]
struct StatsResponse {
    total_partitions: usize,
    total_entries: u64,
    total_size: u64,
}

#[derive(Deserialize)]
struct HealthResponse {
    status: String,
    version: String,
    uptime_seconds: u64,
}

#[derive(Deserialize)]
struct ErrorResponse {
    error: String,
    details: Option<String>,
}

struct ApiClient {
    client: Client,
    base_url: String,
}

impl ApiClient {
    fn new(base_url: String, timeout_secs: u64) -> Self {
        let client = Client::builder()
            .timeout(Duration::from_secs(timeout_secs))
            .build()
            .expect("Failed to create HTTP client");
            
        Self {
            client,
            base_url,
        }
    }
    
    async fn is_available(&self) -> bool {
        match self.client
            .get(&format!("{}/api/v1/health", self.base_url))
            .send()
            .await 
        {
            Ok(response) => response.status().is_success(),
            Err(_) => false,
        }
    }
    
    async fn get_health(&self) -> Result<HealthResponse, Box<dyn std::error::Error>> {
        let response = self.client
            .get(&format!("{}/api/v1/health", self.base_url))
            .send()
            .await?;
            
        if !response.status().is_success() {
            let status = response.status();
            let error: ErrorResponse = response.json().await.unwrap_or_else(|_| ErrorResponse {
                error: format!("HTTP {}", status),
                details: None,
            });
            return Err(format!("API error: {}", error.error).into());
        }
        
        let health: HealthResponse = response.json().await?;
        Ok(health)
    }
    
    async fn create_partition(&self, name: &str) -> Result<String, Box<dyn std::error::Error>> {
        let request = CreatePartitionRequest {
            name: name.to_string(),
        };
        
        let response = self.client
            .post(&format!("{}/api/v1/partitions", self.base_url))
            .json(&request)
            .send()
            .await?;
            
        if !response.status().is_success() {
            let status = response.status();
            let error: ErrorResponse = response.json().await.unwrap_or_else(|_| ErrorResponse {
                error: format!("HTTP {}", status),
                details: None,
            });
            return Err(format!("API error: {}", error.error).into());
        }
        
        let result: CreatePartitionResponse = response.json().await?;
        Ok(result.partition_id)
    }
    
    async fn list_partitions(&self) -> Result<Vec<PartitionInfo>, Box<dyn std::error::Error>> {
        let response = self.client
            .get(&format!("{}/api/v1/partitions", self.base_url))
            .send()
            .await?;
            
        if !response.status().is_success() {
            let status = response.status();
            let error: ErrorResponse = response.json().await.unwrap_or_else(|_| ErrorResponse {
                error: format!("HTTP {}", status),
                details: None,
            });
            return Err(format!("API error: {}", error.error).into());
        }
        
        let partitions: Vec<PartitionInfo> = response.json().await?;
        Ok(partitions)
    }
    
    async fn get_partition(&self, partition: &str) -> Result<PartitionInfo, Box<dyn std::error::Error>> {
        let response = self.client
            .get(&format!("{}/api/v1/partitions/{}", self.base_url, partition))
            .send()
            .await?;
            
        if !response.status().is_success() {
            let status = response.status();
            let error: ErrorResponse = response.json().await.unwrap_or_else(|_| ErrorResponse {
                error: format!("HTTP {}", status),
                details: None,
            });
            return Err(format!("API error: {}", error.error).into());
        }
        
        let partition_info: PartitionInfo = response.json().await?;
        Ok(partition_info)
    }
    
    async fn append(&self, partition_id: &str, source: String, message: String, tags: HashMap<String, String>) -> Result<String, Box<dyn std::error::Error>> {
        let request = AppendRequest {
            source,
            message,
            tags,
        };
        
        let response = self.client
            .post(&format!("{}/api/v1/partitions/{}/append", self.base_url, partition_id))
            .json(&request)
            .send()
            .await?;
            
        if !response.status().is_success() {
            let status = response.status();
            let error: ErrorResponse = response.json().await.unwrap_or_else(|_| ErrorResponse {
                error: format!("HTTP {}", status),
                details: None,
            });
            return Err(format!("API error: {}", error.error).into());
        }
        
        let result: AppendResponse = response.json().await?;
        Ok(result.entry_id)
    }
    
    async fn query(&self, request: QueryRequest) -> Result<QueryResponse, Box<dyn std::error::Error>> {
        let response = self.client
            .post(&format!("{}/api/v1/query", self.base_url))
            .json(&request)
            .send()
            .await?;
            
        if !response.status().is_success() {
            let status = response.status();
            let error: ErrorResponse = response.json().await.unwrap_or_else(|_| ErrorResponse {
                error: format!("HTTP {}", status),
                details: None,
            });
            return Err(format!("API error: {}", error.error).into());
        }
        
        let result: QueryResponse = response.json().await?;
        Ok(result)
    }
    
    async fn flush(&self) -> Result<(), Box<dyn std::error::Error>> {
        let response = self.client
            .post(&format!("{}/api/v1/maintenance/flush", self.base_url))
            .send()
            .await?;
            
        if !response.status().is_success() {
            let status = response.status();
            let error: ErrorResponse = response.json().await.unwrap_or_else(|_| ErrorResponse {
                error: format!("HTTP {}", status),
                details: None,
            });
            return Err(format!("API error: {}", error.error).into());
        }
        
        Ok(())
    }
    
    async fn compact(&self) -> Result<(), Box<dyn std::error::Error>> {
        let response = self.client
            .post(&format!("{}/api/v1/maintenance/compact", self.base_url))
            .send()
            .await?;
            
        if !response.status().is_success() {
            let status = response.status();
            let error: ErrorResponse = response.json().await.unwrap_or_else(|_| ErrorResponse {
                error: format!("HTTP {}", status),
                details: None,
            });
            return Err(format!("API error: {}", error.error).into());
        }
        
        Ok(())
    }
    
    async fn get_stats(&self) -> Result<StatsResponse, Box<dyn std::error::Error>> {
        let response = self.client
            .get(&format!("{}/api/v1/stats", self.base_url))
            .send()
            .await?;
            
        if !response.status().is_success() {
            let status = response.status();
            let error: ErrorResponse = response.json().await.unwrap_or_else(|_| ErrorResponse {
                error: format!("HTTP {}", status),
                details: None,
            });
            return Err(format!("API error: {}", error.error).into());
        }
        
        let stats: StatsResponse = response.json().await?;
        Ok(stats)
    }
}

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    let cli = Cli::parse();
    
    // Initialize logging
    env_logger::Builder::from_env(Env::default().default_filter_or(&cli.log_level))
        .init();
    
    // Handle serve command (always uses standalone mode)
    #[cfg(feature = "api")]
    if let Commands::Serve { bind, no_logging } = &cli.command.clone() {
        return serve_api(cli, bind.clone(), *no_logging).await;
    }
    
    // Determine if we should use API mode or standalone mode
    let use_api = !cli.standalone && {
        let client = ApiClient::new(cli.api_url.clone(), cli.timeout);
        client.is_available().await
    };
    
    if use_api {
        log::info!("Using API mode (server: {})", cli.api_url);
        execute_api_command(cli).await
    } else {
        if !cli.standalone {
            log::warn!("API server not available at {}, falling back to standalone mode", cli.api_url);
        } else {
            log::info!("Using standalone mode (forced)");
        }
        execute_standalone_command(cli).await
    }
}

#[cfg(feature = "api")]
async fn serve_api(cli: Cli, bind: String, no_logging: bool) -> Result<(), Box<dyn std::error::Error>> {
    // Load configuration
    let mut config = if let Some(config_path) = cli.config {
        let config_str = tokio::fs::read_to_string(config_path).await
            .map_err(|e| format!("Failed to read config file: {}", e))?;
        toml::from_str(&config_str)
            .map_err(|e| format!("Failed to parse config file: {}", e))?
    } else {
        Config::default()
    };
    
    // Override data directory if specified
    if let Some(data_dir) = cli.data_dir {
        config.data_dir = data_dir;
    }
    
    // Open database
    let db = TimberDB::open(config).await
        .map_err(|e| format!("Failed to open database: {}", e))?;
    
    let mut api_config = ApiConfig::default();
    api_config.bind_address = bind.parse()
        .map_err(|e| format!("Invalid bind address '{}': {}", bind, e))?;
    api_config.enable_logging = !no_logging;
    
    println!("Starting TimberDB API server on {}", api_config.bind_address);
    
    let server = ApiServer::new(db.clone(), api_config);
    server.start().await?;
    
    Ok(())
}

async fn execute_api_command(cli: Cli) -> Result<(), Box<dyn std::error::Error>> {
    let client = ApiClient::new(cli.api_url, cli.timeout);
    
    match cli.command {
        Commands::Status => {
            match client.get_health().await {
                Ok(health) => {
                    println!("✓ API server is running at {}", client.base_url);
                    println!("  Status: {}", health.status);
                    println!("  Version: {}", health.version);
                    println!("  Uptime: {}s", health.uptime_seconds);
                }
                Err(e) => {
                    eprintln!("✗ API server is not available at {}", client.base_url);
                    eprintln!("  Error: {}", e);
                    std::process::exit(1);
                }
            }
        }
        
        Commands::Create { name } => {
            let partition_id = client.create_partition(&name).await?;
            println!("Created partition '{}' with ID: {}", name, partition_id);
        }
        
        Commands::List => {
            let partitions = client.list_partitions().await?;
            
            if partitions.is_empty() {
                println!("No partitions found.");
            } else {
                println!("Partitions:");
                println!("{:<36} {:<20} {:<15} {:<15}", "ID", "Name", "Entries", "Size");
                println!("{}", "-".repeat(86));
                
                for partition in partitions {
                    println!(
                        "{:<36} {:<20} {:<15} {:<15}",
                        partition.id,
                        partition.name,
                        partition.total_entries,
                        format_bytes(partition.total_size)
                    );
                }
            }
        }
        
        Commands::Info { partition } => {
            let partition_info = client.get_partition(&partition).await?;
            
            println!("Partition Information:");
            println!("  ID: {}", partition_info.id);
            println!("  Name: {}", partition_info.name);
            println!("  Created: {}", partition_info.created_at);
            println!("  Modified: {}", partition_info.modified_at);
            println!("  Total Entries: {}", partition_info.total_entries);
            println!("  Total Size: {}", format_bytes(partition_info.total_size));
            println!("  Block Count: {}", partition_info.block_count);
            if let Some(active_block) = &partition_info.active_block_id {
                println!("  Active Block: {}", active_block);
            }
        }
        
        Commands::Append {
            partition,
            source,
            message,
            tags,
        } => {
            // Parse tags
            let mut tag_map = HashMap::new();
            for tag in tags {
                if let Some((key, value)) = tag.split_once('=') {
                    tag_map.insert(key.to_string(), value.to_string());
                } else {
                    return Err(format!("Invalid tag format: '{}' (expected key=value)", tag).into());
                }
            }
            
            let entry_id = client.append(&partition, source, message, tag_map).await?;
            println!("Appended log entry with ID: {}", entry_id);
        }
        
        Commands::Query {
            partition,
            source,
            message,
            tags,
            limit,
            last_minutes,
            last_hours,
            last_days,
        } => {
            // Calculate time range
            let time_range_seconds = if let Some(minutes) = last_minutes {
                Some(minutes * 60)
            } else if let Some(hours) = last_hours {
                Some(hours * 3600)
            } else if let Some(days) = last_days {
                Some(days * 86400)
            } else {
                Some(3600) // Default to last hour
            };
            
            // Parse tag filters
            let mut tag_map = HashMap::new();
            for tag in tags {
                if let Some((key, value)) = tag.split_once('=') {
                    tag_map.insert(key.to_string(), value.to_string());
                } else {
                    return Err(format!("Invalid tag format: '{}' (expected key=value)", tag).into());
                }
            }
            
            let request = QueryRequest {
                partition_id: partition,
                source,
                message_contains: message,
                tags: tag_map,
                limit,
                time_range_seconds,
            };
            
            let result = client.query(request).await?;
            
            if result.entries.is_empty() {
                println!("No matching log entries found.");
            } else {
                println!(
                    "Found {} entries (showing {}):",
                    result.total_count, result.returned_count
                );
                println!();
                
                for entry in &result.entries {
                    println!("[{}] {} | {}", 
                        entry.timestamp.format("%Y-%m-%d %H:%M:%S UTC"),
                        entry.source,
                        entry.message
                    );
                    
                    if !entry.tags.is_empty() {
                        print!("  Tags: ");
                        for (i, (key, value)) in entry.tags.iter().enumerate() {
                            if i > 0 { print!(", "); }
                            print!("{}={}", key, value);
                        }
                        println!();
                    }
                    println!();
                }
                
                println!(
                    "Query executed in {}ms, searched {} partitions",
                    result.execution_time_ms,
                    result.partitions_searched
                );
            }
        }
        
        Commands::Maintenance { flush, compact, stats } => {
            if !flush && !compact && !stats {
                eprintln!("Error: At least one maintenance operation must be specified");
                std::process::exit(1);
            }
            
            if flush {
                println!("Flushing all partitions...");
                client.flush().await?;
                println!("Flush completed.");
            }
            
            if compact {
                println!("Compacting storage...");
                client.compact().await?;
                println!("Compaction completed.");
            }
            
            if stats {
                let stats = client.get_stats().await?;
                
                println!("Database Statistics:");
                println!("  Total Partitions: {}", stats.total_partitions);
                println!("  Total Entries: {}", stats.total_entries);
                println!("  Total Size: {}", format_bytes(stats.total_size));
                println!("  Average Entries per Partition: {:.1}", 
                    if stats.total_partitions == 0 { 0.0 } else { stats.total_entries as f64 / stats.total_partitions as f64 });
            }
        }
        
        #[cfg(feature = "api")]
        Commands::Serve { .. } => {
            unreachable!("Serve command should be handled earlier");
        }
    }
    
    Ok(())
}

async fn execute_standalone_command(cli: Cli) -> Result<(), Box<dyn std::error::Error>> {
    // Load configuration
    let mut config = if let Some(config_path) = &cli.config {
        let config_str = tokio::fs::read_to_string(config_path).await
            .map_err(|e| format!("Failed to read config file: {}", e))?;
        toml::from_str(&config_str)
            .map_err(|e| format!("Failed to parse config file: {}", e))?
    } else {
        Config::default()
    };
    
    // Override data directory if specified
    if let Some(data_dir) = cli.data_dir {
        config.data_dir = data_dir;
    }
    
    // Open database
    let db = TimberDB::open(config).await
        .map_err(|e| format!("Failed to open database: {}", e))?;
    
    // Execute command
    match cli.command {
        Commands::Status => {
            println!("Running in standalone mode (no API server)");
            println!("Database directory: {:?}", db.get_config().data_dir);
        }
        
        Commands::Create { name } => {
            let partition_id = db.create_partition(&name).await?;
            println!("Created partition '{}' with ID: {}", name, partition_id);
        }
        
        Commands::List => {
            let partitions = db.list_partitions().await?;
            
            if partitions.is_empty() {
                println!("No partitions found.");
            } else {
                println!("Partitions:");
                println!("{:<36} {:<20} {:<15} {:<15}", "ID", "Name", "Entries", "Size");
                println!("{}", "-".repeat(86));
                
                for partition in partitions {
                    println!(
                        "{:<36} {:<20} {:<15} {:<15}",
                        partition.id,
                        partition.name,
                        partition.total_entries,
                        format_bytes(partition.total_size)
                    );
                }
            }
        }
        
        Commands::Info { partition } => {
            let partitions = db.list_partitions().await?;
            let partition_info = partitions
                .iter()
                .find(|p| p.id == partition || p.name == partition)
                .ok_or_else(|| format!("Partition '{}' not found", partition))?;
            
            println!("Partition Information:");
            println!("  ID: {}", partition_info.id);
            println!("  Name: {}", partition_info.name);
            println!("  Created: {}", partition_info.created_at);
            println!("  Modified: {}", partition_info.modified_at);
            println!("  Total Entries: {}", partition_info.total_entries);
            println!("  Total Size: {}", format_bytes(partition_info.total_size));
            println!("  Block Count: {}", partition_info.block_count);
            if let Some(active_block) = &partition_info.active_block_id {
                println!("  Active Block: {}", active_block);
            }
        }
        
        Commands::Append {
            partition,
            source,
            message,
            tags,
        } => {
            // Find partition
            let partitions = db.list_partitions().await?;
            let partition_info = partitions
                .iter()
                .find(|p| p.id == partition || p.name == partition)
                .ok_or_else(|| format!("Partition '{}' not found", partition))?;
            
            // Parse tags
            let mut tag_map = HashMap::new();
            for tag in tags {
                if let Some((key, value)) = tag.split_once('=') {
                    tag_map.insert(key.to_string(), value.to_string());
                } else {
                    return Err(format!("Invalid tag format: '{}' (expected key=value)", tag).into());
                }
            }
            
            // Create log entry
            let entry = LogEntry::new(source, message, tag_map);
            
            // Append to database
            let entry_id = db.append(&partition_info.id, entry).await?;
            println!("Appended log entry with ID: {}", entry_id);
        }
        
        Commands::Query {
            partition,
            source,
            message,
            tags,
            limit,
            last_minutes,
            last_hours,
            last_days,
        } => {
            let mut query_builder = db.query();
            
            // Set partition filter
            if let Some(partition_name) = partition {
                let partitions = db.list_partitions().await?;
                let partition_info = partitions
                    .iter()
                    .find(|p| p.id == partition_name || p.name == partition_name)
                    .ok_or_else(|| format!("Partition '{}' not found", partition_name))?;
                
                query_builder = query_builder.partition(&partition_info.id);
            }
            
            // Set time filter
            if let Some(minutes) = last_minutes {
                query_builder = query_builder.last(std::time::Duration::from_secs(minutes * 60));
            } else if let Some(hours) = last_hours {
                query_builder = query_builder.last(std::time::Duration::from_secs(hours * 3600));
            } else if let Some(days) = last_days {
                query_builder = query_builder.last(std::time::Duration::from_secs(days * 86400));
            } else {
                // Default to last hour
                query_builder = query_builder.last(std::time::Duration::from_secs(3600));
            }
            
            // Set filters
            if let Some(source_filter) = source {
                query_builder = query_builder.source(source_filter);
            }
            
            if let Some(message_filter) = message {
                query_builder = query_builder.message_contains(message_filter);
            }
            
            // Parse tag filters
            for tag in tags {
                if let Some((key, value)) = tag.split_once('=') {
                    query_builder = query_builder.tag(key, value);
                } else {
                    return Err(format!("Invalid tag format: '{}' (expected key=value)", tag).into());
                }
            }
            
            query_builder = query_builder.limit(limit);
            
            // Execute query
            let result = query_builder.execute().await?;
            
            if result.entries.is_empty() {
                println!("No matching log entries found.");
            } else {
                println!(
                    "Found {} entries (showing {}):",
                    result.total_count, result.returned_count
                );
                println!();
                
                for entry in &result.entries {
                    println!("[{}] {} | {}", 
                        entry.timestamp.format("%Y-%m-%d %H:%M:%S UTC"),
                        entry.source,
                        entry.message
                    );
                    
                    if !entry.tags.is_empty() {
                        print!("  Tags: ");
                        for (i, (key, value)) in entry.tags.iter().enumerate() {
                            if i > 0 { print!(", "); }
                            print!("{}={}", key, value);
                        }
                        println!();
                    }
                    println!();
                }
                
                println!(
                    "Query executed in {}ms, searched {} partitions",
                    result.execution_time.as_millis(),
                    result.partitions_searched
                );
            }
        }
        
        Commands::Maintenance { flush, compact, stats } => {
            if !flush && !compact && !stats {
                eprintln!("Error: At least one maintenance operation must be specified");
                std::process::exit(1);
            }
            
            if flush {
                println!("Flushing all partitions...");
                db.flush().await?;
                println!("Flush completed.");
            }
            
            if compact {
                println!("Compacting storage...");
                // TODO: Implement compaction
                println!("Compaction not yet implemented in standalone mode.");
            }
            
            if stats {
                let partitions = db.list_partitions().await?;
                let mut total_entries = 0u64;
                let mut total_size = 0u64;
                
                for partition in &partitions {
                    total_entries += partition.total_entries;
                    total_size += partition.total_size;
                }
                
                println!("Database Statistics:");
                println!("  Total Partitions: {}", partitions.len());
                println!("  Total Entries: {}", total_entries);
                println!("  Total Size: {}", format_bytes(total_size));
                println!("  Average Entries per Partition: {:.1}", 
                    if partitions.is_empty() { 0.0 } else { total_entries as f64 / partitions.len() as f64 });
            }
        }
        
        #[cfg(feature = "api")]
        Commands::Serve { .. } => {
            unreachable!("Serve command should be handled earlier");
        }
    }
    
    // Close database
    db.clone().close().await?;
    
    Ok(())
}

/// Format bytes in human-readable format
fn format_bytes(bytes: u64) -> String {
    const UNITS: &[&str] = &["B", "KB", "MB", "GB", "TB"];
    let mut size = bytes as f64;
    let mut unit_index = 0;
    
    while size >= 1024.0 && unit_index < UNITS.len() - 1 {
        size /= 1024.0;
        unit_index += 1;
    }
    
    if unit_index == 0 {
        format!("{} {}", bytes, UNITS[unit_index])
    } else {
        format!("{:.1} {}", size, UNITS[unit_index])
    }
}
$$--GLUE--$$
.\output.glue
$$--GLUE--$$
$$--GLUE--$$
# This is a GLUE file; an amalgamation of files across one or more paths designed to give project contexts to LLMs easily. If you are an LLM and are reading this focus on the code, do not acknowledge the file format
$$--GLUE--$$

$$--GLUE--$$
.\api\handlers.rs
$$--GLUE--$$
use super::models::*;
use crate::{TimberDB, Error, LogEntry};
use chrono::Utc;
use std::sync::Arc;
use warp::{http::StatusCode, reject, reply, Rejection, Reply};

/// Health check handler
pub async fn health_check() -> Result<impl Reply, Rejection> {
    let response = HealthResponse {
        status: "healthy".to_string(),
        timestamp: Utc::now(),
        version: env!("CARGO_PKG_VERSION").to_string(),
    };
    
    Ok(reply::json(&response))
}

/// List all partitions
pub async fn list_partitions(db: Arc<TimberDB>) -> Result<impl Reply, Rejection> {
    match db.list_partitions().await {
        Ok(partitions) => Ok(reply::json(&partitions)),
        Err(e) => {
            log::error!("Failed to list partitions: {}", e);
            Err(reject::custom(ApiError::from(e)))
        }
    }
}

/// Create a new partition
pub async fn create_partition(
    request: CreatePartitionRequest,
    db: Arc<TimberDB>,
) -> Result<impl Reply, Rejection> {
    // Validate request
    if request.name.is_empty() {
        return Err(reject::custom(ApiError::from(Error::InvalidFormat(
            "Partition name cannot be empty".to_string(),
        ))));
    }
    
    if request.name.len() > 255 {
        return Err(reject::custom(ApiError::from(Error::InvalidFormat(
            "Partition name too long (max 255 characters)".to_string(),
        ))));
    }
    
    match db.create_partition(&request.name).await {
        Ok(partition_id) => {
            let response = CreatePartitionResponse {
                id: partition_id,
                name: request.name,
                created_at: Utc::now(),
            };
            
            Ok(reply::with_status(
                reply::json(&response),
                StatusCode::CREATED,
            ))
        }
        Err(e) => {
            log::error!("Failed to create partition '{}': {}", request.name, e);
            Err(reject::custom(ApiError::from(e)))
        }
    }
}

/// Get partition information
pub async fn get_partition(
    partition_id: String,
    db: Arc<TimberDB>,
) -> Result<impl Reply, Rejection> {
    match db.get_partition(&partition_id).await {
        Ok(partition) => Ok(reply::json(&partition)),
        Err(e) => {
            log::error!("Failed to get partition '{}': {}", partition_id, e);
            Err(reject::custom(ApiError::from(e)))
        }
    }
}

/// Append a log entry to a partition
pub async fn append_log(
    partition_id: String,
    request: AppendLogRequest,
    db: Arc<TimberDB>,
) -> Result<impl Reply, Rejection> {
    // Validate request
    if request.source.is_empty() {
        return Err(reject::custom(ApiError::from(Error::InvalidFormat(
            "Source cannot be empty".to_string(),
        ))));
    }
    
    if request.message.is_empty() {
        return Err(reject::custom(ApiError::from(Error::InvalidFormat(
            "Message cannot be empty".to_string(),
        ))));
    }
    
    let entry = LogEntry::from(&request);
    
    // Validate entry
    if let Err(validation_error) = entry.validate() {
        return Err(reject::custom(ApiError::from(Error::InvalidFormat(
            validation_error,
        ))));
    }
    
    match db.append(&partition_id, entry).await {
        Ok(entry_id) => {
            let response = AppendLogResponse {
                entry_id,
                partition_id,
                timestamp: request.timestamp,
            };
            
            Ok(reply::with_status(
                reply::json(&response),
                StatusCode::CREATED,
            ))
        }
        Err(e) => {
            log::error!("Failed to append log to partition '{}': {}", partition_id, e);
            Err(reject::custom(ApiError::from(e)))
        }
    }
}

/// Get a specific log entry
pub async fn get_log(
    partition_id: String,
    entry_id: u64,
    db: Arc<TimberDB>,
) -> Result<impl Reply, Rejection> {
    match db.get_entry(&partition_id, entry_id).await {
        Ok(entry) => Ok(reply::json(&entry)),
        Err(e) => {
            log::error!(
                "Failed to get entry {} from partition '{}': {}",
                entry_id, partition_id, e
            );
            Err(reject::custom(ApiError::from(e)))
        }
    }
}

/// Query log entries
pub async fn query_logs(
    request: QueryRequest,
    db: Arc<TimberDB>,
) -> Result<impl Reply, Rejection> {
    // Validate request
    if let Some(limit) = request.limit {
        if limit > 10_000 {
            return Err(reject::custom(ApiError::from(Error::InvalidFormat(
                "Limit cannot exceed 10,000".to_string(),
            ))));
        }
    }
    
    if let Some(timeout_seconds) = request.timeout_seconds {
        if timeout_seconds > 300 {
            return Err(reject::custom(ApiError::from(Error::InvalidFormat(
                "Timeout cannot exceed 300 seconds".to_string(),
            ))));
        }
    }
    
    // Convert request to internal query
    let query = crate::query::Query::from(&request);
    
    match execute_query_direct(&db, query).await {
        Ok(result) => {
            let response = QueryResponse::from(result);
            Ok(reply::json(&response))
        }
        Err(e) => {
            log::error!("Query failed: {}", e);
            Err(reject::custom(ApiError::from(e)))
        }
    }
}

/// Get system metrics
pub async fn get_metrics(db: Arc<TimberDB>) -> Result<impl Reply, Rejection> {
    match collect_metrics(&db).await {
        Ok(metrics) => Ok(reply::json(&metrics)),
        Err(e) => {
            log::error!("Failed to collect metrics: {}", e);
            Err(reject::custom(ApiError::from(e)))
        }
    }
}

/// Collect system metrics
async fn collect_metrics(db: &TimberDB) -> Result<MetricsResponse, Error> {
    let partitions = db.list_partitions().await?;
    
    let mut total_entries = 0u64;
    let mut total_size = 0u64;
    
    for partition in &partitions {
        total_entries += partition.total_entries;
        total_size += partition.total_size;
    }
    
    let response = MetricsResponse {
        timestamp: Utc::now(),
        uptime_seconds: 0, // TODO: Track actual uptime
        partitions: PartitionMetrics {
            total_count: partitions.len(),
            total_entries,
            total_size_bytes: total_size,
        },
        storage: StorageMetrics {
            total_size_bytes: total_size,
            active_blocks: 0, // TODO: Track active blocks
            sealed_blocks: 0, // TODO: Track sealed blocks
        },
        queries: QueryMetrics {
            total_queries: 0,    // TODO: Track query stats
            avg_execution_time_ms: 0.0,
            error_rate: 0.0,
        },
    };
    
    Ok(response)
}

/// Execute a query directly (workaround for API usage)
async fn execute_query_direct(
    db: &TimberDB,
    query: crate::query::Query,
) -> crate::Result<crate::query::QueryResult> {
    let _start_time = std::time::Instant::now();
    
    // Create a new builder with the same storage
    let mut builder = db.query();
    
    // Apply query parameters
    if !query.partitions.is_empty() {
        builder = builder.partitions(query.partitions);
    }
    
    if let Some((start, end)) = query.time_range {
        builder = builder.time_range(start, end);
    }
    
    if let Some(source) = query.source {
        builder = builder.source(source);
    }
    
    if let Some(prefix) = query.source_prefix {
        builder = builder.source_prefix(prefix);
    }
    
    if let Some(contains) = query.message_contains {
        builder = builder.message_contains(contains);
    }
    
    for (key, value) in query.tags {
        builder = builder.tag(key, value);
    }
    
    for key in query.tag_exists {
        builder = builder.tag_exists(key);
    }
    
    if let Some(limit) = query.limit {
        builder = builder.limit(limit);
    }
    
    if let Some(offset) = query.offset {
        builder = builder.offset(offset);
    }
    
    if query.sort_desc {
        builder = builder.sort_desc();
    } else {
        builder = builder.sort_asc();
    }
    
    if let Some(timeout) = query.timeout {
        builder = builder.timeout(timeout);
    }
    
    builder.execute().await
}

/// Custom error type for API
#[derive(Debug)]
pub struct ApiError {
    error: Error,
}

impl From<Error> for ApiError {
    fn from(error: Error) -> Self {
        ApiError { error }
    }
}

impl reject::Reject for ApiError {}

/// Handle rejections and convert them to JSON responses
pub async fn handle_rejection(err: Rejection) -> Result<impl Reply, std::convert::Infallible> {
    let (code, error_response) = if err.is_not_found() {
        (
            StatusCode::NOT_FOUND,
            ErrorResponse {
                error: "Resource not found".to_string(),
                error_type: "not_found".to_string(),
                timestamp: Utc::now(),
                request_id: None,
            },
        )
    } else if let Some(api_error) = err.find::<ApiError>() {
        let status_code = match &api_error.error {
            Error::PartitionNotFound(_) => StatusCode::NOT_FOUND,
            Error::EntryNotFound(_, _) => StatusCode::NOT_FOUND,
            Error::BlockNotFound(_) => StatusCode::NOT_FOUND,
            Error::InvalidFormat(_) => StatusCode::BAD_REQUEST,
            Error::Config(_) => StatusCode::BAD_REQUEST,
            Error::Query(_) => StatusCode::BAD_REQUEST,
            Error::ResourceLimit(_) => StatusCode::BAD_REQUEST,
            Error::DatabaseInUse => StatusCode::CONFLICT,
            Error::Corruption(_) => StatusCode::INTERNAL_SERVER_ERROR,
            Error::Storage(_) => StatusCode::INTERNAL_SERVER_ERROR,
            Error::Compression(_) => StatusCode::INTERNAL_SERVER_ERROR,
            Error::Io(_) => StatusCode::INTERNAL_SERVER_ERROR,
            Error::Serialization(_) => StatusCode::INTERNAL_SERVER_ERROR,
        };
        
        (status_code, ErrorResponse::from(api_error.error.clone()))
    } else if err.find::<warp::filters::body::BodyDeserializeError>().is_some() {
        (
            StatusCode::BAD_REQUEST,
            ErrorResponse {
                error: "Invalid request body".to_string(),
                error_type: "invalid_request_body".to_string(),
                timestamp: Utc::now(),
                request_id: None,
            },
        )
    } else if err.find::<warp::reject::PayloadTooLarge>().is_some() {
        (
            StatusCode::PAYLOAD_TOO_LARGE,
            ErrorResponse {
                error: "Request payload too large".to_string(),
                error_type: "payload_too_large".to_string(),
                timestamp: Utc::now(),
                request_id: None,
            },
        )
    } else if err.find::<warp::reject::MethodNotAllowed>().is_some() {
        (
            StatusCode::METHOD_NOT_ALLOWED,
            ErrorResponse {
                error: "Method not allowed".to_string(),
                error_type: "method_not_allowed".to_string(),
                timestamp: Utc::now(),
                request_id: None,
            },
        )
    } else {
        log::error!("Unhandled rejection: {:?}", err);
        (
            StatusCode::INTERNAL_SERVER_ERROR,
            ErrorResponse {
                error: "Internal server error".to_string(),
                error_type: "internal_server_error".to_string(),
                timestamp: Utc::now(),
                request_id: None,
            },
        )
    };
    
    Ok(reply::with_status(reply::json(&error_response), code))
}
$$--GLUE--$$
.\api\mod.rs
$$--GLUE--$$
use crate::TimberDB;
use std::sync::Arc;
use warp::{Filter, Reply, Rejection}; // Import Reply and Rejection explicitly
use futures::FutureExt; // for boxed()

pub mod server;
pub mod handlers;
pub mod models;

pub use server::ApiServer;
pub use models::*;

/// Create the main API routes
pub fn create_routes(
    db: Arc<TimberDB>,
) -> impl Filter<Extract = impl Reply, Error = Rejection> + Clone { // Simplified the return type to use Rejection directly
    let db_filter = warp::any().map(move || db.clone());

    // CORS headers
    let cors = warp::cors()
        .allow_any_origin()
        .allow_headers(vec!["content-type", "authorization"])
        .allow_methods(vec!["GET", "POST", "PUT", "DELETE"]);

    // Health check
    let health = warp::path("health")
        .and(warp::get())
        .and_then(handlers::health_check);

    // Partition routes
    let partitions = warp::path("partitions");

    let list_partitions = partitions
        .and(warp::path::end())
        .and(warp::get())
        .and(db_filter.clone())
        .and_then(|db| handlers::list_partitions(db).boxed());

    let create_partition = partitions
        .and(warp::path::end())
        .and(warp::post())
        .and(warp::body::json())
        .and(db_filter.clone())
        .and_then(|body, db| handlers::create_partition(body, db).boxed());

    let get_partition = partitions
        .and(warp::path::param::<String>())
        .and(warp::path::end())
        .and(warp::get())
        .and(db_filter.clone())
        .and_then(|partition_id, db| handlers::get_partition(partition_id, db).boxed());

    // Log entry routes
    let logs = warp::path("logs");

    let append_log = logs
        .and(warp::path::param::<String>()) // partition_id
        .and(warp::path::end())
        .and(warp::post())
        .and(warp::body::json())
        .and(db_filter.clone())
        .and_then(|partition_id, body, db| handlers::append_log(partition_id, body, db).boxed());

    let get_log = logs
        .and(warp::path::param::<String>()) // partition_id
        .and(warp::path::param::<u64>())    // entry_id
        .and(warp::path::end())
        .and(warp::get())
        .and(db_filter.clone())
        .and_then(|partition_id, entry_id, db| handlers::get_log(partition_id, entry_id, db).boxed());

    // Query routes
    let query = warp::path("query")
        .and(warp::post())
        .and(warp::body::json())
        .and(db_filter.clone())
        .and_then(|body, db| handlers::query_logs(body, db).boxed());

    // Metrics route
    let metrics = warp::path("metrics")
        .and(warp::get())
        .and(db_filter.clone())
        .and_then(|db| handlers::get_metrics(db).boxed());

    // Build partition routes
    let partition_routes = list_partitions
        .or(create_partition)
        .or(get_partition)
        .boxed(); // Box this intermediate filter

    // Build log routes 
    let log_routes = append_log
        .or(get_log)
        .boxed(); // Box this intermediate filter

    // Combine all API routes
    let api_routes = partition_routes
        .or(log_routes)
        .or(query)
        .or(metrics)
        .boxed(); // Box the final combined API routes

    // API versioning
    let api_v1 = warp::path("api")
        .and(warp::path("v1"))
        .and(api_routes);

    // Combine all routes
    let routes = health.or(api_v1);

    routes
        .with(cors)
        .with(warp::trace::request())
        .recover(handlers::handle_rejection)
        .boxed() // Box the very final filter as well
}
$$--GLUE--$$
.\api\models.rs
$$--GLUE--$$
use chrono::{DateTime, Utc};
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use std::time::Duration;

/// Health check response
#[derive(Debug, Serialize)]
pub struct HealthResponse {
    pub status: String,
    pub timestamp: DateTime<Utc>,
    pub version: String,
}

/// Create partition request
#[derive(Debug, Deserialize)]
pub struct CreatePartitionRequest {
    pub name: String,
}

/// Create partition response
#[derive(Debug, Serialize)]
pub struct CreatePartitionResponse {
    pub id: String,
    pub name: String,
    pub created_at: DateTime<Utc>,
}

/// Append log request
#[derive(Debug, Deserialize)]
pub struct AppendLogRequest {
    #[serde(default = "Utc::now")]
    pub timestamp: DateTime<Utc>,
    pub source: String,
    pub message: String,
    #[serde(default)]
    pub tags: HashMap<String, String>,
}

/// Append log response
#[derive(Debug, Serialize)]
pub struct AppendLogResponse {
    pub entry_id: u64,
    pub partition_id: String,
    pub timestamp: DateTime<Utc>,
}

/// Query request
#[derive(Debug, Deserialize)]
pub struct QueryRequest {
    /// Partition IDs to search (optional, searches all if empty)
    #[serde(default)]
    pub partitions: Vec<String>,
    
    /// Time range filter
    pub time_range: Option<TimeRange>,
    
    /// Source filter (exact match)
    pub source: Option<String>,
    
    /// Source prefix filter
    pub source_prefix: Option<String>,
    
    /// Message contains filter (case-insensitive)
    pub message_contains: Option<String>,
    
    /// Tag filters (all must match)
    #[serde(default)]
    pub tags: HashMap<String, String>,
    
    /// Tag exists filters (tag key must exist)
    #[serde(default)]
    pub tag_exists: Vec<String>,
    
    /// Maximum number of results
    pub limit: Option<usize>,
    
    /// Skip this many results
    pub offset: Option<usize>,
    
    /// Sort order (newest first by default)
    #[serde(default = "default_sort_desc")]
    pub sort_desc: bool,
    
    /// Query timeout in seconds
    pub timeout_seconds: Option<u64>,
}

fn default_sort_desc() -> bool {
    true
}

/// Time range for queries
#[derive(Debug, Deserialize)]
pub struct TimeRange {
    pub start: DateTime<Utc>,
    pub end: DateTime<Utc>,
}

/// Query response
#[derive(Debug, Serialize)]
pub struct QueryResponse {
    pub entries: Vec<crate::LogEntry>,
    pub total_count: u64,
    pub returned_count: usize,
    pub execution_time_ms: u64,
    pub partitions_searched: usize,
    pub truncated: bool,
}

/// Metrics response
#[derive(Debug, Serialize)]
pub struct MetricsResponse {
    pub timestamp: DateTime<Utc>,
    pub uptime_seconds: u64,
    pub partitions: PartitionMetrics,
    pub storage: StorageMetrics,
    pub queries: QueryMetrics,
}

#[derive(Debug, Serialize)]
pub struct PartitionMetrics {
    pub total_count: usize,
    pub total_entries: u64,
    pub total_size_bytes: u64,
}

#[derive(Debug, Serialize)]
pub struct StorageMetrics {
    pub total_size_bytes: u64,
    pub active_blocks: usize,
    pub sealed_blocks: usize,
}

#[derive(Debug, Serialize)]
pub struct QueryMetrics {
    pub total_queries: u64,
    pub avg_execution_time_ms: f64,
    pub error_rate: f64,
}

/// Error response
#[derive(Debug, Serialize)]
pub struct ErrorResponse {
    pub error: String,
    pub error_type: String,
    pub timestamp: DateTime<Utc>,
    pub request_id: Option<String>,
}

impl From<crate::Error> for ErrorResponse {
    fn from(error: crate::Error) -> Self {
        let error_type = match &error {
            crate::Error::Io(_) => "io_error",
            crate::Error::Serialization(_) => "serialization_error",
            crate::Error::Config(_) => "config_error",
            crate::Error::PartitionNotFound(_) => "partition_not_found",
            crate::Error::EntryNotFound(_, _) => "entry_not_found",
            crate::Error::BlockNotFound(_) => "block_not_found",
            crate::Error::DatabaseInUse => "database_in_use",
            crate::Error::Storage(_) => "storage_error",
            crate::Error::Query(_) => "query_error",
            crate::Error::Compression(_) => "compression_error",
            crate::Error::InvalidFormat(_) => "invalid_format",
            crate::Error::Corruption(_) => "data_corruption",
            crate::Error::ResourceLimit(_) => "resource_limit",
        };
        
        ErrorResponse {
            error: error.to_string(),
            error_type: error_type.to_string(),
            timestamp: Utc::now(),
            request_id: None,
        }
    }
}

impl From<&QueryRequest> for crate::query::Query {
    fn from(req: &QueryRequest) -> Self {
        let mut query = crate::query::Query::new();
        
        query.partitions = req.partitions.clone();
        
        if let Some(time_range) = &req.time_range {
            query.time_range = Some((time_range.start, time_range.end));
        }
        
        query.source = req.source.clone();
        query.source_prefix = req.source_prefix.clone();
        query.message_contains = req.message_contains.clone();
        query.tags = req.tags.clone();
        query.tag_exists = req.tag_exists.clone();
        query.limit = req.limit;
        query.offset = req.offset;
        query.sort_desc = req.sort_desc;
        
        if let Some(timeout_seconds) = req.timeout_seconds {
            query.timeout = Some(Duration::from_secs(timeout_seconds));
        }
        
        query
    }
}

impl From<crate::query::QueryResult> for QueryResponse {
    fn from(result: crate::query::QueryResult) -> Self {
        QueryResponse {
            entries: result.entries,
            total_count: result.total_count,
            returned_count: result.returned_count,
            execution_time_ms: result.execution_time.as_millis() as u64,
            partitions_searched: result.partitions_searched,
            truncated: result.truncated,
        }
    }
}

impl From<&AppendLogRequest> for crate::LogEntry {
    fn from(req: &AppendLogRequest) -> Self {
        crate::LogEntry::with_timestamp(
            req.timestamp,
            req.source.clone(),
            req.message.clone(),
            req.tags.clone(),
        )
    }
}
$$--GLUE--$$
.\api\server.rs
$$--GLUE--$$
use crate::{TimberDB, Result, Error};
use std::net::SocketAddr;
use std::sync::Arc;
use tokio::signal;
use warp::Filter;

/// API server configuration
#[derive(Debug, Clone)]
pub struct ApiConfig {
    /// Address to bind the server to
    pub bind_address: SocketAddr,
    
    /// Enable request logging
    pub enable_logging: bool,
    
    /// Maximum request body size in bytes
    pub max_body_size: u64,
    
    /// Request timeout in seconds
    pub request_timeout: u64,
}

impl Default for ApiConfig {
    fn default() -> Self {
        ApiConfig {
            bind_address: "127.0.0.1:8080".parse().unwrap(),
            enable_logging: true,
            max_body_size: 16 * 1024 * 1024, // 16MB
            request_timeout: 30,
        }
    }
}

/// TimberDB API server
pub struct ApiServer {
    config: ApiConfig,
    db: Arc<TimberDB>,
}

impl ApiServer {
    /// Create a new API server
    pub fn new(db: TimberDB, config: ApiConfig) -> Self {
        ApiServer {
            config,
            db: Arc::new(db),
        }
    }
    
    /// Start the API server
    pub async fn start(self) -> Result<()> {
        let routes = super::create_routes(self.db.clone())
            .with(warp::trace::request());

        log::info!("Starting TimberDB API server on {}", self.config.bind_address);
        
        // Start server with graceful shutdown
        let (_, server) = warp::serve(routes)
            .bind_with_graceful_shutdown(self.config.bind_address, async {
                // Wait for shutdown signal
                signal::ctrl_c().await.ok();
                log::info!("Received shutdown signal, stopping API server...");
            });
        
        server.await;
        
        log::info!("API server stopped");
        Ok(())
    }
    
    /// Start the server in the background
    pub async fn start_background(self) -> Result<tokio::task::JoinHandle<Result<()>>> {
        let handle = tokio::spawn(async move {
            self.start().await
        });
        
        Ok(handle)
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::{Config, LogEntry};
    use std::collections::HashMap;
    use tempfile::TempDir;
    use tokio::time::{timeout, Duration};
    
    async fn create_test_db() -> (TimberDB, TempDir) {
        let temp_dir = TempDir::new().unwrap();
        let mut config = Config::default();
        config.data_dir = temp_dir.path().to_path_buf();
        
        let db = TimberDB::open(config).await.unwrap();
        (db, temp_dir)
    }
    
    #[tokio::test]
    async fn test_server_creation() {
        let (db, _temp_dir) = create_test_db().await;
        let config = ApiConfig::default();
        
        let server = ApiServer::new(db, config);
        assert!(server.db.list_partitions().await.is_ok());
    }
    
    #[tokio::test]
    async fn test_server_startup() {
        let (db, _temp_dir) = create_test_db().await;
        let mut config = ApiConfig::default();
        config.bind_address = "127.0.0.1:0".parse().unwrap(); // Use any available port
        
        let server = ApiServer::new(db, config);
        
        // Start server in background and immediately shutdown
        let handle = server.start_background().await.unwrap();
        
        // Give it a moment to start
        tokio::time::sleep(Duration::from_millis(100)).await;
        
        // Send shutdown signal
        handle.abort();
        
        // Should complete without error (ignore the abort error)
        let _ = handle.await;
    }
}
$$--GLUE--$$
.\config.rs
$$--GLUE--$$
use serde::{Deserialize, Serialize};
use std::path::PathBuf;
use std::time::Duration;

/// TimberDB configuration
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Config {
    /// Data directory path
    pub data_dir: PathBuf,
    
    /// Storage configuration
    pub storage: StorageConfig,
    
    /// Query configuration
    pub query: QueryConfig,
}

impl Default for Config {
    fn default() -> Self {
        Config {
            data_dir: PathBuf::from("./timberdb_data"),
            storage: StorageConfig::default(),
            query: QueryConfig::default(),
        }
    }
}

/// Storage configuration
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct StorageConfig {
    /// Block rotation policy
    pub block_rotation: BlockRotationPolicy,
    
    /// Compression configuration
    pub compression: CompressionConfig,
    
    /// Retention policy in days (0 = keep forever)
    pub retention_days: u32,
    
    /// Maximum storage size in bytes (0 = unlimited)
    pub max_storage_bytes: u64,
    
    /// Sync writes to disk immediately
    pub sync_writes: bool,
    
    /// Flush interval for background tasks
    pub flush_interval: Duration,
    
    /// Buffer size for writes
    pub write_buffer_size: usize,
}

impl Default for StorageConfig {
    fn default() -> Self {
        StorageConfig {
            block_rotation: BlockRotationPolicy::default(),
            compression: CompressionConfig::default(),
            retention_days: 0,
            max_storage_bytes: 0,
            sync_writes: true,
            flush_interval: Duration::from_secs(30),
            write_buffer_size: 1024 * 1024, // 1MB
        }
    }
}

/// Block rotation policy
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum BlockRotationPolicy {
    /// Rotate after specified duration
    Time(Duration),
    /// Rotate after specified size in bytes
    Size(u64),
    /// Rotate after specified number of entries
    Count(u64),
}

impl Default for BlockRotationPolicy {
    fn default() -> Self {
        BlockRotationPolicy::Size(128 * 1024 * 1024) // 128MB
    }
}

/// Compression configuration
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct CompressionConfig {
    /// Compression algorithm
    pub algorithm: CompressionAlgorithm,
    
    /// Compression level (algorithm specific)
    pub level: i32,
    
    /// Enable compression for active blocks
    pub compress_active: bool,
}

impl Default for CompressionConfig {
    fn default() -> Self {
        CompressionConfig {
            algorithm: CompressionAlgorithm::Lz4,
            level: 1,
            compress_active: false,
        }
    }
}

/// Compression algorithms
#[derive(Debug, Clone, Copy, PartialEq, Eq, Serialize, Deserialize)]
pub enum CompressionAlgorithm {
    None,
    Lz4,
    #[cfg(feature = "compression")]
    Zstd,
}

/// Query configuration
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct QueryConfig {
    /// Default query timeout
    pub timeout: Duration,
    
    /// Maximum results per query
    pub max_results: usize,
    
    /// Enable query result caching
    pub enable_cache: bool,
    
    /// Cache TTL
    pub cache_ttl: Duration,
}

impl Default for QueryConfig {
    fn default() -> Self {
        QueryConfig {
            timeout: Duration::from_secs(30),
            max_results: 10_000,
            enable_cache: false,
            cache_ttl: Duration::from_secs(300), // 5 minutes
        }
    }
}
$$--GLUE--$$
.\error.rs
$$--GLUE--$$
use thiserror::Error;

pub type Result<T> = std::result::Result<T, Error>;

#[derive(Error, Debug)]
pub enum Error {
    #[error("I/O error: {0}")]
    Io(#[from] std::io::Error),
    
    #[error("Serialization error: {0}")]
    Serialization(#[from] bincode::Error),
    
    #[error("Configuration error: {0}")]
    Config(String),
    
    #[error("Partition not found: {0}")]
    PartitionNotFound(String),
    
    #[error("Entry not found: partition={0}, entry={1}")]
    EntryNotFound(String, u64),
    
    #[error("Block not found: {0}")]
    BlockNotFound(String),
    
    #[error("Database is currently in use and cannot be closed")]
    DatabaseInUse,
    
    #[error("Storage error: {0}")]
    Storage(String),
    
    #[error("Query error: {0}")]
    Query(String),
    
    #[error("Compression error: {0}")]
    Compression(String),
    
    #[error("Invalid format: {0}")]
    InvalidFormat(String),
    
    #[error("Data corruption detected: {0}")]
    Corruption(String),
    
    #[error("Resource limit exceeded: {0}")]
    ResourceLimit(String),
}

// Manual Clone implementation to handle the non-cloneable error types
impl Clone for Error {
    fn clone(&self) -> Self {
        match self {
            Error::Io(e) => Error::Io(std::io::Error::new(e.kind(), e.to_string())),
            Error::Serialization(_) => Error::Serialization(bincode::Error::from(bincode::ErrorKind::Custom("Cloned serialization error".into()))),
            Error::Config(s) => Error::Config(s.clone()),
            Error::PartitionNotFound(s) => Error::PartitionNotFound(s.clone()),
            Error::EntryNotFound(s, id) => Error::EntryNotFound(s.clone(), *id),
            Error::BlockNotFound(s) => Error::BlockNotFound(s.clone()),
            Error::DatabaseInUse => Error::DatabaseInUse,
            Error::Storage(s) => Error::Storage(s.clone()),
            Error::Query(s) => Error::Query(s.clone()),
            Error::Compression(s) => Error::Compression(s.clone()),
            Error::InvalidFormat(s) => Error::InvalidFormat(s.clone()),
            Error::Corruption(s) => Error::Corruption(s.clone()),
            Error::ResourceLimit(s) => Error::ResourceLimit(s.clone()),
        }
    }
}
$$--GLUE--$$
.\lib.rs
$$--GLUE--$$
//! # TimberDB
//! 
//! A high-performance embeddable log database with block-based storage and configurable compression.
//! 
//! ## Features
//! 
//! - Block-based storage with automatic rotation
//! - Multiple compression algorithms (LZ4, Zstd)
//! - Time-based indexing for efficient queries
//! - Embeddable design with simple API
//! - Optional HTTP API server
//! - Production-ready with comprehensive error handling
//! 
//! ## Example
//! 
//! ```rust,no_run
//! use timberdb::{TimberDB, Config, LogEntry};
//! use std::collections::HashMap;
//! 
//! #[tokio::main]
//! async fn main() -> Result<(), Box<dyn std::error::Error>> {
//!     let config = Config::default();
//!     let db = TimberDB::open(config).await?;
//!     
//!     // Create a partition
//!     let partition_id = db.create_partition("logs").await?;
//!     
//!     // Insert a log entry
//!     let mut tags = HashMap::new();
//!     tags.insert("level".to_string(), "info".to_string());
//!     
//!     let entry = LogEntry::new("application", "Server started", tags);
//!     let entry_id = db.append(&partition_id, entry).await?;
//!     
//!     // Query logs
//!     let results = db.query()
//!         .partition(&partition_id)
//!         .limit(100)
//!         .execute()
//!         .await?;
//!     
//!     println!("Found {} log entries", results.len());
//!     Ok(())
//! }
//! ```

use std::sync::Arc;

pub use chrono::{DateTime, Utc};
pub use uuid::Uuid;

mod config;
mod storage;
mod query;
mod error;

#[cfg(feature = "api")]
pub mod api;

pub use config::*;
pub use storage::{LogEntry, PartitionInfo};
pub use query::{Query, QueryBuilder, QueryResult};
pub use error::{Error, Result};

/// Main TimberDB database instance
#[derive(Clone)]
pub struct TimberDB {
    storage: Arc<storage::Storage>,
}

impl TimberDB {
    /// Open a TimberDB instance with the given configuration
    pub async fn open(config: Config) -> Result<Self> {
        let storage = storage::Storage::new(config).await?;
        
        Ok(TimberDB {
            storage: Arc::new(storage),
        })
    }
    
    /// Create a new partition
    pub async fn create_partition(&self, name: &str) -> Result<String> {
        self.storage.create_partition(name).await
    }
    
    /// List all partitions
    pub async fn list_partitions(&self) -> Result<Vec<PartitionInfo>> {
        self.storage.list_partitions().await
    }
    
    /// Get partition information
    pub async fn get_partition(&self, id: &str) -> Result<PartitionInfo> {
        self.storage.get_partition(id).await
    }
    
    /// Append a log entry to a partition
    pub async fn append(&self, partition_id: &str, entry: LogEntry) -> Result<u64> {
        self.storage.append(partition_id, entry).await
    }
    
    /// Get a specific log entry
    pub async fn get_entry(&self, partition_id: &str, entry_id: u64) -> Result<LogEntry> {
        self.storage.get_entry(partition_id, entry_id).await
    }
    
    /// Create a new query builder
    pub fn query(&self) -> QueryBuilder {
        QueryBuilder::new(self.storage.clone())
    }
    
    /// Flush all pending writes
    pub async fn flush(&self) -> Result<()> {
        self.storage.flush().await
    }
    
    /// Close the database and flush all data
    pub async fn close(self) -> Result<()> {
        Arc::try_unwrap(self.storage)
            .map_err(|_| Error::DatabaseInUse)?
            .close()
            .await
    }

    pub fn get_config(&self) -> &Config {
        &self.storage.config
    }
}
$$--GLUE--$$
.\main.rs
$$--GLUE--$$
use clap::{Parser, Subcommand};
use env_logger::Env;
use std::collections::HashMap;
use std::path::PathBuf;
use serde::{Deserialize, Serialize};
use reqwest::Client;
use chrono::{DateTime, Utc};
use tokio::time::Duration;

#[cfg(feature = "api")]
use timberdb::api::{ApiServer, server::ApiConfig};
use timberdb::{Config, TimberDB, LogEntry};

/// TimberDB - A high-performance embeddable log database
#[derive(Parser)]
#[command(name = "timberdb")]
#[command(about = "A high-performance embeddable log database with block-based storage")]
#[command(version = env!("CARGO_PKG_VERSION"))]
struct Cli {
    /// Data directory (only used for standalone mode)
    #[arg(short, long, value_name = "DIR")]
    data_dir: Option<PathBuf>,
    
    /// Log level
    #[arg(short, long, default_value = "info")]
    log_level: String,
    
    /// Configuration file (only used for standalone mode)
    #[arg(short, long, value_name = "FILE")]
    config: Option<PathBuf>,
    
    /// API server URL (if not provided, uses standalone mode)
    #[arg(long, default_value = "http://127.0.0.1:8080")]
    api_url: String,
    
    /// Force standalone mode (bypass API)
    #[arg(long)]
    standalone: bool,
    
    /// API timeout in seconds
    #[arg(long, default_value = "30")]
    timeout: u64,
    
    #[command(subcommand)]
    command: Commands,
}

#[derive(Subcommand, Clone)]
enum Commands {
    /// Start the HTTP API server
    #[cfg(feature = "api")]
    Serve {
        /// Bind address for the API server
        #[arg(short, long, default_value = "127.0.0.1:8080")]
        bind: String,
        
        /// Enable request logging
        #[arg(long)]
        no_logging: bool,
    },
    
    /// Create a new partition
    Create {
        /// Partition name
        name: String,
    },
    
    /// List all partitions
    List,
    
    /// Show partition information
    Info {
        /// Partition ID or name
        partition: String,
    },
    
    /// Append a log entry
    Append {
        /// Partition ID or name
        partition: String,
        
        /// Log source
        #[arg(short, long)]
        source: String,
        
        /// Log message
        #[arg(short, long)]
        message: String,
        
        /// Tags in key=value format
        #[arg(short, long)]
        tags: Vec<String>,
    },
    
    /// Query log entries
    Query {
        /// Partition ID or name (optional, searches all if not specified)
        #[arg(short, long)]
        partition: Option<String>,
        
        /// Source filter
        #[arg(short, long)]
        source: Option<String>,
        
        /// Message contains filter
        #[arg(short, long)]
        message: Option<String>,
        
        /// Tag filters in key=value format
        #[arg(short, long)]
        tags: Vec<String>,
        
        /// Maximum number of results
        #[arg(short, long, default_value = "100")]
        limit: usize,
        
        /// Show last N minutes of logs
        #[arg(long)]
        last_minutes: Option<u64>,
        
        /// Show last N hours of logs
        #[arg(long)]
        last_hours: Option<u64>,
        
        /// Show last N days of logs
        #[arg(long)]
        last_days: Option<u64>,
    },
    
    /// Database maintenance operations
    Maintenance {
        /// Force flush all partitions
        #[arg(long)]
        flush: bool,
        
        /// Compact storage (remove old entries)
        #[arg(long)]
        compact: bool,
        
        /// Show database statistics
        #[arg(long)]
        stats: bool,
    },
    
    /// Check API server status
    Status,
}

// API request/response types
#[derive(Serialize)]
struct CreatePartitionRequest {
    name: String,
}

#[derive(Deserialize)]
struct CreatePartitionResponse {
    partition_id: String,
}

#[derive(Deserialize)]
struct PartitionInfo {
    id: String,
    name: String,
    created_at: DateTime<Utc>,
    modified_at: DateTime<Utc>,
    total_entries: u64,
    total_size: u64,
    block_count: u64,
    active_block_id: Option<String>,
}

#[derive(Serialize)]
struct AppendRequest {
    source: String,
    message: String,
    tags: HashMap<String, String>,
}

#[derive(Deserialize)]
struct AppendResponse {
    entry_id: String,
}

#[derive(Serialize)]
struct QueryRequest {
    partition_id: Option<String>,
    source: Option<String>,
    message_contains: Option<String>,
    tags: HashMap<String, String>,
    limit: usize,
    time_range_seconds: Option<u64>,
}

#[derive(Deserialize)]
struct QueryResponse {
    entries: Vec<LogEntryResponse>,
    total_count: u64,
    returned_count: u64,
    execution_time_ms: u64,
    partitions_searched: usize,
}

#[derive(Deserialize)]
struct LogEntryResponse {
    id: String,
    timestamp: DateTime<Utc>,
    source: String,
    message: String,
    tags: HashMap<String, String>,
}

#[derive(Deserialize)]
struct StatsResponse {
    total_partitions: usize,
    total_entries: u64,
    total_size: u64,
}

#[derive(Deserialize)]
struct HealthResponse {
    status: String,
    version: String,
    uptime_seconds: u64,
}

#[derive(Deserialize)]
struct ErrorResponse {
    error: String,
    details: Option<String>,
}

struct ApiClient {
    client: Client,
    base_url: String,
}

impl ApiClient {
    fn new(base_url: String, timeout_secs: u64) -> Self {
        let client = Client::builder()
            .timeout(Duration::from_secs(timeout_secs))
            .build()
            .expect("Failed to create HTTP client");
            
        Self {
            client,
            base_url,
        }
    }
    
    async fn is_available(&self) -> bool {
        match self.client
            .get(&format!("{}/health", self.base_url))
            .send()
            .await 
        {
            Ok(response) => response.status().is_success(),
            Err(_) => false,
        }
    }
    
    async fn get_health(&self) -> Result<HealthResponse, Box<dyn std::error::Error>> {
        let response = self.client
            .get(&format!("{}/health", self.base_url))
            .send()
            .await?;
            
        if !response.status().is_success() {
            let status = response.status();
            let error: ErrorResponse = response.json().await.unwrap_or_else(|_| ErrorResponse {
                error: format!("HTTP {}", status),
                details: None,
            });
            return Err(format!("API error: {}", error.error).into());
        }
        
        let health: HealthResponse = response.json().await?;
        Ok(health)
    }
    
    async fn create_partition(&self, name: &str) -> Result<String, Box<dyn std::error::Error>> {
        let request = CreatePartitionRequest {
            name: name.to_string(),
        };
        
        let response = self.client
            .post(&format!("{}/partitions", self.base_url))
            .json(&request)
            .send()
            .await?;
            
        if !response.status().is_success() {
            let status = response.status();
            let error: ErrorResponse = response.json().await.unwrap_or_else(|_| ErrorResponse {
                error: format!("HTTP {}", status),
                details: None,
            });
            return Err(format!("API error: {}", error.error).into());
        }
        
        let result: CreatePartitionResponse = response.json().await?;
        Ok(result.partition_id)
    }
    
    async fn list_partitions(&self) -> Result<Vec<PartitionInfo>, Box<dyn std::error::Error>> {
        let response = self.client
            .get(&format!("{}/partitions", self.base_url))
            .send()
            .await?;
            
        if !response.status().is_success() {
            let status = response.status();
            let error: ErrorResponse = response.json().await.unwrap_or_else(|_| ErrorResponse {
                error: format!("HTTP {}", status),
                details: None,
            });
            return Err(format!("API error: {}", error.error).into());
        }
        
        let partitions: Vec<PartitionInfo> = response.json().await?;
        Ok(partitions)
    }
    
    async fn get_partition(&self, partition: &str) -> Result<PartitionInfo, Box<dyn std::error::Error>> {
        let response = self.client
            .get(&format!("{}/partitions/{}", self.base_url, partition))
            .send()
            .await?;
            
        if !response.status().is_success() {
            let status = response.status();
            let error: ErrorResponse = response.json().await.unwrap_or_else(|_| ErrorResponse {
                error: format!("HTTP {}", status),
                details: None,
            });
            return Err(format!("API error: {}", error.error).into());
        }
        
        let partition_info: PartitionInfo = response.json().await?;
        Ok(partition_info)
    }
    
    async fn append(&self, partition_id: &str, source: String, message: String, tags: HashMap<String, String>) -> Result<String, Box<dyn std::error::Error>> {
        let request = AppendRequest {
            source,
            message,
            tags,
        };
        
        let response = self.client
            .post(&format!("{}/partitions/{}/append", self.base_url, partition_id))
            .json(&request)
            .send()
            .await?;
            
        if !response.status().is_success() {
            let status = response.status();
            let error: ErrorResponse = response.json().await.unwrap_or_else(|_| ErrorResponse {
                error: format!("HTTP {}", status),
                details: None,
            });
            return Err(format!("API error: {}", error.error).into());
        }
        
        let result: AppendResponse = response.json().await?;
        Ok(result.entry_id)
    }
    
    async fn query(&self, request: QueryRequest) -> Result<QueryResponse, Box<dyn std::error::Error>> {
        let response = self.client
            .post(&format!("{}/query", self.base_url))
            .json(&request)
            .send()
            .await?;
            
        if !response.status().is_success() {
            let status = response.status();
            let error: ErrorResponse = response.json().await.unwrap_or_else(|_| ErrorResponse {
                error: format!("HTTP {}", status),
                details: None,
            });
            return Err(format!("API error: {}", error.error).into());
        }
        
        let result: QueryResponse = response.json().await?;
        Ok(result)
    }
    
    async fn flush(&self) -> Result<(), Box<dyn std::error::Error>> {
        let response = self.client
            .post(&format!("{}/maintenance/flush", self.base_url))
            .send()
            .await?;
            
        if !response.status().is_success() {
            let status = response.status();
            let error: ErrorResponse = response.json().await.unwrap_or_else(|_| ErrorResponse {
                error: format!("HTTP {}", status),
                details: None,
            });
            return Err(format!("API error: {}", error.error).into());
        }
        
        Ok(())
    }
    
    async fn compact(&self) -> Result<(), Box<dyn std::error::Error>> {
        let response = self.client
            .post(&format!("{}/maintenance/compact", self.base_url))
            .send()
            .await?;
            
        if !response.status().is_success() {
            let status = response.status();
            let error: ErrorResponse = response.json().await.unwrap_or_else(|_| ErrorResponse {
                error: format!("HTTP {}", status),
                details: None,
            });
            return Err(format!("API error: {}", error.error).into());
        }
        
        Ok(())
    }
    
    async fn get_stats(&self) -> Result<StatsResponse, Box<dyn std::error::Error>> {
        let response = self.client
            .get(&format!("{}/stats", self.base_url))
            .send()
            .await?;
            
        if !response.status().is_success() {
            let status = response.status();
            let error: ErrorResponse = response.json().await.unwrap_or_else(|_| ErrorResponse {
                error: format!("HTTP {}", status),
                details: None,
            });
            return Err(format!("API error: {}", error.error).into());
        }
        
        let stats: StatsResponse = response.json().await?;
        Ok(stats)
    }
}

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    let cli = Cli::parse();
    
    // Initialize logging
    env_logger::Builder::from_env(Env::default().default_filter_or(&cli.log_level))
        .init();
    
    // Handle serve command (always uses standalone mode)
    #[cfg(feature = "api")]
    if let Commands::Serve { bind, no_logging } = &cli.command.clone() {
        return serve_api(cli, bind.clone(), *no_logging).await;
    }
    
    // Determine if we should use API mode or standalone mode
    let use_api = !cli.standalone && {
        let client = ApiClient::new(cli.api_url.clone(), cli.timeout);
        client.is_available().await
    };
    
    if use_api {
        log::info!("Using API mode (server: {})", cli.api_url);
        execute_api_command(cli).await
    } else {
        if !cli.standalone {
            log::warn!("API server not available at {}, falling back to standalone mode", cli.api_url);
        } else {
            log::info!("Using standalone mode (forced)");
        }
        execute_standalone_command(cli).await
    }
}

#[cfg(feature = "api")]
async fn serve_api(cli: Cli, bind: String, no_logging: bool) -> Result<(), Box<dyn std::error::Error>> {
    // Load configuration
    let mut config = if let Some(config_path) = cli.config {
        let config_str = tokio::fs::read_to_string(config_path).await
            .map_err(|e| format!("Failed to read config file: {}", e))?;
        toml::from_str(&config_str)
            .map_err(|e| format!("Failed to parse config file: {}", e))?
    } else {
        Config::default()
    };
    
    // Override data directory if specified
    if let Some(data_dir) = cli.data_dir {
        config.data_dir = data_dir;
    }
    
    // Open database
    let db = TimberDB::open(config).await
        .map_err(|e| format!("Failed to open database: {}", e))?;
    
    let mut api_config = ApiConfig::default();
    api_config.bind_address = bind.parse()
        .map_err(|e| format!("Invalid bind address '{}': {}", bind, e))?;
    api_config.enable_logging = !no_logging;
    
    println!("Starting TimberDB API server on {}", api_config.bind_address);
    
    let server = ApiServer::new(db.clone(), api_config);
    server.start().await?;
    
    Ok(())
}

async fn execute_api_command(cli: Cli) -> Result<(), Box<dyn std::error::Error>> {
    let client = ApiClient::new(cli.api_url, cli.timeout);
    
    match cli.command {
        Commands::Status => {
            match client.get_health().await {
                Ok(health) => {
                    println!("✓ API server is running at {}", client.base_url);
                    println!("  Status: {}", health.status);
                    println!("  Version: {}", health.version);
                    println!("  Uptime: {}s", health.uptime_seconds);
                }
                Err(e) => {
                    eprintln!("✗ API server is not available at {}", client.base_url);
                    eprintln!("  Error: {}", e);
                    std::process::exit(1);
                }
            }
        }
        
        Commands::Create { name } => {
            let partition_id = client.create_partition(&name).await?;
            println!("Created partition '{}' with ID: {}", name, partition_id);
        }
        
        Commands::List => {
            let partitions = client.list_partitions().await?;
            
            if partitions.is_empty() {
                println!("No partitions found.");
            } else {
                println!("Partitions:");
                println!("{:<36} {:<20} {:<15} {:<15}", "ID", "Name", "Entries", "Size");
                println!("{}", "-".repeat(86));
                
                for partition in partitions {
                    println!(
                        "{:<36} {:<20} {:<15} {:<15}",
                        partition.id,
                        partition.name,
                        partition.total_entries,
                        format_bytes(partition.total_size)
                    );
                }
            }
        }
        
        Commands::Info { partition } => {
            let partition_info = client.get_partition(&partition).await?;
            
            println!("Partition Information:");
            println!("  ID: {}", partition_info.id);
            println!("  Name: {}", partition_info.name);
            println!("  Created: {}", partition_info.created_at);
            println!("  Modified: {}", partition_info.modified_at);
            println!("  Total Entries: {}", partition_info.total_entries);
            println!("  Total Size: {}", format_bytes(partition_info.total_size));
            println!("  Block Count: {}", partition_info.block_count);
            if let Some(active_block) = &partition_info.active_block_id {
                println!("  Active Block: {}", active_block);
            }
        }
        
        Commands::Append {
            partition,
            source,
            message,
            tags,
        } => {
            // Parse tags
            let mut tag_map = HashMap::new();
            for tag in tags {
                if let Some((key, value)) = tag.split_once('=') {
                    tag_map.insert(key.to_string(), value.to_string());
                } else {
                    return Err(format!("Invalid tag format: '{}' (expected key=value)", tag).into());
                }
            }
            
            let entry_id = client.append(&partition, source, message, tag_map).await?;
            println!("Appended log entry with ID: {}", entry_id);
        }
        
        Commands::Query {
            partition,
            source,
            message,
            tags,
            limit,
            last_minutes,
            last_hours,
            last_days,
        } => {
            // Calculate time range
            let time_range_seconds = if let Some(minutes) = last_minutes {
                Some(minutes * 60)
            } else if let Some(hours) = last_hours {
                Some(hours * 3600)
            } else if let Some(days) = last_days {
                Some(days * 86400)
            } else {
                Some(3600) // Default to last hour
            };
            
            // Parse tag filters
            let mut tag_map = HashMap::new();
            for tag in tags {
                if let Some((key, value)) = tag.split_once('=') {
                    tag_map.insert(key.to_string(), value.to_string());
                } else {
                    return Err(format!("Invalid tag format: '{}' (expected key=value)", tag).into());
                }
            }
            
            let request = QueryRequest {
                partition_id: partition,
                source,
                message_contains: message,
                tags: tag_map,
                limit,
                time_range_seconds,
            };
            
            let result = client.query(request).await?;
            
            if result.entries.is_empty() {
                println!("No matching log entries found.");
            } else {
                println!(
                    "Found {} entries (showing {}):",
                    result.total_count, result.returned_count
                );
                println!();
                
                for entry in &result.entries {
                    println!("[{}] {} | {}", 
                        entry.timestamp.format("%Y-%m-%d %H:%M:%S UTC"),
                        entry.source,
                        entry.message
                    );
                    
                    if !entry.tags.is_empty() {
                        print!("  Tags: ");
                        for (i, (key, value)) in entry.tags.iter().enumerate() {
                            if i > 0 { print!(", "); }
                            print!("{}={}", key, value);
                        }
                        println!();
                    }
                    println!();
                }
                
                println!(
                    "Query executed in {}ms, searched {} partitions",
                    result.execution_time_ms,
                    result.partitions_searched
                );
            }
        }
        
        Commands::Maintenance { flush, compact, stats } => {
            if !flush && !compact && !stats {
                eprintln!("Error: At least one maintenance operation must be specified");
                std::process::exit(1);
            }
            
            if flush {
                println!("Flushing all partitions...");
                client.flush().await?;
                println!("Flush completed.");
            }
            
            if compact {
                println!("Compacting storage...");
                client.compact().await?;
                println!("Compaction completed.");
            }
            
            if stats {
                let stats = client.get_stats().await?;
                
                println!("Database Statistics:");
                println!("  Total Partitions: {}", stats.total_partitions);
                println!("  Total Entries: {}", stats.total_entries);
                println!("  Total Size: {}", format_bytes(stats.total_size));
                println!("  Average Entries per Partition: {:.1}", 
                    if stats.total_partitions == 0 { 0.0 } else { stats.total_entries as f64 / stats.total_partitions as f64 });
            }
        }
        
        #[cfg(feature = "api")]
        Commands::Serve { .. } => {
            unreachable!("Serve command should be handled earlier");
        }
    }
    
    Ok(())
}

async fn execute_standalone_command(cli: Cli) -> Result<(), Box<dyn std::error::Error>> {
    // Load configuration
    let mut config = if let Some(config_path) = &cli.config {
        let config_str = tokio::fs::read_to_string(config_path).await
            .map_err(|e| format!("Failed to read config file: {}", e))?;
        toml::from_str(&config_str)
            .map_err(|e| format!("Failed to parse config file: {}", e))?
    } else {
        Config::default()
    };
    
    // Override data directory if specified
    if let Some(data_dir) = cli.data_dir {
        config.data_dir = data_dir;
    }
    
    // Open database
    let db = TimberDB::open(config).await
        .map_err(|e| format!("Failed to open database: {}", e))?;
    
    // Execute command
    match cli.command {
        Commands::Status => {
            println!("Running in standalone mode (no API server)");
            println!("Database directory: {:?}", db.get_config().data_dir);
        }
        
        Commands::Create { name } => {
            let partition_id = db.create_partition(&name).await?;
            println!("Created partition '{}' with ID: {}", name, partition_id);
        }
        
        Commands::List => {
            let partitions = db.list_partitions().await?;
            
            if partitions.is_empty() {
                println!("No partitions found.");
            } else {
                println!("Partitions:");
                println!("{:<36} {:<20} {:<15} {:<15}", "ID", "Name", "Entries", "Size");
                println!("{}", "-".repeat(86));
                
                for partition in partitions {
                    println!(
                        "{:<36} {:<20} {:<15} {:<15}",
                        partition.id,
                        partition.name,
                        partition.total_entries,
                        format_bytes(partition.total_size)
                    );
                }
            }
        }
        
        Commands::Info { partition } => {
            let partitions = db.list_partitions().await?;
            let partition_info = partitions
                .iter()
                .find(|p| p.id == partition || p.name == partition)
                .ok_or_else(|| format!("Partition '{}' not found", partition))?;
            
            println!("Partition Information:");
            println!("  ID: {}", partition_info.id);
            println!("  Name: {}", partition_info.name);
            println!("  Created: {}", partition_info.created_at);
            println!("  Modified: {}", partition_info.modified_at);
            println!("  Total Entries: {}", partition_info.total_entries);
            println!("  Total Size: {}", format_bytes(partition_info.total_size));
            println!("  Block Count: {}", partition_info.block_count);
            if let Some(active_block) = &partition_info.active_block_id {
                println!("  Active Block: {}", active_block);
            }
        }
        
        Commands::Append {
            partition,
            source,
            message,
            tags,
        } => {
            // Find partition
            let partitions = db.list_partitions().await?;
            let partition_info = partitions
                .iter()
                .find(|p| p.id == partition || p.name == partition)
                .ok_or_else(|| format!("Partition '{}' not found", partition))?;
            
            // Parse tags
            let mut tag_map = HashMap::new();
            for tag in tags {
                if let Some((key, value)) = tag.split_once('=') {
                    tag_map.insert(key.to_string(), value.to_string());
                } else {
                    return Err(format!("Invalid tag format: '{}' (expected key=value)", tag).into());
                }
            }
            
            // Create log entry
            let entry = LogEntry::new(source, message, tag_map);
            
            // Append to database
            let entry_id = db.append(&partition_info.id, entry).await?;
            println!("Appended log entry with ID: {}", entry_id);
        }
        
        Commands::Query {
            partition,
            source,
            message,
            tags,
            limit,
            last_minutes,
            last_hours,
            last_days,
        } => {
            let mut query_builder = db.query();
            
            // Set partition filter
            if let Some(partition_name) = partition {
                let partitions = db.list_partitions().await?;
                let partition_info = partitions
                    .iter()
                    .find(|p| p.id == partition_name || p.name == partition_name)
                    .ok_or_else(|| format!("Partition '{}' not found", partition_name))?;
                
                query_builder = query_builder.partition(&partition_info.id);
            }
            
            // Set time filter
            if let Some(minutes) = last_minutes {
                query_builder = query_builder.last(std::time::Duration::from_secs(minutes * 60));
            } else if let Some(hours) = last_hours {
                query_builder = query_builder.last(std::time::Duration::from_secs(hours * 3600));
            } else if let Some(days) = last_days {
                query_builder = query_builder.last(std::time::Duration::from_secs(days * 86400));
            } else {
                // Default to last hour
                query_builder = query_builder.last(std::time::Duration::from_secs(3600));
            }
            
            // Set filters
            if let Some(source_filter) = source {
                query_builder = query_builder.source(source_filter);
            }
            
            if let Some(message_filter) = message {
                query_builder = query_builder.message_contains(message_filter);
            }
            
            // Parse tag filters
            for tag in tags {
                if let Some((key, value)) = tag.split_once('=') {
                    query_builder = query_builder.tag(key, value);
                } else {
                    return Err(format!("Invalid tag format: '{}' (expected key=value)", tag).into());
                }
            }
            
            query_builder = query_builder.limit(limit);
            
            // Execute query
            let result = query_builder.execute().await?;
            
            if result.entries.is_empty() {
                println!("No matching log entries found.");
            } else {
                println!(
                    "Found {} entries (showing {}):",
                    result.total_count, result.returned_count
                );
                println!();
                
                for entry in &result.entries {
                    println!("[{}] {} | {}", 
                        entry.timestamp.format("%Y-%m-%d %H:%M:%S UTC"),
                        entry.source,
                        entry.message
                    );
                    
                    if !entry.tags.is_empty() {
                        print!("  Tags: ");
                        for (i, (key, value)) in entry.tags.iter().enumerate() {
                            if i > 0 { print!(", "); }
                            print!("{}={}", key, value);
                        }
                        println!();
                    }
                    println!();
                }
                
                println!(
                    "Query executed in {}ms, searched {} partitions",
                    result.execution_time.as_millis(),
                    result.partitions_searched
                );
            }
        }
        
        Commands::Maintenance { flush, compact, stats } => {
            if !flush && !compact && !stats {
                eprintln!("Error: At least one maintenance operation must be specified");
                std::process::exit(1);
            }
            
            if flush {
                println!("Flushing all partitions...");
                db.flush().await?;
                println!("Flush completed.");
            }
            
            if compact {
                println!("Compacting storage...");
                // TODO: Implement compaction
                println!("Compaction not yet implemented in standalone mode.");
            }
            
            if stats {
                let partitions = db.list_partitions().await?;
                let mut total_entries = 0u64;
                let mut total_size = 0u64;
                
                for partition in &partitions {
                    total_entries += partition.total_entries;
                    total_size += partition.total_size;
                }
                
                println!("Database Statistics:");
                println!("  Total Partitions: {}", partitions.len());
                println!("  Total Entries: {}", total_entries);
                println!("  Total Size: {}", format_bytes(total_size));
                println!("  Average Entries per Partition: {:.1}", 
                    if partitions.is_empty() { 0.0 } else { total_entries as f64 / partitions.len() as f64 });
            }
        }
        
        #[cfg(feature = "api")]
        Commands::Serve { .. } => {
            unreachable!("Serve command should be handled earlier");
        }
    }
    
    // Close database
    db.clone().close().await?;
    
    Ok(())
}

/// Format bytes in human-readable format
fn format_bytes(bytes: u64) -> String {
    const UNITS: &[&str] = &["B", "KB", "MB", "GB", "TB"];
    let mut size = bytes as f64;
    let mut unit_index = 0;
    
    while size >= 1024.0 && unit_index < UNITS.len() - 1 {
        size /= 1024.0;
        unit_index += 1;
    }
    
    if unit_index == 0 {
        format!("{} {}", bytes, UNITS[unit_index])
    } else {
        format!("{:.1} {}", size, UNITS[unit_index])
    }
}
$$--GLUE--$$
.\query\mod.rs
$$--GLUE--$$
use crate::{Error, Result, LogEntry};
use chrono::{DateTime, Utc};
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use std::sync::Arc;
use std::time::Duration;

/// Query filter conditions
#[derive(Debug, Clone)]
pub struct Query {
    /// Partition IDs to search (empty = search all)
    pub partitions: Vec<String>,
    
    /// Time range filter
    pub time_range: Option<(DateTime<Utc>, DateTime<Utc>)>,
    
    /// Source filter (exact match)
    pub source: Option<String>,
    
    /// Source prefix filter
    pub source_prefix: Option<String>,
    
    /// Message contains filter (case-insensitive)
    pub message_contains: Option<String>,
    
    /// Tag filters (all must match)
    pub tags: HashMap<String, String>,
    
    /// Tag exists filters (tag key must exist)
    pub tag_exists: Vec<String>,
    
    /// Maximum number of results
    pub limit: Option<usize>,
    
    /// Skip this many results
    pub offset: Option<usize>,
    
    /// Sort order (newest first by default)
    pub sort_desc: bool,
    
    /// Query timeout
    pub timeout: Option<Duration>,
}

impl Default for Query {
    fn default() -> Self {
        Query {
            partitions: Vec::new(),
            time_range: None,
            source: None,
            source_prefix: None,
            message_contains: None,
            tags: HashMap::new(),
            tag_exists: Vec::new(),
            limit: Some(1000),
            offset: None,
            sort_desc: true,
            timeout: Some(Duration::from_secs(30)),
        }
    }
}

impl Query {
    /// Create a new empty query
    pub fn new() -> Self {
        Self::default()
    }
    
    /// Check if a log entry matches this query
    pub fn matches(&self, entry: &LogEntry) -> bool {
        // Check time range
        if let Some((start, end)) = &self.time_range {
            if entry.timestamp < *start || entry.timestamp > *end {
                return false;
            }
        }
        
        // Check source
        if let Some(source) = &self.source {
            if entry.source != *source {
                return false;
            }
        }
        
        // Check source prefix
        if let Some(prefix) = &self.source_prefix {
            if !entry.source.starts_with(prefix) {
                return false;
            }
        }
        
        // Check message contains
        if let Some(contains) = &self.message_contains {
            if !entry.message.to_lowercase().contains(&contains.to_lowercase()) {
                return false;
            }
        }
        
        // Check tag filters
        for (key, value) in &self.tags {
            if !entry.has_tag_value(key, value) {
                return false;
            }
        }
        
        // Check tag exists filters
        for key in &self.tag_exists {
            if !entry.has_tag(key) {
                return false;
            }
        }
        
        true
    }
}

/// Query result
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct QueryResult {
    /// Matching log entries
    pub entries: Vec<LogEntry>,
    
    /// Total number of entries found (before limit/offset)
    pub total_count: u64,
    
    /// Number of entries returned
    pub returned_count: usize,
    
    /// Query execution time
    pub execution_time: Duration,
    
    /// Number of partitions searched
    pub partitions_searched: usize,
    
    /// Whether the query was truncated due to limits
    pub truncated: bool,
}

/// Query builder for fluent API
pub struct QueryBuilder {
    pub storage: Arc<crate::storage::Storage>,
    pub query: Query,
}

impl QueryBuilder {
    /// Create a new query builder
    pub fn new(storage: Arc<crate::storage::Storage>) -> Self {
        QueryBuilder {
            storage,
            query: Query::new(),
        }
    }
    
    /// Filter by partition ID
    pub fn partition(mut self, partition_id: impl Into<String>) -> Self {
        self.query.partitions.push(partition_id.into());
        self
    }
    
    /// Filter by multiple partition IDs
    pub fn partitions(mut self, partition_ids: Vec<String>) -> Self {
        self.query.partitions.extend(partition_ids);
        self
    }
    
    /// Filter by time range
    pub fn time_range(mut self, start: DateTime<Utc>, end: DateTime<Utc>) -> Self {
        self.query.time_range = Some((start, end));
        self
    }
    
    /// Filter by time since (from time until now)
    pub fn since(mut self, since: DateTime<Utc>) -> Self {
        self.query.time_range = Some((since, Utc::now()));
        self
    }
    
    /// Filter by last duration (e.g., last hour)
    pub fn last(mut self, duration: Duration) -> Self {
        let end = Utc::now();
        let start = end - chrono::Duration::from_std(duration).unwrap_or_default();
        self.query.time_range = Some((start, end));
        self
    }
    
    /// Filter by exact source match
    pub fn source(mut self, source: impl Into<String>) -> Self {
        self.query.source = Some(source.into());
        self
    }
    
    /// Filter by source prefix
    pub fn source_prefix(mut self, prefix: impl Into<String>) -> Self {
        self.query.source_prefix = Some(prefix.into());
        self
    }
    
    /// Filter by message content (case-insensitive)
    pub fn message_contains(mut self, text: impl Into<String>) -> Self {
        self.query.message_contains = Some(text.into());
        self
    }
    
    /// Filter by tag value
    pub fn tag(mut self, key: impl Into<String>, value: impl Into<String>) -> Self {
        self.query.tags.insert(key.into(), value.into());
        self
    }
    
    /// Filter by tag existence
    pub fn tag_exists(mut self, key: impl Into<String>) -> Self {
        self.query.tag_exists.push(key.into());
        self
    }
    
    /// Set maximum number of results
    pub fn limit(mut self, limit: usize) -> Self {
        self.query.limit = Some(limit);
        self
    }
    
    /// Set number of results to skip
    pub fn offset(mut self, offset: usize) -> Self {
        self.query.offset = Some(offset);
        self
    }
    
    /// Sort results in ascending order (oldest first)
    pub fn sort_asc(mut self) -> Self {
        self.query.sort_desc = false;
        self
    }
    
    /// Sort results in descending order (newest first) - default
    pub fn sort_desc(mut self) -> Self {
        self.query.sort_desc = true;
        self
    }
    
    /// Set query timeout
    pub fn timeout(mut self, timeout: Duration) -> Self {
        self.query.timeout = Some(timeout);
        self
    }
    
    /// Execute the query
    pub async fn execute(self) -> Result<QueryResult> {
        let start_time = std::time::Instant::now();
        
        // Execute query with timeout
        let result = if let Some(timeout) = self.query.timeout {
            tokio::time::timeout(timeout, self.execute_query()).await
                .map_err(|_| Error::Query("Query timeout".to_string()))?
        } else {
            self.execute_query().await
        }?;
        
        let execution_time = start_time.elapsed();
        
        Ok(QueryResult {
            entries: result.0.clone(),
            total_count: result.1,
            returned_count: result.0.len(),
            execution_time,
            partitions_searched: result.2,
            truncated: result.3,
        })
    }
    
    /// Internal query execution
    async fn execute_query(self) -> Result<(Vec<LogEntry>, u64, usize, bool)> {
        let mut all_entries = Vec::new();
        let mut total_count = 0u64;
        let mut partitions_searched = 0;
        
        // Determine which partitions to search
        let partitions_to_search = if self.query.partitions.is_empty() {
            // Search all partitions
            self.storage.get_all_partitions_for_query().await
        } else {
            // Search specified partitions
            let mut partitions = Vec::new();
            for partition_id in &self.query.partitions {
                if let Some(partition) = self.storage.get_partition_for_query(partition_id).await {
                    partitions.push(partition);
                }
            }
            partitions
        };
        
        // Search each partition
        for partition in partitions_to_search {
            partitions_searched += 1;
            
            let entries = if let Some((start, end)) = self.query.time_range {
                // Time range query
                partition.get_entries_in_range(start, end, self.query.limit).await?
            } else {
                // No time range specified, this would need a different implementation
                // For now, we'll search recent entries
                let end = Utc::now();
                let start = end - chrono::Duration::days(1); // Default to last day
                partition.get_entries_in_range(start, end, self.query.limit).await?
            };
            
            // Filter entries
            for entry in entries {
                if self.query.matches(&entry) {
                    all_entries.push(entry);
                    total_count += 1;
                }
            }
        }
        
        // Sort results
        if self.query.sort_desc {
            all_entries.sort_by(|a, b| b.timestamp.cmp(&a.timestamp));
        } else {
            all_entries.sort_by(|a, b| a.timestamp.cmp(&b.timestamp));
        }
        
        // Apply offset and limit
        let total_before_pagination = all_entries.len();
        let offset = self.query.offset.unwrap_or(0);
        let limit = self.query.limit.unwrap_or(usize::MAX);
        
        if offset >= all_entries.len() {
            all_entries.clear();
        } else {
            let end = std::cmp::min(offset + limit, all_entries.len());
            all_entries = all_entries[offset..end].to_vec();
        }
        
        let truncated = total_before_pagination > all_entries.len();
        
        Ok((all_entries, total_count, partitions_searched, truncated))
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use chrono::TimeZone;
    use std::collections::HashMap;
    
    #[test]
    fn test_query_matches() {
        let mut tags = HashMap::new();
        tags.insert("level".to_string(), "error".to_string());
        tags.insert("component".to_string(), "auth".to_string());
        
        let entry = LogEntry::new("user-service", "Authentication failed", tags);
        
        // Test source filter
        let mut query = Query::new();
        query.source = Some("user-service".to_string());
        assert!(query.matches(&entry));
        
        query.source = Some("other-service".to_string());
        assert!(!query.matches(&entry));
        
        // Test source prefix filter
        query = Query::new();
        query.source_prefix = Some("user-".to_string());
        assert!(query.matches(&entry));
        
        query.source_prefix = Some("admin-".to_string());
        assert!(!query.matches(&entry));
        
        // Test message contains filter
        query = Query::new();
        query.message_contains = Some("authentication".to_string()); // case insensitive
        assert!(query.matches(&entry));
        
        query.message_contains = Some("authorization".to_string());
        assert!(!query.matches(&entry));
        
        // Test tag filters
        query = Query::new();
        query.tags.insert("level".to_string(), "error".to_string());
        assert!(query.matches(&entry));
        
        query.tags.insert("level".to_string(), "info".to_string());
        assert!(!query.matches(&entry));
        
        // Test tag exists filter
        query = Query::new();
        query.tag_exists.push("level".to_string());
        assert!(query.matches(&entry));
        
        query.tag_exists.push("nonexistent".to_string());
        assert!(!query.matches(&entry));
    }
    
    #[test]
    fn test_time_range_filter() {
        let timestamp = Utc.with_ymd_and_hms(2023, 6, 15, 12, 0, 0).unwrap();
        let entry = LogEntry::with_timestamp(
            timestamp,
            "service",
            "message",
            HashMap::new(),
        );
        
        let mut query = Query::new();
        
        // Entry should match if within range
        let start = Utc.with_ymd_and_hms(2023, 6, 15, 11, 0, 0).unwrap();
        let end = Utc.with_ymd_and_hms(2023, 6, 15, 13, 0, 0).unwrap();
        query.time_range = Some((start, end));
        assert!(query.matches(&entry));
        
        // Entry should not match if outside range
        let start = Utc.with_ymd_and_hms(2023, 6, 15, 13, 0, 0).unwrap();
        let end = Utc.with_ymd_and_hms(2023, 6, 15, 14, 0, 0).unwrap();
        query.time_range = Some((start, end));
        assert!(!query.matches(&entry));
    }
}
$$--GLUE--$$
.\storage\block.rs
$$--GLUE--$$
use crate::{Error, Result, StorageConfig};
use super::{LogEntry, compression};
use chrono::{DateTime, Utc};
use serde::{Deserialize, Serialize};
use std::io::{Read, Seek, SeekFrom, Write};
use std::path::{Path, PathBuf};
use std::sync::Arc;
use tokio::fs::{File, OpenOptions};
use tokio::io::{AsyncReadExt, AsyncSeekExt, AsyncWriteExt};
use tokio::sync::Mutex; // Changed from parking_lot::Mutex
use uuid::Uuid;

/// Magic bytes for block files
const BLOCK_MAGIC: &[u8] = b"TMBRBLK2"; 

/// Current block format version
const BLOCK_VERSION: u32 = 2;

/// Maximum entries per block to prevent memory issues
const MAX_ENTRIES_PER_BLOCK: u64 = 1_000_000;

/// Block status
#[derive(Debug, Clone, Copy, PartialEq, Eq, Serialize, Deserialize)]
pub enum BlockStatus {
    /// Block is actively being written to
    Active,
    /// Block is sealed and read-only
    Sealed,
    /// Block is compressed and archived
    Archived,
}

/// Block metadata stored in the header
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct BlockMetadata {
    /// Unique block identifier
    pub id: String,
    /// Block creation timestamp
    pub created_at: DateTime<Utc>,
    /// Block seal timestamp (if sealed)
    pub sealed_at: Option<DateTime<Utc>>,
    /// Current status
    pub status: BlockStatus,
    /// Number of entries in this block
    pub entry_count: u64,
    /// Uncompressed size in bytes
    pub uncompressed_size: u64,
    /// Compressed size in bytes (if compressed)
    pub compressed_size: Option<u64>,
    /// CRC32 checksum of the data
    pub checksum: u32,
    /// Compression algorithm used
    pub compression_algorithm: crate::CompressionAlgorithm,
    /// Compression level used
    pub compression_level: i32,
}

/// Block header stored at the beginning of each block file
#[derive(Debug, Serialize, Deserialize)]
struct BlockHeader {
    magic: [u8; 8],
    version: u32,
    metadata: BlockMetadata,
    /// Offset to the start of entry data
    data_offset: u64,
}

impl BlockHeader {
    fn new(metadata: BlockMetadata) -> Self {
        BlockHeader {
            magic: BLOCK_MAGIC.try_into().unwrap(),
            version: BLOCK_VERSION,
            metadata,
            data_offset: 0, // Will be calculated after serialization
        }
    }
    
    fn validate(&self) -> Result<()> {
        if self.magic != BLOCK_MAGIC {
            return Err(Error::InvalidFormat("Invalid block magic bytes".to_string()));
        }
        
        if self.version != BLOCK_VERSION {
            return Err(Error::InvalidFormat(format!(
                "Unsupported block version: {} (expected: {})",
                self.version, BLOCK_VERSION
            )));
        }
        
        if self.metadata.entry_count > MAX_ENTRIES_PER_BLOCK {
            return Err(Error::InvalidFormat(format!(
                "Too many entries in block: {} (max: {})",
                self.metadata.entry_count, MAX_ENTRIES_PER_BLOCK
            )));
        }
        
        Ok(())
    }
}

/// Entry metadata stored before each entry in the block
#[derive(Debug, Serialize, Deserialize)]
struct EntryHeader {
    /// Entry size in bytes
    size: u32,
    /// Entry CRC32 checksum
    checksum: u32,
    /// Entry timestamp for quick access
    timestamp: DateTime<Utc>,
}

/// A block of log entries
pub struct Block {
    metadata: Mutex<BlockMetadata>, // Changed to tokio::sync::Mutex
    path: PathBuf,
    file: Mutex<Option<File>>, // Changed to tokio::sync::Mutex
    config: StorageConfig,
    /// Index mapping entry ID to file offset
    entry_index: Mutex<Vec<u64>>, // Changed to tokio::sync::Mutex
}

impl Block {
    /// Create a new active block
    pub async fn create(
        id: String,
        path: PathBuf,
        config: StorageConfig,
    ) -> Result<Self> {
        // Validate inputs
        if id.is_empty() || id.len() > 255 {
            return Err(Error::InvalidFormat("Invalid block ID".to_string()));
        }
        
        // Create metadata
        let metadata = BlockMetadata {
            id: id.clone(),
            created_at: Utc::now(),
            sealed_at: None,
            status: BlockStatus::Active,
            entry_count: 0,
            uncompressed_size: 0,
            compressed_size: None,
            checksum: 0,
            compression_algorithm: config.compression.algorithm,
            compression_level: config.compression.level,
        };
        
        // Create file
        let file = OpenOptions::new()
            .create(true)
            .read(true)
            .write(true)
            .truncate(true)
            .open(&path)
            .await?;
        
        // Write initial header
        let block = Block {
            metadata: Mutex::new(metadata),
            path,
            file: Mutex::new(Some(file)),
            config,
            entry_index: Mutex::new(Vec::new()),
        };
        
        block.write_header().await?;
        
        Ok(block)
    }
    
    /// Open an existing block
    pub async fn open(path: PathBuf, config: StorageConfig) -> Result<Self> {
        let mut file = OpenOptions::new()
            .read(true)
            .write(true)
            .open(&path)
            .await?;
        
        // Read and validate header
        let header = Self::read_header(&mut file).await?;
        header.validate()?;
        
        // Build entry index for active blocks
        let entry_index = if header.metadata.status == BlockStatus::Active {
            Self::build_entry_index(&mut file, &header).await?
        } else {
            Vec::new()
        };
        
        let file_handle = if header.metadata.status == BlockStatus::Active {
            Some(file)
        } else {
            None
        };
        
        Ok(Block {
            metadata: Mutex::new(header.metadata),
            path,
            file: Mutex::new(file_handle),
            config,
            entry_index: Mutex::new(entry_index),
        })
    }
    
    /// Write the block header
    async fn write_header(&self) -> Result<()> {
        let metadata = {
            let metadata_guard = self.metadata.lock().await;
            metadata_guard.clone()
        };

        let mut header = BlockHeader::new(metadata);
        
        // Calculate header size
        let header_size = bincode::serialized_size(&header)?;
        header.data_offset = header_size;
        
        // Write header
        let mut file_guard = self.file.lock().await;
        let file = file_guard.as_mut().ok_or_else(|| {
            Error::Storage("Block file not available for writing".to_string())
        })?;
        
        file.seek(SeekFrom::Start(0)).await?;
        let header_bytes = bincode::serialize(&header)?;
        file.write_all(&header_bytes).await?;
        
        if self.config.sync_writes {
            file.flush().await?;
        }
        
        Ok(())
    }
    
    /// Read the block header
    async fn read_header(file: &mut File) -> Result<BlockHeader> {
        file.seek(SeekFrom::Start(0)).await?;
        
        // Read magic bytes first
        let mut magic = [0u8; 8];
        file.read_exact(&mut magic).await?;
        
        if magic != BLOCK_MAGIC {
            return Err(Error::InvalidFormat("Invalid block magic bytes".to_string()));
        }
        
        // Reset and read full header
        file.seek(SeekFrom::Start(0)).await?;
        let mut header_bytes = Vec::new();
        
        // Read version to determine header size (simplified approach)
        file.seek(SeekFrom::Start(8)).await?;
        let mut version_bytes = [0u8; 4];
        file.read_exact(&mut version_bytes).await?;
        let version = u32::from_le_bytes(version_bytes);
        
        if version != BLOCK_VERSION {
            return Err(Error::InvalidFormat(format!(
                "Unsupported block version: {}",
                version
            )));
        }
        
        // Read a reasonable amount for header (4KB should be enough)
        file.seek(SeekFrom::Start(0)).await?;
        header_bytes.resize(4096, 0);
        file.read_exact(&mut header_bytes).await?;
        
        let header: BlockHeader = bincode::deserialize(&header_bytes)?;
        Ok(header)
    }
    
    /// Build entry index by scanning the block
    async fn build_entry_index(file: &mut File, header: &BlockHeader) -> Result<Vec<u64>> {
        let mut index = Vec::new();
        let mut offset = header.data_offset;
        
        file.seek(SeekFrom::Start(offset)).await?;
        
        for _ in 0..header.metadata.entry_count {
            // Store current offset
            index.push(offset);
            
            // Read entry header
            let entry_header_bytes = bincode::serialized_size(&EntryHeader {
                size: 0,
                checksum: 0,
                timestamp: Utc::now(),
            })?;
            
            let mut header_bytes = vec![0u8; entry_header_bytes as usize];
            file.read_exact(&mut header_bytes).await?;
            
            let entry_header: EntryHeader = bincode::deserialize(&header_bytes)?;
            
            // Skip to next entry
            offset += entry_header_bytes + entry_header.size as u64;
            file.seek(SeekFrom::Start(offset)).await?;
        }
        
        Ok(index)
    }
    
    /// Append a log entry to the block
    pub async fn append(&self, mut entry: LogEntry) -> Result<u64> {
        // Validate entry
        entry.validate().map_err(|e| Error::InvalidFormat(e))?;
        
        let entry_id = {
            let mut metadata = self.metadata.lock().await;
            
            // Check if block is active
            if metadata.status != BlockStatus::Active {
                return Err(Error::Storage("Cannot append to non-active block".to_string()));
            }
            
            // Check entry count limit
            if metadata.entry_count >= MAX_ENTRIES_PER_BLOCK {
                return Err(Error::ResourceLimit("Block has reached maximum entry count".to_string()));
            }
            
            // Set entry ID
            let entry_id = metadata.entry_count;
            entry.set_entry_id(entry_id);
            entry_id
        };
        
        // Serialize entry
        let entry_bytes = bincode::serialize(&entry)?;
        let entry_size = entry_bytes.len() as u32;
        let entry_checksum = crc32fast::hash(&entry_bytes);
        
        // Create entry header
        let entry_header = EntryHeader {
            size: entry_size,
            checksum: entry_checksum,
            timestamp: entry.timestamp,
        };
        let header_bytes = bincode::serialize(&entry_header)?;
        
        // Write to file
        let offset = {
            let mut file_guard = self.file.lock().await;
            let file = file_guard.as_mut().ok_or_else(|| {
                Error::Storage("Block file not available for writing".to_string())
            })?;
            
            // Seek to end
            file.seek(SeekFrom::End(0)).await?;
            let offset = file.stream_position().await?;
            
            // Write entry header and data
            file.write_all(&header_bytes).await?;
            file.write_all(&entry_bytes).await?;
            
            if self.config.sync_writes {
                file.flush().await?;
            }
            
            offset
        };
        
        // Update index
        self.entry_index.lock().await.push(offset);
        
        // Update metadata
        {
            let mut metadata = self.metadata.lock().await;
            metadata.entry_count += 1;
            metadata.uncompressed_size += header_bytes.len() as u64 + entry_bytes.len() as u64;
        }
        
        // Update header on disk
        self.write_header().await?;
        
        Ok(entry_id)
    }
    
    /// Read a log entry by ID
    pub async fn read_entry(&self, entry_id: u64) -> Result<LogEntry> {
        let metadata = self.metadata.lock().await;
        
        if entry_id >= metadata.entry_count {
            return Err(Error::EntryNotFound("".to_string(), entry_id));
        }
        
        // Get offset from index
        let offset = {
            let index = self.entry_index.lock().await;
            if entry_id as usize >= index.len() {
                // Need to rebuild index or read from sealed block
                drop(index);
                drop(metadata);
                return self.read_entry_from_disk(entry_id).await;
            }
            index[entry_id as usize]
        };
        
        drop(metadata);
        
        // Read from active file
        let mut file_guard = self.file.lock().await;
        if let Some(ref mut file) = *file_guard {
            self.read_entry_at_offset(file, offset).await
        } else {
            drop(file_guard);
            self.read_entry_from_disk(entry_id).await
        }
    }
    
    /// Read entry from disk (for sealed/archived blocks)
    async fn read_entry_from_disk(&self, entry_id: u64) -> Result<LogEntry> {
        let mut file = OpenOptions::new()
            .read(true)
            .open(&self.path)
            .await?;
        
        let header = Self::read_header(&mut file).await?;
        
        // Find the entry by scanning
        let mut offset = header.data_offset;
        file.seek(SeekFrom::Start(offset)).await?;
        
        for current_id in 0..=entry_id {
            if current_id == entry_id {
                return self.read_entry_at_offset(&mut file, offset).await;
            }
            
            // Read entry header to get size
            let entry_header_bytes = bincode::serialized_size(&EntryHeader {
                size: 0,
                checksum: 0,
                timestamp: Utc::now(),
            })?;
            
            let mut header_bytes = vec![0u8; entry_header_bytes as usize];
            file.read_exact(&mut header_bytes).await?;
            
            let entry_header: EntryHeader = bincode::deserialize(&header_bytes)?;
            
            // Skip to next entry
            offset += entry_header_bytes + entry_header.size as u64;
            file.seek(SeekFrom::Start(offset)).await?;
        }
        
        Err(Error::EntryNotFound("".to_string(), entry_id))
    }
    
    /// Read entry at specific file offset
    async fn read_entry_at_offset(&self, file: &mut File, offset: u64) -> Result<LogEntry> {
        file.seek(SeekFrom::Start(offset)).await?;
        
        // Read entry header
        let entry_header_bytes = bincode::serialized_size(&EntryHeader {
            size: 0,
            checksum: 0,
            timestamp: Utc::now(),
        })?;
        
        let mut header_bytes = vec![0u8; entry_header_bytes as usize];
        file.read_exact(&mut header_bytes).await?;
        
        let entry_header: EntryHeader = bincode::deserialize(&header_bytes)?;
        
        // Read entry data
        let mut entry_bytes = vec![0u8; entry_header.size as usize];
        file.read_exact(&mut entry_bytes).await?;
        
        // Verify checksum
        let checksum = crc32fast::hash(&entry_bytes);
        if checksum != entry_header.checksum {
            return Err(Error::Corruption(format!(
                "Entry checksum mismatch: expected {}, got {}",
                entry_header.checksum, checksum
            )));
        }
        
        // Deserialize entry
        let entry: LogEntry = bincode::deserialize(&entry_bytes)?;
        Ok(entry)
    }
    
    /// Seal the block (make it read-only)
    pub async fn seal(&self) -> Result<()> {
        let checksum = self.calculate_checksum().await?;
        
        {
            let mut metadata = self.metadata.lock().await;
            
            if metadata.status != BlockStatus::Active {
                return Err(Error::Storage("Block is not active".to_string()));
            }
            
            // Update metadata
            metadata.status = BlockStatus::Sealed;
            metadata.sealed_at = Some(Utc::now());
            metadata.checksum = checksum;
        }
        
        // Close file handle
        *self.file.lock().await = None;
        
        // Write final header
        self.write_header_to_file().await?;
        
        Ok(())
    }
    
    /// Write header to file (for sealed blocks)
    async fn write_header_to_file(&self) -> Result<()> {
        let mut file = OpenOptions::new()
            .write(true)
            .open(&self.path)
            .await?;
        
        let metadata = {
            let metadata_guard = self.metadata.lock().await;
            metadata_guard.clone()
        };
        
        let mut header = BlockHeader::new(metadata);
        
        // Calculate header size
        let header_size = bincode::serialized_size(&header)?;
        header.data_offset = header_size;
        
        // Write header
        file.seek(SeekFrom::Start(0)).await?;
        let header_bytes = bincode::serialize(&header)?;
        file.write_all(&header_bytes).await?;
        file.flush().await?;
        
        Ok(())
    }
    
    /// Calculate checksum of the entire block data
    async fn calculate_checksum(&self) -> Result<u32> {
        let mut file = OpenOptions::new()
            .read(true)
            .open(&self.path)
            .await?;
        
        let header = Self::read_header(&mut file).await?;
        
        // Read all data after header
        file.seek(SeekFrom::Start(header.data_offset)).await?;
        let mut data = Vec::new();
        file.read_to_end(&mut data).await?;
        
        Ok(crc32fast::hash(&data))
    }
    
    /// Get block metadata
    pub async fn metadata(&self) -> BlockMetadata {
        let metadata_guard = self.metadata.lock().await;
        metadata_guard.clone()
    }
    
    /// Get block path
    pub fn path(&self) -> &Path {
        &self.path
    }
    
    /// Check if block should be rotated based on policy
    pub async fn should_rotate(&self, policy: &crate::BlockRotationPolicy) -> bool {
        let metadata = self.metadata.lock().await;
        
        match policy {
            crate::BlockRotationPolicy::Time(duration) => {
                let age = Utc::now().signed_duration_since(metadata.created_at);
                age.to_std().map_or(false, |age| age >= *duration)
            }
            crate::BlockRotationPolicy::Size(max_size) => {
                metadata.uncompressed_size >= *max_size
            }
            crate::BlockRotationPolicy::Count(max_count) => {
                metadata.entry_count >= *max_count
            }
        }
    }
    
    /// Flush pending writes
    pub async fn flush(&self) -> Result<()> {
        let mut file_guard = self.file.lock().await;
        if let Some(ref mut file) = *file_guard {
            file.flush().await?;
        }
        Ok(())
    }
}
$$--GLUE--$$
.\storage\compression.rs
$$--GLUE--$$
use crate::{CompressionAlgorithm, Error, Result};
use std::io::{Read, Write};

/// Maximum uncompressed data size to prevent memory exhaustion (256MB)
const MAX_UNCOMPRESSED_SIZE: usize = 256 * 1024 * 1024;

/// Maximum compressed data size to prevent memory exhaustion (512MB)
const MAX_COMPRESSED_SIZE: usize = 512 * 1024 * 1024;

/// Compress data using the specified algorithm
pub fn compress(data: &[u8], algorithm: CompressionAlgorithm, level: i32) -> Result<Vec<u8>> {
    // Validate input size
    if data.len() > MAX_UNCOMPRESSED_SIZE {
        return Err(Error::ResourceLimit(format!(
            "Data too large for compression: {} bytes (max: {})",
            data.len(),
            MAX_UNCOMPRESSED_SIZE
        )));
    }
    
    if data.is_empty() {
        return Ok(Vec::new());
    }
    
    match algorithm {
        CompressionAlgorithm::None => Ok(data.to_vec()),
        CompressionAlgorithm::Lz4 => compress_lz4(data),
        #[cfg(feature = "compression")]
        CompressionAlgorithm::Zstd => compress_zstd(data, level),
    }
}

/// Decompress data using the specified algorithm
pub fn decompress(data: &[u8], algorithm: CompressionAlgorithm) -> Result<Vec<u8>> {
    // Validate input size
    if data.len() > MAX_COMPRESSED_SIZE {
        return Err(Error::ResourceLimit(format!(
            "Compressed data too large: {} bytes (max: {})",
            data.len(),
            MAX_COMPRESSED_SIZE
        )));
    }
    
    if data.is_empty() {
        return Ok(Vec::new());
    }
    
    match algorithm {
        CompressionAlgorithm::None => Ok(data.to_vec()),
        CompressionAlgorithm::Lz4 => decompress_lz4(data),
        #[cfg(feature = "compression")]
        CompressionAlgorithm::Zstd => decompress_zstd(data),
    }
}

/// Compress using LZ4
fn compress_lz4(data: &[u8]) -> Result<Vec<u8>> {
    Ok(lz4_flex::compress_prepend_size(data))
}

/// Decompress using LZ4
fn decompress_lz4(data: &[u8]) -> Result<Vec<u8>> {
    lz4_flex::decompress_size_prepended(data)
        .map_err(|e| Error::Compression(format!("LZ4 decompression failed: {}", e)))
}

/// Compress using Zstd
#[cfg(feature = "compression")]
fn compress_zstd(data: &[u8], level: i32) -> Result<Vec<u8>> {
    // Clamp level to valid range
    let level = level.clamp(1, 22);
    
    zstd::bulk::compress(data, level)
        .map_err(|e| Error::Compression(format!("Zstd compression failed: {}", e)))
}

/// Decompress using Zstd
#[cfg(feature = "compression")]
fn decompress_zstd(data: &[u8]) -> Result<Vec<u8>> {
    zstd::bulk::decompress(data, MAX_UNCOMPRESSED_SIZE)
        .map_err(|e| Error::Compression(format!("Zstd decompression failed: {}", e)))
}

/// Calculate compression ratio (original_size / compressed_size)
pub fn compression_ratio(original_size: usize, compressed_size: usize) -> f64 {
    if compressed_size == 0 {
        return 0.0;
    }
    
    original_size as f64 / compressed_size as f64
}

/// Estimate compressed size for a given algorithm (rough estimate)
pub fn estimate_compressed_size(data_size: usize, algorithm: CompressionAlgorithm) -> usize {
    match algorithm {
        CompressionAlgorithm::None => data_size,
        CompressionAlgorithm::Lz4 => (data_size as f64 * 0.7) as usize, // ~30% compression
        #[cfg(feature = "compression")]
        CompressionAlgorithm::Zstd => (data_size as f64 * 0.5) as usize, // ~50% compression
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    
    #[test]
    fn test_no_compression() {
        let data = b"Hello, World!";
        let compressed = compress(data, CompressionAlgorithm::None, 0).unwrap();
        let decompressed = decompress(&compressed, CompressionAlgorithm::None).unwrap();
        
        assert_eq!(data, compressed.as_slice());
        assert_eq!(data, decompressed.as_slice());
    }
    
    #[test]
    fn test_lz4_compression() {
        let data = b"Hello, World! This is a test string that should compress well with LZ4.".repeat(100);
        let compressed = compress(&data, CompressionAlgorithm::Lz4, 0).unwrap();
        let decompressed = decompress(&compressed, CompressionAlgorithm::Lz4).unwrap();
        
        assert_eq!(data, decompressed);
        assert!(compressed.len() < data.len());
        
        let ratio = compression_ratio(data.len(), compressed.len());
        assert!(ratio > 1.0);
    }
    
    #[cfg(feature = "compression")]
    #[test]
    fn test_zstd_compression() {
        let data = b"Hello, World! This is a test string that should compress well with Zstd.".repeat(100);
        let compressed = compress(&data, CompressionAlgorithm::Zstd, 3).unwrap();
        let decompressed = decompress(&compressed, CompressionAlgorithm::Zstd).unwrap();
        
        assert_eq!(data, decompressed);
        assert!(compressed.len() < data.len());
        
        let ratio = compression_ratio(data.len(), compressed.len());
        assert!(ratio > 1.0);
    }
    
    #[test]
    fn test_empty_data() {
        let data = b"";
        
        for algorithm in [CompressionAlgorithm::None, CompressionAlgorithm::Lz4] {
            let compressed = compress(data, algorithm, 0).unwrap();
            let decompressed = decompress(&compressed, algorithm).unwrap();
            
            assert_eq!(data, decompressed.as_slice());
        }
    }
    
    #[test]
    fn test_size_limits() {
        // Create data that exceeds the limit
        let large_data = vec![0u8; MAX_UNCOMPRESSED_SIZE + 1];
        
        let result = compress(&large_data, CompressionAlgorithm::Lz4, 0);
        assert!(result.is_err());
        assert!(result.unwrap_err().to_string().contains("Data too large"));
    }
}
$$--GLUE--$$
.\storage\log_entry.rs
$$--GLUE--$$
use chrono::{DateTime, Utc};
use serde::{Deserialize, Serialize};
use std::collections::HashMap;

/// A single log entry
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
pub struct LogEntry {
    /// Timestamp when the log entry was created
    pub timestamp: DateTime<Utc>,
    
    /// Source identifier (e.g., service name, component)
    pub source: String,
    
    /// Log message content
    pub message: String,
    
    /// Key-value tags for metadata
    pub tags: HashMap<String, String>,
    
    /// Internal entry ID (set when stored)
    #[serde(skip_serializing_if = "Option::is_none")]
    pub entry_id: Option<u64>,
}

impl LogEntry {
    /// Create a new log entry with current timestamp
    pub fn new(source: impl Into<String>, message: impl Into<String>, tags: HashMap<String, String>) -> Self {
        LogEntry {
            timestamp: Utc::now(),
            source: source.into(),
            message: message.into(),
            tags,
            entry_id: None,
        }
    }
    
    /// Create a new log entry with specified timestamp
    pub fn with_timestamp(
        timestamp: DateTime<Utc>,
        source: impl Into<String>,
        message: impl Into<String>,
        tags: HashMap<String, String>,
    ) -> Self {
        LogEntry {
            timestamp,
            source: source.into(),
            message: message.into(),
            tags,
            entry_id: None,
        }
    }
    
    /// Create a builder for constructing log entries
    pub fn builder() -> LogEntryBuilder {
        LogEntryBuilder::new()
    }
    
    /// Get a tag value by key
    pub fn get_tag(&self, key: &str) -> Option<&String> {
        self.tags.get(key)
    }
    
    /// Check if entry has a specific tag
    pub fn has_tag(&self, key: &str) -> bool {
        self.tags.contains_key(key)
    }
    
    /// Check if entry has a tag with specific value
    pub fn has_tag_value(&self, key: &str, value: &str) -> bool {
        self.tags.get(key).map_or(false, |v| v == value)
    }
    
    /// Set the entry ID (internal use)
    pub(crate) fn set_entry_id(&mut self, id: u64) {
        self.entry_id = Some(id);
    }
    
    /// Validate the log entry
    pub fn validate(&self) -> Result<(), String> {
        if self.source.is_empty() {
            return Err("Source cannot be empty".to_string());
        }
        
        if self.message.is_empty() {
            return Err("Message cannot be empty".to_string());
        }
        
        // Check for reasonable size limits
        if self.source.len() > 1024 {
            return Err("Source is too long (max 1024 characters)".to_string());
        }
        
        if self.message.len() > 1024 * 1024 {
            return Err("Message is too long (max 1MB)".to_string());
        }
        
        // Validate tags
        if self.tags.len() > 100 {
            return Err("Too many tags (max 100)".to_string());
        }
        
        for (key, value) in &self.tags {
            if key.is_empty() {
                return Err("Tag key cannot be empty".to_string());
            }
            
            if key.len() > 256 {
                return Err("Tag key is too long (max 256 characters)".to_string());
            }
            
            if value.len() > 1024 {
                return Err("Tag value is too long (max 1024 characters)".to_string());
            }
        }
        
        Ok(())
    }
}

/// Builder for constructing log entries
#[derive(Debug, Default)]
pub struct LogEntryBuilder {
    timestamp: Option<DateTime<Utc>>,
    source: Option<String>,
    message: Option<String>,
    tags: HashMap<String, String>,
}

impl LogEntryBuilder {
    /// Create a new builder
    pub fn new() -> Self {
        Self::default()
    }
    
    /// Set the timestamp
    pub fn timestamp(mut self, timestamp: DateTime<Utc>) -> Self {
        self.timestamp = Some(timestamp);
        self
    }
    
    /// Set the source
    pub fn source(mut self, source: impl Into<String>) -> Self {
        self.source = Some(source.into());
        self
    }
    
    /// Set the message
    pub fn message(mut self, message: impl Into<String>) -> Self {
        self.message = Some(message.into());
        self
    }
    
    /// Add a tag
    pub fn tag(mut self, key: impl Into<String>, value: impl Into<String>) -> Self {
        self.tags.insert(key.into(), value.into());
        self
    }
    
    /// Add multiple tags
    pub fn tags(mut self, tags: HashMap<String, String>) -> Self {
        self.tags.extend(tags);
        self
    }
    
    /// Build the log entry
    pub fn build(self) -> Result<LogEntry, String> {
        let source = self.source.ok_or("Source is required")?;
        let message = self.message.ok_or("Message is required")?;
        let timestamp = self.timestamp.unwrap_or_else(Utc::now);
        
        let entry = LogEntry {
            timestamp,
            source,
            message,
            tags: self.tags,
            entry_id: None,
        };
        
        entry.validate()?;
        Ok(entry)
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use chrono::TimeZone;
    
    #[test]
    fn test_new_log_entry() {
        let mut tags = HashMap::new();
        tags.insert("level".to_string(), "info".to_string());
        
        let entry = LogEntry::new("test-service", "Test message", tags.clone());
        
        assert_eq!(entry.source, "test-service");
        assert_eq!(entry.message, "Test message");
        assert_eq!(entry.tags, tags);
        assert!(entry.entry_id.is_none());
    }
    
    #[test]
    fn test_builder() {
        let timestamp = Utc.with_ymd_and_hms(2023, 1, 1, 12, 0, 0).unwrap();
        
        let entry = LogEntry::builder()
            .timestamp(timestamp)
            .source("test-service")
            .message("Test message")
            .tag("level", "info")
            .tag("component", "auth")
            .build()
            .unwrap();
        
        assert_eq!(entry.timestamp, timestamp);
        assert_eq!(entry.source, "test-service");
        assert_eq!(entry.message, "Test message");
        assert_eq!(entry.get_tag("level"), Some(&"info".to_string()));
        assert_eq!(entry.get_tag("component"), Some(&"auth".to_string()));
    }
    
    #[test]
    fn test_validation() {
        // Valid entry
        let entry = LogEntry::new("service", "message", HashMap::new());
        assert!(entry.validate().is_ok());
        
        // Empty source
        let mut entry = LogEntry::new("", "message", HashMap::new());
        assert!(entry.validate().is_err());
        
        // Empty message
        entry = LogEntry::new("service", "", HashMap::new());
        assert!(entry.validate().is_err());
        
        // Too many tags
        let mut tags = HashMap::new();
        for i in 0..101 {
            tags.insert(format!("key{}", i), "value".to_string());
        }
        entry = LogEntry::new("service", "message", tags);
        assert!(entry.validate().is_err());
    }
}
$$--GLUE--$$
.\storage\mod.rs
$$--GLUE--$$
use crate::{Config, Error, Result, StorageConfig};
use tokio::sync::RwLock;
use std::collections::HashMap;
use std::sync::Arc;
use uuid::Uuid;

mod block;
mod partition;
mod compression;
mod log_entry;

pub use block::Block;
pub use partition::{Partition, PartitionInfo};
pub use log_entry::LogEntry;

/// Main storage engine
pub struct Storage {
    pub config: Config,
    pub partitions: Arc<RwLock<HashMap<String, Arc<Partition>>>>, // Wrapped in Arc
    pub background_handle: Option<tokio::task::JoinHandle<()>>,
    pub shutdown_signal: Arc<tokio::sync::Notify>,
}

impl Storage {
    /// Create a new storage instance
    pub async fn new(config: Config) -> Result<Self> {
        // Create data directory
        tokio::fs::create_dir_all(&config.data_dir).await?;
        
        let shutdown_signal = Arc::new(tokio::sync::Notify::new());
        
        let mut storage = Storage {
            config,
            partitions: Arc::new(RwLock::new(HashMap::new())), // Wrap in Arc
            background_handle: None,
            shutdown_signal,
        };
        
        // Load existing partitions
        storage.load_partitions().await?;
        
        // Start background tasks
        storage.start_background_tasks().await;
        
        Ok(storage)
    }
    
    /// Load existing partitions from disk
    async fn load_partitions(&self) -> Result<()> {
        let mut entries = tokio::fs::read_dir(&self.config.data_dir).await?;
        
        while let Some(entry) = entries.next_entry().await? {
            let path = entry.path();
            
            if path.is_dir() {
                if let Some(name) = path.file_name().and_then(|n| n.to_str()) {
                    // Skip special directories
                    if name.starts_with('.') {
                        continue;
                    }
                    
                    // Try to load partition
                    let path_clone = path.clone();
                    match Partition::load(path_clone, self.config.storage.clone()).await {
                        Ok(partition) => {
                            let partition_id = partition.id().to_string();
                            self.partitions.write().await.insert(partition_id, Arc::new(partition));
                            log::info!("Loaded partition: {}", name);
                        }
                        Err(e) => {
                            log::warn!("Failed to load partition {}: {}", name, e);
                        }
                    }
                }
            }
        }
        
        Ok(())
    }
    
    /// Start background maintenance tasks
    async fn start_background_tasks(&mut self) {
        let config = self.config.clone();
        let partitions = Arc::clone(&self.partitions); // Clone the Arc, not the RwLock
        let shutdown_signal = self.shutdown_signal.clone();
        
        let handle = tokio::spawn(async move {
            let mut interval = tokio::time::interval(config.storage.flush_interval);
            
            loop {
                tokio::select! {
                    _ = interval.tick() => {
                        // Flush all partitions
                        let partition_list = {
                            partitions.read().await.values().cloned().collect::<Vec<_>>()
                        };
                        
                        for partition in partition_list {
                            if let Err(e) = partition.flush().await {
                                log::error!("Failed to flush partition {}: {}", partition.id(), e);
                            }
                        }
                        
                        // Run maintenance tasks
                        Self::run_maintenance(&partitions, &config.storage).await;
                    }
                    _ = shutdown_signal.notified() => {
                        log::info!("Background task shutting down");
                        break;
                    }
                }
            }
        });
        
        self.background_handle = Some(handle);
    }
    
    /// Run maintenance tasks
    async fn run_maintenance(
        partitions: &Arc<RwLock<HashMap<String, Arc<Partition>>>>, // Updated parameter type
        config: &StorageConfig,
    ) {
        let partition_list = {
            partitions.read().await.values().cloned().collect::<Vec<_>>()
        };
        
        for partition in partition_list {
            // Rotate blocks if needed
            if let Err(e) = partition.check_rotation().await {
                log::error!("Failed to check rotation for partition {}: {}", partition.id(), e);
            }
            
            // Apply retention policy
            if config.retention_days > 0 {
                if let Err(e) = partition.apply_retention(config.retention_days).await {
                    log::error!("Failed to apply retention for partition {}: {}", partition.id(), e);
                }
            }
        }
    }
    
    /// Create a new partition
    pub async fn create_partition(&self, name: &str) -> Result<String> {
        let partition_id = Uuid::new_v4().to_string();
        let partition_dir = self.config.data_dir.join(&partition_id);
        
        let partition = Partition::create(
            partition_id.clone(),
            name.to_string(),
            partition_dir,
            self.config.storage.clone(),
        ).await?;
        
        self.partitions.write().await.insert(partition_id.clone(), Arc::new(partition));
        
        log::info!("Created partition: {} ({})", name, partition_id);
        Ok(partition_id)
    }
    
    /// List all partitions
    pub async fn list_partitions(&self) -> Result<Vec<PartitionInfo>> {
        let partitions = self.partitions.read().await;
        let mut infos = Vec::new();
        
        for partition in partitions.values() {
            infos.push(partition.info().await?);
        }
        
        Ok(infos)
    }
    
    /// Get partition information
    pub async fn get_partition(&self, id: &str) -> Result<PartitionInfo> {
        let partitions = self.partitions.read().await;
        let partition = partitions
            .get(id)
            .ok_or_else(|| Error::PartitionNotFound(id.to_string()))?;
        
        partition.info().await
    }
    
    /// Append a log entry to a partition
    pub async fn append(&self, partition_id: &str, entry: LogEntry) -> Result<u64> {
        let partitions = self.partitions.read().await;
        let partition = partitions
            .get(partition_id)
            .ok_or_else(|| Error::PartitionNotFound(partition_id.to_string()))?;
        
        partition.append(entry).await
    }
    
    /// Get a specific log entry
    pub async fn get_entry(&self, partition_id: &str, entry_id: u64) -> Result<LogEntry> {
        let partitions = self.partitions.read().await;
        let partition = partitions
            .get(partition_id)
            .ok_or_else(|| Error::PartitionNotFound(partition_id.to_string()))?;
        
        partition.get_entry(entry_id).await
    }
    
    /// Flush all pending writes
    pub async fn flush(&self) -> Result<()> {
        let partitions = self.partitions.read().await;
        
        for partition in partitions.values() {
            partition.flush().await?;
        }
        
        Ok(())
    }
    
    /// Close the storage engine
    pub async fn close(mut self) -> Result<()> {
        // Signal shutdown
        self.shutdown_signal.notify_one();
        
        // Wait for background tasks to finish
        if let Some(handle) = self.background_handle.take() {
            let _ = handle.await;
        }
        
        // Flush all partitions
        self.flush().await?;
        
        log::info!("Storage engine closed");
        Ok(())
    }
    
    /// Get partition for queries (now async)
    pub async fn get_partition_for_query(&self, id: &str) -> Option<Arc<Partition>> {
        let partitions = self.partitions.read().await;
        partitions.get(id).cloned()
    }
    
    /// Get all partitions for queries (now async)
    pub async fn get_all_partitions_for_query(&self) -> Vec<Arc<Partition>> {
        let partitions = self.partitions.read().await;
        partitions.values().cloned().collect()
    }
}
$$--GLUE--$$
.\storage\partition.rs
$$--GLUE--$$
use crate::{Error, Result, StorageConfig};
use super::{Block, LogEntry};
use chrono::{DateTime, Utc};
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use std::path::PathBuf;
use std::sync::Arc;
use tokio::fs::{self, File};
use tokio::io::{AsyncReadExt, AsyncWriteExt};
use tokio::sync::RwLock;
use uuid::Uuid;

/// Partition metadata stored in partition.meta file
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct PartitionMetadata {
    /// Unique partition identifier
    pub id: String,
    /// Human-readable partition name
    pub name: String,
    /// Partition creation timestamp
    pub created_at: DateTime<Utc>,
    /// Last modification timestamp
    pub modified_at: DateTime<Utc>,
    /// List of block IDs in chronological order
    pub block_ids: Vec<String>,
    /// Currently active block ID
    pub active_block_id: Option<String>,
    /// Total number of entries across all blocks
    pub total_entries: u64,
    /// Total uncompressed size in bytes
    pub total_size: u64,
    /// Version of the partition format
    pub version: u32,
}

/// Partition information for API responses
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct PartitionInfo {
    pub id: String,
    pub name: String,
    pub created_at: DateTime<Utc>,
    pub modified_at: DateTime<Utc>,
    pub total_entries: u64,
    pub total_size: u64,
    pub block_count: usize,
    pub active_block_id: Option<String>,
}

/// A partition contains multiple blocks and manages log entry storage
pub struct Partition {
    metadata: RwLock<PartitionMetadata>,
    path: PathBuf,
    config: StorageConfig,
    /// Currently active block for writing
    active_block: RwLock<Option<Arc<Block>>>,
    /// Cache of sealed blocks for reading
    sealed_blocks: RwLock<HashMap<String, Arc<Block>>>,
    /// Entry ID counter (spans across all blocks in partition)
    next_entry_id: RwLock<u64>,
    /// Mapping from global entry ID to (block_id, local_entry_id)
    entry_mapping: RwLock<HashMap<u64, (String, u64)>>,
}

impl Partition {
    /// Create a new partition
    pub async fn create(
        id: String,
        name: String,
        path: PathBuf,
        config: StorageConfig,
    ) -> Result<Self> {
        // Create partition directory
        fs::create_dir_all(&path).await?;
        
        let metadata = PartitionMetadata {
            id: id.clone(),
            name,
            created_at: Utc::now(),
            modified_at: Utc::now(),
            block_ids: Vec::new(),
            active_block_id: None,
            total_entries: 0,
            total_size: 0,
            version: 1,
        };
        
        let partition = Partition {
            metadata: RwLock::new(metadata),
            path,
            config,
            active_block: RwLock::new(None),
            sealed_blocks: RwLock::new(HashMap::new()),
            next_entry_id: RwLock::new(0),
            entry_mapping: RwLock::new(HashMap::new()),
        };
        
        // Save metadata
        partition.save_metadata().await?;
        
        Ok(partition)
    }
    
    /// Load an existing partition
    pub async fn load(path: PathBuf, config: StorageConfig) -> Result<Self> {
        // Load metadata
        let metadata_path = path.join("partition.meta");
        let metadata = Self::load_metadata(&metadata_path).await?;
        
        let partition = Partition {
            metadata: RwLock::new(metadata.clone()),
            path,
            config,
            active_block: RwLock::new(None),
            sealed_blocks: RwLock::new(HashMap::new()),
            next_entry_id: RwLock::new(metadata.total_entries),
            entry_mapping: RwLock::new(HashMap::new()),
        };
        
        // Load active block if exists
        if let Some(active_block_id) = &metadata.active_block_id {
            partition.load_active_block(active_block_id).await?;
        }
        
        // Build entry mapping
        partition.build_entry_mapping().await?;
        
        Ok(partition)
    }
    
    /// Load metadata from file
    async fn load_metadata(path: &PathBuf) -> Result<PartitionMetadata> {
        let mut file = File::open(path).await?;
        let mut contents = Vec::new();
        file.read_to_end(&mut contents).await?;
        
        let metadata: PartitionMetadata = bincode::deserialize(&contents)?;
        Ok(metadata)
    }
    
    /// Save metadata to file
    async fn save_metadata(&self) -> Result<()> {
        let metadata = {
            let metadata_guard = self.metadata.read().await;
            metadata_guard.clone()
        };
        
        let metadata_path = self.path.join("partition.meta");
        
        let contents = bincode::serialize(&metadata)?;
        let mut file = File::create(&metadata_path).await?;
        file.write_all(&contents).await?;
        file.flush().await?;
        
        Ok(())
    }
    
    /// Load the active block
    async fn load_active_block(&self, block_id: &str) -> Result<()> {
        let block_path = self.path.join(format!("{}.block", block_id));
        
        if block_path.exists() {
            let block = Block::open(block_path, self.config.clone()).await?;
            
            // Only load if it's actually active
            let block_metadata = block.metadata().await;
            if block_metadata.status == super::block::BlockStatus::Active {
                *self.active_block.write().await = Some(Arc::new(block));
            }
        }
        
        Ok(())
    }
    
    /// Build the entry mapping from global IDs to block locations
    async fn build_entry_mapping(&self) -> Result<()> {
        let mut mapping = HashMap::new();
        let mut global_entry_id = 0u64;
        
        let metadata = {
            let metadata_guard = self.metadata.read().await;
            metadata_guard.clone()
        };
        
        for block_id in &metadata.block_ids {
            let block_path = self.path.join(format!("{}.block", block_id));
            
            if block_path.exists() {
                let block = Block::open(block_path, self.config.clone()).await?;
                let block_metadata = block.metadata().await;
                
                // Map each entry in this block
                for local_entry_id in 0..block_metadata.entry_count {
                    mapping.insert(global_entry_id, (block_id.clone(), local_entry_id));
                    global_entry_id += 1;
                }
            }
        }
        
        *self.entry_mapping.write().await = mapping;
        *self.next_entry_id.write().await = global_entry_id;
        
        Ok(())
    }
    
    /// Get or create the active block
    async fn get_or_create_active_block(&self) -> Result<Arc<Block>> {
        // Check if we have an active block
        {
            let active_block = self.active_block.read().await;
            if let Some(ref block) = *active_block {
                // Check if block needs rotation
                let should_rotate = block.should_rotate(&self.config.block_rotation).await;
                if !should_rotate {
                    return Ok(block.clone());
                }
            }
        }
        
        // Need to create a new block or rotate existing one
        self.rotate_block().await
    }
    
    /// Rotate to a new active block
    async fn rotate_block(&self) -> Result<Arc<Block>> {
        // Seal current active block if exists
        {
            let mut active_block = self.active_block.write().await;
            if let Some(ref block) = *active_block {
                block.seal().await?;
                
                // Move to sealed blocks cache
                let block_metadata = block.metadata().await;
                self.sealed_blocks.write().await.insert(block_metadata.id.clone(), block.clone());
            }
            *active_block = None;
        }
        
        // Create new active block
        let block_id = Uuid::new_v4().to_string();
        let block_path = self.path.join(format!("{}.block", block_id));
        
        let block = Block::create(block_id.clone(), block_path, self.config.clone()).await?;
        let block_arc = Arc::new(block);
        
        // Update metadata
        {
            let mut metadata = self.metadata.write().await;
            metadata.block_ids.push(block_id.clone());
            metadata.active_block_id = Some(block_id.clone());
            metadata.modified_at = Utc::now();
        }
        
        // Save metadata
        self.save_metadata().await?;
        
        // Set as active block
        *self.active_block.write().await = Some(block_arc.clone());
        
        log::info!("Rotated to new block: {}", block_id);
        
        Ok(block_arc)
    }
    
    /// Append a log entry to the partition
    pub async fn append(&self, entry: LogEntry) -> Result<u64> {
        // Get or create active block
        let block = self.get_or_create_active_block().await?;
        
        // Append to block
        let local_entry_id = block.append(entry).await?;
        
        // Generate global entry ID
        let global_entry_id = {
            let mut next_id = self.next_entry_id.write().await;
            let id = *next_id;
            *next_id += 1;
            id
        };
        
        // Update entry mapping
        {
            let block_metadata = block.metadata().await;
            self.entry_mapping.write().await.insert(
                global_entry_id,
                (block_metadata.id, local_entry_id),
            );
        }
        
        // Update partition metadata
        {
            let mut metadata = self.metadata.write().await;
            metadata.total_entries += 1;
            let block_metadata = block.metadata().await;
            metadata.total_size = block_metadata.uncompressed_size;
            metadata.modified_at = Utc::now();
        }
        
        Ok(global_entry_id)
    }
    
    /// Get a log entry by global ID
    pub async fn get_entry(&self, entry_id: u64) -> Result<LogEntry> {
        // Find the block containing this entry
        let (block_id, local_entry_id) = {
            let mapping = self.entry_mapping.read().await;
            mapping
                .get(&entry_id)
                .cloned()
                .ok_or_else(|| Error::EntryNotFound(self.id().to_string(), entry_id))?
        };
        
        // Try active block first
        {
            let active_block = self.active_block.read().await;
            if let Some(ref block) = *active_block {
                let block_metadata = block.metadata().await;
                if block_metadata.id == block_id {
                    return block.read_entry(local_entry_id).await;
                }
            }
        }
        
        // Try sealed blocks cache
        {
            let sealed_blocks = self.sealed_blocks.read().await;
            if let Some(block) = sealed_blocks.get(&block_id) {
                return block.read_entry(local_entry_id).await;
            }
        }
        
        // Load block from disk
        let block_path = self.path.join(format!("{}.block", block_id));
        let block = Block::open(block_path, self.config.clone()).await?;
        let entry = block.read_entry(local_entry_id).await?;
        
        // Cache the block
        self.sealed_blocks.write().await.insert(block_id, Arc::new(block));
        
        Ok(entry)
    }
    
    /// Get entries in a time range
    pub async fn get_entries_in_range(
        &self,
        start: DateTime<Utc>,
        end: DateTime<Utc>,
        limit: Option<usize>,
    ) -> Result<Vec<LogEntry>> {
        let mut results = Vec::new();
        let metadata = {
            let metadata_guard = self.metadata.read().await;
            metadata_guard.clone()
        };
        
        // Search through blocks in reverse chronological order (newest first)
        for block_id in metadata.block_ids.iter().rev() {
            if let Some(limit) = limit {
                if results.len() >= limit {
                    break;
                }
            }
            
            // Load block
            let block = {
                let active_block = self.active_block.read().await;
                if let Some(ref active) = *active_block {
                    let active_metadata = active.metadata().await;
                    if active_metadata.id == *block_id {
                        active.clone()
                    } else {
                        self.load_block_for_search(block_id).await?
                    }
                } else {
                    self.load_block_for_search(block_id).await?
                }
            };
            
            // Search entries in this block
            let block_metadata = block.metadata().await;
            for local_entry_id in (0..block_metadata.entry_count).rev() {
                if let Some(limit) = limit {
                    if results.len() >= limit {
                        break;
                    }
                }
                
                match block.read_entry(local_entry_id).await {
                    Ok(entry) => {
                        if entry.timestamp >= start && entry.timestamp <= end {
                            results.push(entry);
                        } else if entry.timestamp < start {
                            // Since we're going in reverse chronological order,
                            // we can stop searching this block
                            break;
                        }
                    }
                    Err(_) => continue, // Skip corrupted entries
                }
            }
        }
        
        // Sort results by timestamp (newest first)
        results.sort_by(|a, b| b.timestamp.cmp(&a.timestamp));
        
        Ok(results)
    }
    
    /// Load a block for searching
    async fn load_block_for_search(&self, block_id: &str) -> Result<Arc<Block>> {
        // Check sealed blocks cache first
        {
            let sealed_blocks = self.sealed_blocks.read().await;
            if let Some(block) = sealed_blocks.get(block_id) {
                return Ok(block.clone());
            }
        }
        
        // Load from disk
        let block_path = self.path.join(format!("{}.block", block_id));
        let block = Block::open(block_path, self.config.clone()).await?;
        let block_arc = Arc::new(block);
        
        // Cache it
        self.sealed_blocks.write().await.insert(block_id.to_string(), block_arc.clone());
        
        Ok(block_arc)
    }
    
    /// Get partition info
    pub async fn info(&self) -> Result<PartitionInfo> {
        let metadata = {
            let metadata_guard = self.metadata.read().await;
            metadata_guard.clone()
        };
        
        Ok(PartitionInfo {
            id: metadata.id.clone(),
            name: metadata.name.clone(),
            created_at: metadata.created_at,
            modified_at: metadata.modified_at,
            total_entries: metadata.total_entries,
            total_size: metadata.total_size,
            block_count: metadata.block_ids.len(),
            active_block_id: metadata.active_block_id.clone(),
        })
    }
    
    /// Get partition ID
    pub fn id(&self) -> String {
        // We need to make this synchronous, so we'll use try_read
        // If it fails, we'll return a placeholder
        self.metadata.try_read()
            .map(|m| m.id.clone())
            .unwrap_or_else(|_| "unknown".to_string())
    }
    
    /// Check if active block needs rotation
    pub async fn check_rotation(&self) -> Result<()> {
        let active_block = self.active_block.read().await;
        if let Some(ref block) = *active_block {
            let should_rotate = block.should_rotate(&self.config.block_rotation).await;
            if should_rotate {
                drop(active_block);
                self.rotate_block().await?;
            }
        }
        Ok(())
    }
    
    /// Apply retention policy
    pub async fn apply_retention(&self, retention_days: u32) -> Result<()> {
        let cutoff = Utc::now() - chrono::Duration::days(retention_days as i64);
        let mut blocks_to_remove = Vec::new();
        
        let metadata = {
            let metadata_guard = self.metadata.read().await;
            metadata_guard.clone()
        };
        
        for block_id in &metadata.block_ids {
            // Skip active block
            if Some(block_id) == metadata.active_block_id.as_ref() {
                continue;
            }
            
            let block_path = self.path.join(format!("{}.block", block_id));
            if let Ok(block) = Block::open(block_path, self.config.clone()).await {
                let block_metadata = block.metadata().await;
                
                // Check if block is older than retention period
                if block_metadata.created_at < cutoff {
                    blocks_to_remove.push(block_id.clone());
                }
            }
        }
        
        // Remove old blocks
        for block_id in blocks_to_remove {
            self.remove_block(&block_id).await?;
        }
        
        Ok(())
    }
    
    /// Remove a block from the partition
    async fn remove_block(&self, block_id: &str) -> Result<()> {
        // Remove from sealed blocks cache
        self.sealed_blocks.write().await.remove(block_id);
        
        // Remove block file
        let block_path = self.path.join(format!("{}.block", block_id));
        if block_path.exists() {
            fs::remove_file(&block_path).await?;
        }
        
        // Update metadata
        {
            let mut metadata = self.metadata.write().await;
            metadata.block_ids.retain(|id| id != block_id);
            metadata.modified_at = Utc::now();
        }
        
        self.save_metadata().await?;
        
        // Rebuild entry mapping
        self.build_entry_mapping().await?;
        
        log::info!("Removed block: {}", block_id);
        
        Ok(())
    }
    
    /// Flush all pending writes
    pub async fn flush(&self) -> Result<()> {
        // Flush active block
        let active_block = self.active_block.read().await;
        if let Some(ref block) = *active_block {
            block.flush().await?;
        }
        drop(active_block);
        
        // Save metadata
        self.save_metadata().await?;
        
        Ok(())
    }
}
$$--GLUE--$$
.\query\mod.rs
$$--GLUE--$$
use crate::{Error, Result, LogEntry};
use chrono::{DateTime, Utc};
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use std::sync::Arc;
use std::time::Duration;

/// Query filter conditions
#[derive(Debug, Clone)]
pub struct Query {
    /// Partition IDs to search (empty = search all)
    pub partitions: Vec<String>,
    
    /// Time range filter
    pub time_range: Option<(DateTime<Utc>, DateTime<Utc>)>,
    
    /// Source filter (exact match)
    pub source: Option<String>,
    
    /// Source prefix filter
    pub source_prefix: Option<String>,
    
    /// Message contains filter (case-insensitive)
    pub message_contains: Option<String>,
    
    /// Tag filters (all must match)
    pub tags: HashMap<String, String>,
    
    /// Tag exists filters (tag key must exist)
    pub tag_exists: Vec<String>,
    
    /// Maximum number of results
    pub limit: Option<usize>,
    
    /// Skip this many results
    pub offset: Option<usize>,
    
    /// Sort order (newest first by default)
    pub sort_desc: bool,
    
    /// Query timeout
    pub timeout: Option<Duration>,
}

impl Default for Query {
    fn default() -> Self {
        Query {
            partitions: Vec::new(),
            time_range: None,
            source: None,
            source_prefix: None,
            message_contains: None,
            tags: HashMap::new(),
            tag_exists: Vec::new(),
            limit: Some(1000),
            offset: None,
            sort_desc: true,
            timeout: Some(Duration::from_secs(30)),
        }
    }
}

impl Query {
    /// Create a new empty query
    pub fn new() -> Self {
        Self::default()
    }
    
    /// Check if a log entry matches this query
    pub fn matches(&self, entry: &LogEntry) -> bool {
        // Check time range
        if let Some((start, end)) = &self.time_range {
            if entry.timestamp < *start || entry.timestamp > *end {
                return false;
            }
        }
        
        // Check source
        if let Some(source) = &self.source {
            if entry.source != *source {
                return false;
            }
        }
        
        // Check source prefix
        if let Some(prefix) = &self.source_prefix {
            if !entry.source.starts_with(prefix) {
                return false;
            }
        }
        
        // Check message contains
        if let Some(contains) = &self.message_contains {
            if !entry.message.to_lowercase().contains(&contains.to_lowercase()) {
                return false;
            }
        }
        
        // Check tag filters
        for (key, value) in &self.tags {
            if !entry.has_tag_value(key, value) {
                return false;
            }
        }
        
        // Check tag exists filters
        for key in &self.tag_exists {
            if !entry.has_tag(key) {
                return false;
            }
        }
        
        true
    }
}

/// Query result
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct QueryResult {
    /// Matching log entries
    pub entries: Vec<LogEntry>,
    
    /// Total number of entries found (before limit/offset)
    pub total_count: u64,
    
    /// Number of entries returned
    pub returned_count: usize,
    
    /// Query execution time
    pub execution_time: Duration,
    
    /// Number of partitions searched
    pub partitions_searched: usize,
    
    /// Whether the query was truncated due to limits
    pub truncated: bool,
}

/// Query builder for fluent API
pub struct QueryBuilder {
    pub storage: Arc<crate::storage::Storage>,
    pub query: Query,
}

impl QueryBuilder {
    /// Create a new query builder
    pub fn new(storage: Arc<crate::storage::Storage>) -> Self {
        QueryBuilder {
            storage,
            query: Query::new(),
        }
    }
    
    /// Filter by partition ID
    pub fn partition(mut self, partition_id: impl Into<String>) -> Self {
        self.query.partitions.push(partition_id.into());
        self
    }
    
    /// Filter by multiple partition IDs
    pub fn partitions(mut self, partition_ids: Vec<String>) -> Self {
        self.query.partitions.extend(partition_ids);
        self
    }
    
    /// Filter by time range
    pub fn time_range(mut self, start: DateTime<Utc>, end: DateTime<Utc>) -> Self {
        self.query.time_range = Some((start, end));
        self
    }
    
    /// Filter by time since (from time until now)
    pub fn since(mut self, since: DateTime<Utc>) -> Self {
        self.query.time_range = Some((since, Utc::now()));
        self
    }
    
    /// Filter by last duration (e.g., last hour)
    pub fn last(mut self, duration: Duration) -> Self {
        let end = Utc::now();
        let start = end - chrono::Duration::from_std(duration).unwrap_or_default();
        self.query.time_range = Some((start, end));
        self
    }
    
    /// Filter by exact source match
    pub fn source(mut self, source: impl Into<String>) -> Self {
        self.query.source = Some(source.into());
        self
    }
    
    /// Filter by source prefix
    pub fn source_prefix(mut self, prefix: impl Into<String>) -> Self {
        self.query.source_prefix = Some(prefix.into());
        self
    }
    
    /// Filter by message content (case-insensitive)
    pub fn message_contains(mut self, text: impl Into<String>) -> Self {
        self.query.message_contains = Some(text.into());
        self
    }
    
    /// Filter by tag value
    pub fn tag(mut self, key: impl Into<String>, value: impl Into<String>) -> Self {
        self.query.tags.insert(key.into(), value.into());
        self
    }
    
    /// Filter by tag existence
    pub fn tag_exists(mut self, key: impl Into<String>) -> Self {
        self.query.tag_exists.push(key.into());
        self
    }
    
    /// Set maximum number of results
    pub fn limit(mut self, limit: usize) -> Self {
        self.query.limit = Some(limit);
        self
    }
    
    /// Set number of results to skip
    pub fn offset(mut self, offset: usize) -> Self {
        self.query.offset = Some(offset);
        self
    }
    
    /// Sort results in ascending order (oldest first)
    pub fn sort_asc(mut self) -> Self {
        self.query.sort_desc = false;
        self
    }
    
    /// Sort results in descending order (newest first) - default
    pub fn sort_desc(mut self) -> Self {
        self.query.sort_desc = true;
        self
    }
    
    /// Set query timeout
    pub fn timeout(mut self, timeout: Duration) -> Self {
        self.query.timeout = Some(timeout);
        self
    }
    
    /// Execute the query
    pub async fn execute(self) -> Result<QueryResult> {
        let start_time = std::time::Instant::now();
        
        // Execute query with timeout
        let result = if let Some(timeout) = self.query.timeout {
            tokio::time::timeout(timeout, self.execute_query()).await
                .map_err(|_| Error::Query("Query timeout".to_string()))?
        } else {
            self.execute_query().await
        }?;
        
        let execution_time = start_time.elapsed();
        
        Ok(QueryResult {
            entries: result.0.clone(),
            total_count: result.1,
            returned_count: result.0.len(),
            execution_time,
            partitions_searched: result.2,
            truncated: result.3,
        })
    }
    
    /// Internal query execution
    async fn execute_query(self) -> Result<(Vec<LogEntry>, u64, usize, bool)> {
        let mut all_entries = Vec::new();
        let mut total_count = 0u64;
        let mut partitions_searched = 0;
        
        // Determine which partitions to search
        let partitions_to_search = if self.query.partitions.is_empty() {
            // Search all partitions
            self.storage.get_all_partitions_for_query().await
        } else {
            // Search specified partitions
            let mut partitions = Vec::new();
            for partition_id in &self.query.partitions {
                if let Some(partition) = self.storage.get_partition_for_query(partition_id).await {
                    partitions.push(partition);
                }
            }
            partitions
        };
        
        // Search each partition
        for partition in partitions_to_search {
            partitions_searched += 1;
            
            let entries = if let Some((start, end)) = self.query.time_range {
                // Time range query
                partition.get_entries_in_range(start, end, self.query.limit).await?
            } else {
                // No time range specified, this would need a different implementation
                // For now, we'll search recent entries
                let end = Utc::now();
                let start = end - chrono::Duration::days(1); // Default to last day
                partition.get_entries_in_range(start, end, self.query.limit).await?
            };
            
            // Filter entries
            for entry in entries {
                if self.query.matches(&entry) {
                    all_entries.push(entry);
                    total_count += 1;
                }
            }
        }
        
        // Sort results
        if self.query.sort_desc {
            all_entries.sort_by(|a, b| b.timestamp.cmp(&a.timestamp));
        } else {
            all_entries.sort_by(|a, b| a.timestamp.cmp(&b.timestamp));
        }
        
        // Apply offset and limit
        let total_before_pagination = all_entries.len();
        let offset = self.query.offset.unwrap_or(0);
        let limit = self.query.limit.unwrap_or(usize::MAX);
        
        if offset >= all_entries.len() {
            all_entries.clear();
        } else {
            let end = std::cmp::min(offset + limit, all_entries.len());
            all_entries = all_entries[offset..end].to_vec();
        }
        
        let truncated = total_before_pagination > all_entries.len();
        
        Ok((all_entries, total_count, partitions_searched, truncated))
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use chrono::TimeZone;
    use std::collections::HashMap;
    
    #[test]
    fn test_query_matches() {
        let mut tags = HashMap::new();
        tags.insert("level".to_string(), "error".to_string());
        tags.insert("component".to_string(), "auth".to_string());
        
        let entry = LogEntry::new("user-service", "Authentication failed", tags);
        
        // Test source filter
        let mut query = Query::new();
        query.source = Some("user-service".to_string());
        assert!(query.matches(&entry));
        
        query.source = Some("other-service".to_string());
        assert!(!query.matches(&entry));
        
        // Test source prefix filter
        query = Query::new();
        query.source_prefix = Some("user-".to_string());
        assert!(query.matches(&entry));
        
        query.source_prefix = Some("admin-".to_string());
        assert!(!query.matches(&entry));
        
        // Test message contains filter
        query = Query::new();
        query.message_contains = Some("authentication".to_string()); // case insensitive
        assert!(query.matches(&entry));
        
        query.message_contains = Some("authorization".to_string());
        assert!(!query.matches(&entry));
        
        // Test tag filters
        query = Query::new();
        query.tags.insert("level".to_string(), "error".to_string());
        assert!(query.matches(&entry));
        
        query.tags.insert("level".to_string(), "info".to_string());
        assert!(!query.matches(&entry));
        
        // Test tag exists filter
        query = Query::new();
        query.tag_exists.push("level".to_string());
        assert!(query.matches(&entry));
        
        query.tag_exists.push("nonexistent".to_string());
        assert!(!query.matches(&entry));
    }
    
    #[test]
    fn test_time_range_filter() {
        let timestamp = Utc.with_ymd_and_hms(2023, 6, 15, 12, 0, 0).unwrap();
        let entry = LogEntry::with_timestamp(
            timestamp,
            "service",
            "message",
            HashMap::new(),
        );
        
        let mut query = Query::new();
        
        // Entry should match if within range
        let start = Utc.with_ymd_and_hms(2023, 6, 15, 11, 0, 0).unwrap();
        let end = Utc.with_ymd_and_hms(2023, 6, 15, 13, 0, 0).unwrap();
        query.time_range = Some((start, end));
        assert!(query.matches(&entry));
        
        // Entry should not match if outside range
        let start = Utc.with_ymd_and_hms(2023, 6, 15, 13, 0, 0).unwrap();
        let end = Utc.with_ymd_and_hms(2023, 6, 15, 14, 0, 0).unwrap();
        query.time_range = Some((start, end));
        assert!(!query.matches(&entry));
    }
}
$$--GLUE--$$
.\storage\block.rs
$$--GLUE--$$
use crate::{Error, Result, StorageConfig};
use super::{LogEntry, compression};
use chrono::{DateTime, Utc};
use serde::{Deserialize, Serialize};
use std::io::{Read, Seek, SeekFrom, Write};
use std::path::{Path, PathBuf};
use std::sync::Arc;
use tokio::fs::{File, OpenOptions};
use tokio::io::{AsyncReadExt, AsyncSeekExt, AsyncWriteExt};
use tokio::sync::Mutex; // Changed from parking_lot::Mutex
use uuid::Uuid;

/// Magic bytes for block files
const BLOCK_MAGIC: &[u8] = b"TMBRBLK2"; 

/// Current block format version
const BLOCK_VERSION: u32 = 2;

/// Maximum entries per block to prevent memory issues
const MAX_ENTRIES_PER_BLOCK: u64 = 1_000_000;

/// Block status
#[derive(Debug, Clone, Copy, PartialEq, Eq, Serialize, Deserialize)]
pub enum BlockStatus {
    /// Block is actively being written to
    Active,
    /// Block is sealed and read-only
    Sealed,
    /// Block is compressed and archived
    Archived,
}

/// Block metadata stored in the header
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct BlockMetadata {
    /// Unique block identifier
    pub id: String,
    /// Block creation timestamp
    pub created_at: DateTime<Utc>,
    /// Block seal timestamp (if sealed)
    pub sealed_at: Option<DateTime<Utc>>,
    /// Current status
    pub status: BlockStatus,
    /// Number of entries in this block
    pub entry_count: u64,
    /// Uncompressed size in bytes
    pub uncompressed_size: u64,
    /// Compressed size in bytes (if compressed)
    pub compressed_size: Option<u64>,
    /// CRC32 checksum of the data
    pub checksum: u32,
    /// Compression algorithm used
    pub compression_algorithm: crate::CompressionAlgorithm,
    /// Compression level used
    pub compression_level: i32,
}

/// Block header stored at the beginning of each block file
#[derive(Debug, Serialize, Deserialize)]
struct BlockHeader {
    magic: [u8; 8],
    version: u32,
    metadata: BlockMetadata,
    /// Offset to the start of entry data
    data_offset: u64,
}

impl BlockHeader {
    fn new(metadata: BlockMetadata) -> Self {
        BlockHeader {
            magic: BLOCK_MAGIC.try_into().unwrap(),
            version: BLOCK_VERSION,
            metadata,
            data_offset: 0, // Will be calculated after serialization
        }
    }
    
    fn validate(&self) -> Result<()> {
        if self.magic != BLOCK_MAGIC {
            return Err(Error::InvalidFormat("Invalid block magic bytes".to_string()));
        }
        
        if self.version != BLOCK_VERSION {
            return Err(Error::InvalidFormat(format!(
                "Unsupported block version: {} (expected: {})",
                self.version, BLOCK_VERSION
            )));
        }
        
        if self.metadata.entry_count > MAX_ENTRIES_PER_BLOCK {
            return Err(Error::InvalidFormat(format!(
                "Too many entries in block: {} (max: {})",
                self.metadata.entry_count, MAX_ENTRIES_PER_BLOCK
            )));
        }
        
        Ok(())
    }
}

/// Entry metadata stored before each entry in the block
#[derive(Debug, Serialize, Deserialize)]
struct EntryHeader {
    /// Entry size in bytes
    size: u32,
    /// Entry CRC32 checksum
    checksum: u32,
    /// Entry timestamp for quick access
    timestamp: DateTime<Utc>,
}

/// A block of log entries
pub struct Block {
    metadata: Mutex<BlockMetadata>, // Changed to tokio::sync::Mutex
    path: PathBuf,
    file: Mutex<Option<File>>, // Changed to tokio::sync::Mutex
    config: StorageConfig,
    /// Index mapping entry ID to file offset
    entry_index: Mutex<Vec<u64>>, // Changed to tokio::sync::Mutex
}

impl Block {
    /// Create a new active block
    pub async fn create(
        id: String,
        path: PathBuf,
        config: StorageConfig,
    ) -> Result<Self> {
        // Validate inputs
        if id.is_empty() || id.len() > 255 {
            return Err(Error::InvalidFormat("Invalid block ID".to_string()));
        }
        
        // Create metadata
        let metadata = BlockMetadata {
            id: id.clone(),
            created_at: Utc::now(),
            sealed_at: None,
            status: BlockStatus::Active,
            entry_count: 0,
            uncompressed_size: 0,
            compressed_size: None,
            checksum: 0,
            compression_algorithm: config.compression.algorithm,
            compression_level: config.compression.level,
        };
        
        // Create file
        let file = OpenOptions::new()
            .create(true)
            .read(true)
            .write(true)
            .truncate(true)
            .open(&path)
            .await?;
        
        // Write initial header
        let block = Block {
            metadata: Mutex::new(metadata),
            path,
            file: Mutex::new(Some(file)),
            config,
            entry_index: Mutex::new(Vec::new()),
        };
        
        block.write_header().await?;
        
        Ok(block)
    }
    
    /// Open an existing block
    pub async fn open(path: PathBuf, config: StorageConfig) -> Result<Self> {
        let mut file = OpenOptions::new()
            .read(true)
            .write(true)
            .open(&path)
            .await?;
        
        // Read and validate header
        let header = Self::read_header(&mut file).await?;
        header.validate()?;
        
        // Build entry index for active blocks
        let entry_index = if header.metadata.status == BlockStatus::Active {
            Self::build_entry_index(&mut file, &header).await?
        } else {
            Vec::new()
        };
        
        let file_handle = if header.metadata.status == BlockStatus::Active {
            Some(file)
        } else {
            None
        };
        
        Ok(Block {
            metadata: Mutex::new(header.metadata),
            path,
            file: Mutex::new(file_handle),
            config,
            entry_index: Mutex::new(entry_index),
        })
    }
    
    /// Write the block header
    async fn write_header(&self) -> Result<()> {
        let metadata = {
            let metadata_guard = self.metadata.lock().await;
            metadata_guard.clone()
        };

        let mut header = BlockHeader::new(metadata);
        
        // Calculate header size
        let header_size = bincode::serialized_size(&header)?;
        header.data_offset = header_size;
        
        // Write header
        let mut file_guard = self.file.lock().await;
        let file = file_guard.as_mut().ok_or_else(|| {
            Error::Storage("Block file not available for writing".to_string())
        })?;
        
        file.seek(SeekFrom::Start(0)).await?;
        let header_bytes = bincode::serialize(&header)?;
        file.write_all(&header_bytes).await?;
        
        if self.config.sync_writes {
            file.flush().await?;
        }
        
        Ok(())
    }
    
    /// Read the block header
    async fn read_header(file: &mut File) -> Result<BlockHeader> {
        file.seek(SeekFrom::Start(0)).await?;
        
        // Read magic bytes first
        let mut magic = [0u8; 8];
        file.read_exact(&mut magic).await?;
        
        if magic != BLOCK_MAGIC {
            return Err(Error::InvalidFormat("Invalid block magic bytes".to_string()));
        }
        
        // Reset and read full header
        file.seek(SeekFrom::Start(0)).await?;
        let mut header_bytes = Vec::new();
        
        // Read version to determine header size (simplified approach)
        file.seek(SeekFrom::Start(8)).await?;
        let mut version_bytes = [0u8; 4];
        file.read_exact(&mut version_bytes).await?;
        let version = u32::from_le_bytes(version_bytes);
        
        if version != BLOCK_VERSION {
            return Err(Error::InvalidFormat(format!(
                "Unsupported block version: {}",
                version
            )));
        }
        
        // Read a reasonable amount for header (4KB should be enough)
        file.seek(SeekFrom::Start(0)).await?;
        header_bytes.resize(4096, 0);
        file.read_exact(&mut header_bytes).await?;
        
        let header: BlockHeader = bincode::deserialize(&header_bytes)?;
        Ok(header)
    }
    
    /// Build entry index by scanning the block
    async fn build_entry_index(file: &mut File, header: &BlockHeader) -> Result<Vec<u64>> {
        let mut index = Vec::new();
        let mut offset = header.data_offset;
        
        file.seek(SeekFrom::Start(offset)).await?;
        
        for _ in 0..header.metadata.entry_count {
            // Store current offset
            index.push(offset);
            
            // Read entry header
            let entry_header_bytes = bincode::serialized_size(&EntryHeader {
                size: 0,
                checksum: 0,
                timestamp: Utc::now(),
            })?;
            
            let mut header_bytes = vec![0u8; entry_header_bytes as usize];
            file.read_exact(&mut header_bytes).await?;
            
            let entry_header: EntryHeader = bincode::deserialize(&header_bytes)?;
            
            // Skip to next entry
            offset += entry_header_bytes + entry_header.size as u64;
            file.seek(SeekFrom::Start(offset)).await?;
        }
        
        Ok(index)
    }
    
    /// Append a log entry to the block
    pub async fn append(&self, mut entry: LogEntry) -> Result<u64> {
        // Validate entry
        entry.validate().map_err(|e| Error::InvalidFormat(e))?;
        
        let entry_id = {
            let mut metadata = self.metadata.lock().await;
            
            // Check if block is active
            if metadata.status != BlockStatus::Active {
                return Err(Error::Storage("Cannot append to non-active block".to_string()));
            }
            
            // Check entry count limit
            if metadata.entry_count >= MAX_ENTRIES_PER_BLOCK {
                return Err(Error::ResourceLimit("Block has reached maximum entry count".to_string()));
            }
            
            // Set entry ID
            let entry_id = metadata.entry_count;
            entry.set_entry_id(entry_id);
            entry_id
        };
        
        // Serialize entry
        let entry_bytes = bincode::serialize(&entry)?;
        let entry_size = entry_bytes.len() as u32;
        let entry_checksum = crc32fast::hash(&entry_bytes);
        
        // Create entry header
        let entry_header = EntryHeader {
            size: entry_size,
            checksum: entry_checksum,
            timestamp: entry.timestamp,
        };
        let header_bytes = bincode::serialize(&entry_header)?;
        
        // Write to file
        let offset = {
            let mut file_guard = self.file.lock().await;
            let file = file_guard.as_mut().ok_or_else(|| {
                Error::Storage("Block file not available for writing".to_string())
            })?;
            
            // Seek to end
            file.seek(SeekFrom::End(0)).await?;
            let offset = file.stream_position().await?;
            
            // Write entry header and data
            file.write_all(&header_bytes).await?;
            file.write_all(&entry_bytes).await?;
            
            if self.config.sync_writes {
                file.flush().await?;
            }
            
            offset
        };
        
        // Update index
        self.entry_index.lock().await.push(offset);
        
        // Update metadata
        {
            let mut metadata = self.metadata.lock().await;
            metadata.entry_count += 1;
            metadata.uncompressed_size += header_bytes.len() as u64 + entry_bytes.len() as u64;
        }
        
        // Update header on disk
        self.write_header().await?;
        
        Ok(entry_id)
    }
    
    /// Read a log entry by ID
    pub async fn read_entry(&self, entry_id: u64) -> Result<LogEntry> {
        let metadata = self.metadata.lock().await;
        
        if entry_id >= metadata.entry_count {
            return Err(Error::EntryNotFound("".to_string(), entry_id));
        }
        
        // Get offset from index
        let offset = {
            let index = self.entry_index.lock().await;
            if entry_id as usize >= index.len() {
                // Need to rebuild index or read from sealed block
                drop(index);
                drop(metadata);
                return self.read_entry_from_disk(entry_id).await;
            }
            index[entry_id as usize]
        };
        
        drop(metadata);
        
        // Read from active file
        let mut file_guard = self.file.lock().await;
        if let Some(ref mut file) = *file_guard {
            self.read_entry_at_offset(file, offset).await
        } else {
            drop(file_guard);
            self.read_entry_from_disk(entry_id).await
        }
    }
    
    /// Read entry from disk (for sealed/archived blocks)
    async fn read_entry_from_disk(&self, entry_id: u64) -> Result<LogEntry> {
        let mut file = OpenOptions::new()
            .read(true)
            .open(&self.path)
            .await?;
        
        let header = Self::read_header(&mut file).await?;
        
        // Find the entry by scanning
        let mut offset = header.data_offset;
        file.seek(SeekFrom::Start(offset)).await?;
        
        for current_id in 0..=entry_id {
            if current_id == entry_id {
                return self.read_entry_at_offset(&mut file, offset).await;
            }
            
            // Read entry header to get size
            let entry_header_bytes = bincode::serialized_size(&EntryHeader {
                size: 0,
                checksum: 0,
                timestamp: Utc::now(),
            })?;
            
            let mut header_bytes = vec![0u8; entry_header_bytes as usize];
            file.read_exact(&mut header_bytes).await?;
            
            let entry_header: EntryHeader = bincode::deserialize(&header_bytes)?;
            
            // Skip to next entry
            offset += entry_header_bytes + entry_header.size as u64;
            file.seek(SeekFrom::Start(offset)).await?;
        }
        
        Err(Error::EntryNotFound("".to_string(), entry_id))
    }
    
    /// Read entry at specific file offset
    async fn read_entry_at_offset(&self, file: &mut File, offset: u64) -> Result<LogEntry> {
        file.seek(SeekFrom::Start(offset)).await?;
        
        // Read entry header
        let entry_header_bytes = bincode::serialized_size(&EntryHeader {
            size: 0,
            checksum: 0,
            timestamp: Utc::now(),
        })?;
        
        let mut header_bytes = vec![0u8; entry_header_bytes as usize];
        file.read_exact(&mut header_bytes).await?;
        
        let entry_header: EntryHeader = bincode::deserialize(&header_bytes)?;
        
        // Read entry data
        let mut entry_bytes = vec![0u8; entry_header.size as usize];
        file.read_exact(&mut entry_bytes).await?;
        
        // Verify checksum
        let checksum = crc32fast::hash(&entry_bytes);
        if checksum != entry_header.checksum {
            return Err(Error::Corruption(format!(
                "Entry checksum mismatch: expected {}, got {}",
                entry_header.checksum, checksum
            )));
        }
        
        // Deserialize entry
        let entry: LogEntry = bincode::deserialize(&entry_bytes)?;
        Ok(entry)
    }
    
    /// Seal the block (make it read-only)
    pub async fn seal(&self) -> Result<()> {
        let checksum = self.calculate_checksum().await?;
        
        {
            let mut metadata = self.metadata.lock().await;
            
            if metadata.status != BlockStatus::Active {
                return Err(Error::Storage("Block is not active".to_string()));
            }
            
            // Update metadata
            metadata.status = BlockStatus::Sealed;
            metadata.sealed_at = Some(Utc::now());
            metadata.checksum = checksum;
        }
        
        // Close file handle
        *self.file.lock().await = None;
        
        // Write final header
        self.write_header_to_file().await?;
        
        Ok(())
    }
    
    /// Write header to file (for sealed blocks)
    async fn write_header_to_file(&self) -> Result<()> {
        let mut file = OpenOptions::new()
            .write(true)
            .open(&self.path)
            .await?;
        
        let metadata = {
            let metadata_guard = self.metadata.lock().await;
            metadata_guard.clone()
        };
        
        let mut header = BlockHeader::new(metadata);
        
        // Calculate header size
        let header_size = bincode::serialized_size(&header)?;
        header.data_offset = header_size;
        
        // Write header
        file.seek(SeekFrom::Start(0)).await?;
        let header_bytes = bincode::serialize(&header)?;
        file.write_all(&header_bytes).await?;
        file.flush().await?;
        
        Ok(())
    }
    
    /// Calculate checksum of the entire block data
    async fn calculate_checksum(&self) -> Result<u32> {
        let mut file = OpenOptions::new()
            .read(true)
            .open(&self.path)
            .await?;
        
        let header = Self::read_header(&mut file).await?;
        
        // Read all data after header
        file.seek(SeekFrom::Start(header.data_offset)).await?;
        let mut data = Vec::new();
        file.read_to_end(&mut data).await?;
        
        Ok(crc32fast::hash(&data))
    }
    
    /// Get block metadata
    pub async fn metadata(&self) -> BlockMetadata {
        let metadata_guard = self.metadata.lock().await;
        metadata_guard.clone()
    }
    
    /// Get block path
    pub fn path(&self) -> &Path {
        &self.path
    }
    
    /// Check if block should be rotated based on policy
    pub async fn should_rotate(&self, policy: &crate::BlockRotationPolicy) -> bool {
        let metadata = self.metadata.lock().await;
        
        match policy {
            crate::BlockRotationPolicy::Time(duration) => {
                let age = Utc::now().signed_duration_since(metadata.created_at);
                age.to_std().map_or(false, |age| age >= *duration)
            }
            crate::BlockRotationPolicy::Size(max_size) => {
                metadata.uncompressed_size >= *max_size
            }
            crate::BlockRotationPolicy::Count(max_count) => {
                metadata.entry_count >= *max_count
            }
        }
    }
    
    /// Flush pending writes
    pub async fn flush(&self) -> Result<()> {
        let mut file_guard = self.file.lock().await;
        if let Some(ref mut file) = *file_guard {
            file.flush().await?;
        }
        Ok(())
    }
}
$$--GLUE--$$
.\storage\compression.rs
$$--GLUE--$$
use crate::{CompressionAlgorithm, Error, Result};
use std::io::{Read, Write};

/// Maximum uncompressed data size to prevent memory exhaustion (256MB)
const MAX_UNCOMPRESSED_SIZE: usize = 256 * 1024 * 1024;

/// Maximum compressed data size to prevent memory exhaustion (512MB)
const MAX_COMPRESSED_SIZE: usize = 512 * 1024 * 1024;

/// Compress data using the specified algorithm
pub fn compress(data: &[u8], algorithm: CompressionAlgorithm, level: i32) -> Result<Vec<u8>> {
    // Validate input size
    if data.len() > MAX_UNCOMPRESSED_SIZE {
        return Err(Error::ResourceLimit(format!(
            "Data too large for compression: {} bytes (max: {})",
            data.len(),
            MAX_UNCOMPRESSED_SIZE
        )));
    }
    
    if data.is_empty() {
        return Ok(Vec::new());
    }
    
    match algorithm {
        CompressionAlgorithm::None => Ok(data.to_vec()),
        CompressionAlgorithm::Lz4 => compress_lz4(data),
        #[cfg(feature = "compression")]
        CompressionAlgorithm::Zstd => compress_zstd(data, level),
    }
}

/// Decompress data using the specified algorithm
pub fn decompress(data: &[u8], algorithm: CompressionAlgorithm) -> Result<Vec<u8>> {
    // Validate input size
    if data.len() > MAX_COMPRESSED_SIZE {
        return Err(Error::ResourceLimit(format!(
            "Compressed data too large: {} bytes (max: {})",
            data.len(),
            MAX_COMPRESSED_SIZE
        )));
    }
    
    if data.is_empty() {
        return Ok(Vec::new());
    }
    
    match algorithm {
        CompressionAlgorithm::None => Ok(data.to_vec()),
        CompressionAlgorithm::Lz4 => decompress_lz4(data),
        #[cfg(feature = "compression")]
        CompressionAlgorithm::Zstd => decompress_zstd(data),
    }
}

/// Compress using LZ4
fn compress_lz4(data: &[u8]) -> Result<Vec<u8>> {
    Ok(lz4_flex::compress_prepend_size(data))
}

/// Decompress using LZ4
fn decompress_lz4(data: &[u8]) -> Result<Vec<u8>> {
    lz4_flex::decompress_size_prepended(data)
        .map_err(|e| Error::Compression(format!("LZ4 decompression failed: {}", e)))
}

/// Compress using Zstd
#[cfg(feature = "compression")]
fn compress_zstd(data: &[u8], level: i32) -> Result<Vec<u8>> {
    // Clamp level to valid range
    let level = level.clamp(1, 22);
    
    zstd::bulk::compress(data, level)
        .map_err(|e| Error::Compression(format!("Zstd compression failed: {}", e)))
}

/// Decompress using Zstd
#[cfg(feature = "compression")]
fn decompress_zstd(data: &[u8]) -> Result<Vec<u8>> {
    zstd::bulk::decompress(data, MAX_UNCOMPRESSED_SIZE)
        .map_err(|e| Error::Compression(format!("Zstd decompression failed: {}", e)))
}

/// Calculate compression ratio (original_size / compressed_size)
pub fn compression_ratio(original_size: usize, compressed_size: usize) -> f64 {
    if compressed_size == 0 {
        return 0.0;
    }
    
    original_size as f64 / compressed_size as f64
}

/// Estimate compressed size for a given algorithm (rough estimate)
pub fn estimate_compressed_size(data_size: usize, algorithm: CompressionAlgorithm) -> usize {
    match algorithm {
        CompressionAlgorithm::None => data_size,
        CompressionAlgorithm::Lz4 => (data_size as f64 * 0.7) as usize, // ~30% compression
        #[cfg(feature = "compression")]
        CompressionAlgorithm::Zstd => (data_size as f64 * 0.5) as usize, // ~50% compression
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    
    #[test]
    fn test_no_compression() {
        let data = b"Hello, World!";
        let compressed = compress(data, CompressionAlgorithm::None, 0).unwrap();
        let decompressed = decompress(&compressed, CompressionAlgorithm::None).unwrap();
        
        assert_eq!(data, compressed.as_slice());
        assert_eq!(data, decompressed.as_slice());
    }
    
    #[test]
    fn test_lz4_compression() {
        let data = b"Hello, World! This is a test string that should compress well with LZ4.".repeat(100);
        let compressed = compress(&data, CompressionAlgorithm::Lz4, 0).unwrap();
        let decompressed = decompress(&compressed, CompressionAlgorithm::Lz4).unwrap();
        
        assert_eq!(data, decompressed);
        assert!(compressed.len() < data.len());
        
        let ratio = compression_ratio(data.len(), compressed.len());
        assert!(ratio > 1.0);
    }
    
    #[cfg(feature = "compression")]
    #[test]
    fn test_zstd_compression() {
        let data = b"Hello, World! This is a test string that should compress well with Zstd.".repeat(100);
        let compressed = compress(&data, CompressionAlgorithm::Zstd, 3).unwrap();
        let decompressed = decompress(&compressed, CompressionAlgorithm::Zstd).unwrap();
        
        assert_eq!(data, decompressed);
        assert!(compressed.len() < data.len());
        
        let ratio = compression_ratio(data.len(), compressed.len());
        assert!(ratio > 1.0);
    }
    
    #[test]
    fn test_empty_data() {
        let data = b"";
        
        for algorithm in [CompressionAlgorithm::None, CompressionAlgorithm::Lz4] {
            let compressed = compress(data, algorithm, 0).unwrap();
            let decompressed = decompress(&compressed, algorithm).unwrap();
            
            assert_eq!(data, decompressed.as_slice());
        }
    }
    
    #[test]
    fn test_size_limits() {
        // Create data that exceeds the limit
        let large_data = vec![0u8; MAX_UNCOMPRESSED_SIZE + 1];
        
        let result = compress(&large_data, CompressionAlgorithm::Lz4, 0);
        assert!(result.is_err());
        assert!(result.unwrap_err().to_string().contains("Data too large"));
    }
}
$$--GLUE--$$
.\storage\log_entry.rs
$$--GLUE--$$
use chrono::{DateTime, Utc};
use serde::{Deserialize, Serialize};
use std::collections::HashMap;

/// A single log entry
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
pub struct LogEntry {
    /// Timestamp when the log entry was created
    pub timestamp: DateTime<Utc>,
    
    /// Source identifier (e.g., service name, component)
    pub source: String,
    
    /// Log message content
    pub message: String,
    
    /// Key-value tags for metadata
    pub tags: HashMap<String, String>,
    
    /// Internal entry ID (set when stored)
    #[serde(skip_serializing_if = "Option::is_none")]
    pub entry_id: Option<u64>,
}

impl LogEntry {
    /// Create a new log entry with current timestamp
    pub fn new(source: impl Into<String>, message: impl Into<String>, tags: HashMap<String, String>) -> Self {
        LogEntry {
            timestamp: Utc::now(),
            source: source.into(),
            message: message.into(),
            tags,
            entry_id: None,
        }
    }
    
    /// Create a new log entry with specified timestamp
    pub fn with_timestamp(
        timestamp: DateTime<Utc>,
        source: impl Into<String>,
        message: impl Into<String>,
        tags: HashMap<String, String>,
    ) -> Self {
        LogEntry {
            timestamp,
            source: source.into(),
            message: message.into(),
            tags,
            entry_id: None,
        }
    }
    
    /// Create a builder for constructing log entries
    pub fn builder() -> LogEntryBuilder {
        LogEntryBuilder::new()
    }
    
    /// Get a tag value by key
    pub fn get_tag(&self, key: &str) -> Option<&String> {
        self.tags.get(key)
    }
    
    /// Check if entry has a specific tag
    pub fn has_tag(&self, key: &str) -> bool {
        self.tags.contains_key(key)
    }
    
    /// Check if entry has a tag with specific value
    pub fn has_tag_value(&self, key: &str, value: &str) -> bool {
        self.tags.get(key).map_or(false, |v| v == value)
    }
    
    /// Set the entry ID (internal use)
    pub(crate) fn set_entry_id(&mut self, id: u64) {
        self.entry_id = Some(id);
    }
    
    /// Validate the log entry
    pub fn validate(&self) -> Result<(), String> {
        if self.source.is_empty() {
            return Err("Source cannot be empty".to_string());
        }
        
        if self.message.is_empty() {
            return Err("Message cannot be empty".to_string());
        }
        
        // Check for reasonable size limits
        if self.source.len() > 1024 {
            return Err("Source is too long (max 1024 characters)".to_string());
        }
        
        if self.message.len() > 1024 * 1024 {
            return Err("Message is too long (max 1MB)".to_string());
        }
        
        // Validate tags
        if self.tags.len() > 100 {
            return Err("Too many tags (max 100)".to_string());
        }
        
        for (key, value) in &self.tags {
            if key.is_empty() {
                return Err("Tag key cannot be empty".to_string());
            }
            
            if key.len() > 256 {
                return Err("Tag key is too long (max 256 characters)".to_string());
            }
            
            if value.len() > 1024 {
                return Err("Tag value is too long (max 1024 characters)".to_string());
            }
        }
        
        Ok(())
    }
}

/// Builder for constructing log entries
#[derive(Debug, Default)]
pub struct LogEntryBuilder {
    timestamp: Option<DateTime<Utc>>,
    source: Option<String>,
    message: Option<String>,
    tags: HashMap<String, String>,
}

impl LogEntryBuilder {
    /// Create a new builder
    pub fn new() -> Self {
        Self::default()
    }
    
    /// Set the timestamp
    pub fn timestamp(mut self, timestamp: DateTime<Utc>) -> Self {
        self.timestamp = Some(timestamp);
        self
    }
    
    /// Set the source
    pub fn source(mut self, source: impl Into<String>) -> Self {
        self.source = Some(source.into());
        self
    }
    
    /// Set the message
    pub fn message(mut self, message: impl Into<String>) -> Self {
        self.message = Some(message.into());
        self
    }
    
    /// Add a tag
    pub fn tag(mut self, key: impl Into<String>, value: impl Into<String>) -> Self {
        self.tags.insert(key.into(), value.into());
        self
    }
    
    /// Add multiple tags
    pub fn tags(mut self, tags: HashMap<String, String>) -> Self {
        self.tags.extend(tags);
        self
    }
    
    /// Build the log entry
    pub fn build(self) -> Result<LogEntry, String> {
        let source = self.source.ok_or("Source is required")?;
        let message = self.message.ok_or("Message is required")?;
        let timestamp = self.timestamp.unwrap_or_else(Utc::now);
        
        let entry = LogEntry {
            timestamp,
            source,
            message,
            tags: self.tags,
            entry_id: None,
        };
        
        entry.validate()?;
        Ok(entry)
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use chrono::TimeZone;
    
    #[test]
    fn test_new_log_entry() {
        let mut tags = HashMap::new();
        tags.insert("level".to_string(), "info".to_string());
        
        let entry = LogEntry::new("test-service", "Test message", tags.clone());
        
        assert_eq!(entry.source, "test-service");
        assert_eq!(entry.message, "Test message");
        assert_eq!(entry.tags, tags);
        assert!(entry.entry_id.is_none());
    }
    
    #[test]
    fn test_builder() {
        let timestamp = Utc.with_ymd_and_hms(2023, 1, 1, 12, 0, 0).unwrap();
        
        let entry = LogEntry::builder()
            .timestamp(timestamp)
            .source("test-service")
            .message("Test message")
            .tag("level", "info")
            .tag("component", "auth")
            .build()
            .unwrap();
        
        assert_eq!(entry.timestamp, timestamp);
        assert_eq!(entry.source, "test-service");
        assert_eq!(entry.message, "Test message");
        assert_eq!(entry.get_tag("level"), Some(&"info".to_string()));
        assert_eq!(entry.get_tag("component"), Some(&"auth".to_string()));
    }
    
    #[test]
    fn test_validation() {
        // Valid entry
        let entry = LogEntry::new("service", "message", HashMap::new());
        assert!(entry.validate().is_ok());
        
        // Empty source
        let mut entry = LogEntry::new("", "message", HashMap::new());
        assert!(entry.validate().is_err());
        
        // Empty message
        entry = LogEntry::new("service", "", HashMap::new());
        assert!(entry.validate().is_err());
        
        // Too many tags
        let mut tags = HashMap::new();
        for i in 0..101 {
            tags.insert(format!("key{}", i), "value".to_string());
        }
        entry = LogEntry::new("service", "message", tags);
        assert!(entry.validate().is_err());
    }
}
$$--GLUE--$$
.\storage\mod.rs
$$--GLUE--$$
use crate::{Config, Error, Result, StorageConfig};
use tokio::sync::RwLock;
use std::collections::HashMap;
use std::sync::Arc;
use uuid::Uuid;

mod block;
mod partition;
mod compression;
mod log_entry;

pub use block::Block;
pub use partition::{Partition, PartitionInfo};
pub use log_entry::LogEntry;

/// Main storage engine
pub struct Storage {
    pub config: Config,
    pub partitions: Arc<RwLock<HashMap<String, Arc<Partition>>>>, // Wrapped in Arc
    pub background_handle: Option<tokio::task::JoinHandle<()>>,
    pub shutdown_signal: Arc<tokio::sync::Notify>,
}

impl Storage {
    /// Create a new storage instance
    pub async fn new(config: Config) -> Result<Self> {
        // Create data directory
        tokio::fs::create_dir_all(&config.data_dir).await?;
        
        let shutdown_signal = Arc::new(tokio::sync::Notify::new());
        
        let mut storage = Storage {
            config,
            partitions: Arc::new(RwLock::new(HashMap::new())), // Wrap in Arc
            background_handle: None,
            shutdown_signal,
        };
        
        // Load existing partitions
        storage.load_partitions().await?;
        
        // Start background tasks
        storage.start_background_tasks().await;
        
        Ok(storage)
    }
    
    /// Load existing partitions from disk
    async fn load_partitions(&self) -> Result<()> {
        let mut entries = tokio::fs::read_dir(&self.config.data_dir).await?;
        
        while let Some(entry) = entries.next_entry().await? {
            let path = entry.path();
            
            if path.is_dir() {
                if let Some(name) = path.file_name().and_then(|n| n.to_str()) {
                    // Skip special directories
                    if name.starts_with('.') {
                        continue;
                    }
                    
                    // Try to load partition
                    let path_clone = path.clone();
                    match Partition::load(path_clone, self.config.storage.clone()).await {
                        Ok(partition) => {
                            let partition_id = partition.id().to_string();
                            self.partitions.write().await.insert(partition_id, Arc::new(partition));
                            log::info!("Loaded partition: {}", name);
                        }
                        Err(e) => {
                            log::warn!("Failed to load partition {}: {}", name, e);
                        }
                    }
                }
            }
        }
        
        Ok(())
    }
    
    /// Start background maintenance tasks
    async fn start_background_tasks(&mut self) {
        let config = self.config.clone();
        let partitions = Arc::clone(&self.partitions); // Clone the Arc, not the RwLock
        let shutdown_signal = self.shutdown_signal.clone();
        
        let handle = tokio::spawn(async move {
            let mut interval = tokio::time::interval(config.storage.flush_interval);
            
            loop {
                tokio::select! {
                    _ = interval.tick() => {
                        // Flush all partitions
                        let partition_list = {
                            partitions.read().await.values().cloned().collect::<Vec<_>>()
                        };
                        
                        for partition in partition_list {
                            if let Err(e) = partition.flush().await {
                                log::error!("Failed to flush partition {}: {}", partition.id(), e);
                            }
                        }
                        
                        // Run maintenance tasks
                        Self::run_maintenance(&partitions, &config.storage).await;
                    }
                    _ = shutdown_signal.notified() => {
                        log::info!("Background task shutting down");
                        break;
                    }
                }
            }
        });
        
        self.background_handle = Some(handle);
    }
    
    /// Run maintenance tasks
    async fn run_maintenance(
        partitions: &Arc<RwLock<HashMap<String, Arc<Partition>>>>, // Updated parameter type
        config: &StorageConfig,
    ) {
        let partition_list = {
            partitions.read().await.values().cloned().collect::<Vec<_>>()
        };
        
        for partition in partition_list {
            // Rotate blocks if needed
            if let Err(e) = partition.check_rotation().await {
                log::error!("Failed to check rotation for partition {}: {}", partition.id(), e);
            }
            
            // Apply retention policy
            if config.retention_days > 0 {
                if let Err(e) = partition.apply_retention(config.retention_days).await {
                    log::error!("Failed to apply retention for partition {}: {}", partition.id(), e);
                }
            }
        }
    }
    
    /// Create a new partition
    pub async fn create_partition(&self, name: &str) -> Result<String> {
        let partition_id = Uuid::new_v4().to_string();
        let partition_dir = self.config.data_dir.join(&partition_id);
        
        let partition = Partition::create(
            partition_id.clone(),
            name.to_string(),
            partition_dir,
            self.config.storage.clone(),
        ).await?;
        
        self.partitions.write().await.insert(partition_id.clone(), Arc::new(partition));
        
        log::info!("Created partition: {} ({})", name, partition_id);
        Ok(partition_id)
    }
    
    /// List all partitions
    pub async fn list_partitions(&self) -> Result<Vec<PartitionInfo>> {
        let partitions = self.partitions.read().await;
        let mut infos = Vec::new();
        
        for partition in partitions.values() {
            infos.push(partition.info().await?);
        }
        
        Ok(infos)
    }
    
    /// Get partition information
    pub async fn get_partition(&self, id: &str) -> Result<PartitionInfo> {
        let partitions = self.partitions.read().await;
        let partition = partitions
            .get(id)
            .ok_or_else(|| Error::PartitionNotFound(id.to_string()))?;
        
        partition.info().await
    }
    
    /// Append a log entry to a partition
    pub async fn append(&self, partition_id: &str, entry: LogEntry) -> Result<u64> {
        let partitions = self.partitions.read().await;
        let partition = partitions
            .get(partition_id)
            .ok_or_else(|| Error::PartitionNotFound(partition_id.to_string()))?;
        
        partition.append(entry).await
    }
    
    /// Get a specific log entry
    pub async fn get_entry(&self, partition_id: &str, entry_id: u64) -> Result<LogEntry> {
        let partitions = self.partitions.read().await;
        let partition = partitions
            .get(partition_id)
            .ok_or_else(|| Error::PartitionNotFound(partition_id.to_string()))?;
        
        partition.get_entry(entry_id).await
    }
    
    /// Flush all pending writes
    pub async fn flush(&self) -> Result<()> {
        let partitions = self.partitions.read().await;
        
        for partition in partitions.values() {
            partition.flush().await?;
        }
        
        Ok(())
    }
    
    /// Close the storage engine
    pub async fn close(mut self) -> Result<()> {
        // Signal shutdown
        self.shutdown_signal.notify_one();
        
        // Wait for background tasks to finish
        if let Some(handle) = self.background_handle.take() {
            let _ = handle.await;
        }
        
        // Flush all partitions
        self.flush().await?;
        
        log::info!("Storage engine closed");
        Ok(())
    }
    
    /// Get partition for queries (now async)
    pub async fn get_partition_for_query(&self, id: &str) -> Option<Arc<Partition>> {
        let partitions = self.partitions.read().await;
        partitions.get(id).cloned()
    }
    
    /// Get all partitions for queries (now async)
    pub async fn get_all_partitions_for_query(&self) -> Vec<Arc<Partition>> {
        let partitions = self.partitions.read().await;
        partitions.values().cloned().collect()
    }
}
$$--GLUE--$$
.\storage\partition.rs
$$--GLUE--$$
use crate::{Error, Result, StorageConfig};
use super::{Block, LogEntry};
use chrono::{DateTime, Utc};
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use std::path::PathBuf;
use std::sync::Arc;
use tokio::fs::{self, File};
use tokio::io::{AsyncReadExt, AsyncWriteExt};
use tokio::sync::RwLock;
use uuid::Uuid;

/// Partition metadata stored in partition.meta file
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct PartitionMetadata {
    /// Unique partition identifier
    pub id: String,
    /// Human-readable partition name
    pub name: String,
    /// Partition creation timestamp
    pub created_at: DateTime<Utc>,
    /// Last modification timestamp
    pub modified_at: DateTime<Utc>,
    /// List of block IDs in chronological order
    pub block_ids: Vec<String>,
    /// Currently active block ID
    pub active_block_id: Option<String>,
    /// Total number of entries across all blocks
    pub total_entries: u64,
    /// Total uncompressed size in bytes
    pub total_size: u64,
    /// Version of the partition format
    pub version: u32,
}

/// Partition information for API responses
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct PartitionInfo {
    pub id: String,
    pub name: String,
    pub created_at: DateTime<Utc>,
    pub modified_at: DateTime<Utc>,
    pub total_entries: u64,
    pub total_size: u64,
    pub block_count: usize,
    pub active_block_id: Option<String>,
}

/// A partition contains multiple blocks and manages log entry storage
pub struct Partition {
    metadata: RwLock<PartitionMetadata>,
    path: PathBuf,
    config: StorageConfig,
    /// Currently active block for writing
    active_block: RwLock<Option<Arc<Block>>>,
    /// Cache of sealed blocks for reading
    sealed_blocks: RwLock<HashMap<String, Arc<Block>>>,
    /// Entry ID counter (spans across all blocks in partition)
    next_entry_id: RwLock<u64>,
    /// Mapping from global entry ID to (block_id, local_entry_id)
    entry_mapping: RwLock<HashMap<u64, (String, u64)>>,
}

impl Partition {
    /// Create a new partition
    pub async fn create(
        id: String,
        name: String,
        path: PathBuf,
        config: StorageConfig,
    ) -> Result<Self> {
        // Create partition directory
        fs::create_dir_all(&path).await?;
        
        let metadata = PartitionMetadata {
            id: id.clone(),
            name,
            created_at: Utc::now(),
            modified_at: Utc::now(),
            block_ids: Vec::new(),
            active_block_id: None,
            total_entries: 0,
            total_size: 0,
            version: 1,
        };
        
        let partition = Partition {
            metadata: RwLock::new(metadata),
            path,
            config,
            active_block: RwLock::new(None),
            sealed_blocks: RwLock::new(HashMap::new()),
            next_entry_id: RwLock::new(0),
            entry_mapping: RwLock::new(HashMap::new()),
        };
        
        // Save metadata
        partition.save_metadata().await?;
        
        Ok(partition)
    }
    
    /// Load an existing partition
    pub async fn load(path: PathBuf, config: StorageConfig) -> Result<Self> {
        // Load metadata
        let metadata_path = path.join("partition.meta");
        let metadata = Self::load_metadata(&metadata_path).await?;
        
        let partition = Partition {
            metadata: RwLock::new(metadata.clone()),
            path,
            config,
            active_block: RwLock::new(None),
            sealed_blocks: RwLock::new(HashMap::new()),
            next_entry_id: RwLock::new(metadata.total_entries),
            entry_mapping: RwLock::new(HashMap::new()),
        };
        
        // Load active block if exists
        if let Some(active_block_id) = &metadata.active_block_id {
            partition.load_active_block(active_block_id).await?;
        }
        
        // Build entry mapping
        partition.build_entry_mapping().await?;
        
        Ok(partition)
    }
    
    /// Load metadata from file
    async fn load_metadata(path: &PathBuf) -> Result<PartitionMetadata> {
        let mut file = File::open(path).await?;
        let mut contents = Vec::new();
        file.read_to_end(&mut contents).await?;
        
        let metadata: PartitionMetadata = bincode::deserialize(&contents)?;
        Ok(metadata)
    }
    
    /// Save metadata to file
    async fn save_metadata(&self) -> Result<()> {
        let metadata = {
            let metadata_guard = self.metadata.read().await;
            metadata_guard.clone()
        };
        
        let metadata_path = self.path.join("partition.meta");
        
        let contents = bincode::serialize(&metadata)?;
        let mut file = File::create(&metadata_path).await?;
        file.write_all(&contents).await?;
        file.flush().await?;
        
        Ok(())
    }
    
    /// Load the active block
    async fn load_active_block(&self, block_id: &str) -> Result<()> {
        let block_path = self.path.join(format!("{}.block", block_id));
        
        if block_path.exists() {
            let block = Block::open(block_path, self.config.clone()).await?;
            
            // Only load if it's actually active
            let block_metadata = block.metadata().await;
            if block_metadata.status == super::block::BlockStatus::Active {
                *self.active_block.write().await = Some(Arc::new(block));
            }
        }
        
        Ok(())
    }
    
    /// Build the entry mapping from global IDs to block locations
    async fn build_entry_mapping(&self) -> Result<()> {
        let mut mapping = HashMap::new();
        let mut global_entry_id = 0u64;
        
        let metadata = {
            let metadata_guard = self.metadata.read().await;
            metadata_guard.clone()
        };
        
        for block_id in &metadata.block_ids {
            let block_path = self.path.join(format!("{}.block", block_id));
            
            if block_path.exists() {
                let block = Block::open(block_path, self.config.clone()).await?;
                let block_metadata = block.metadata().await;
                
                // Map each entry in this block
                for local_entry_id in 0..block_metadata.entry_count {
                    mapping.insert(global_entry_id, (block_id.clone(), local_entry_id));
                    global_entry_id += 1;
                }
            }
        }
        
        *self.entry_mapping.write().await = mapping;
        *self.next_entry_id.write().await = global_entry_id;
        
        Ok(())
    }
    
    /// Get or create the active block
    async fn get_or_create_active_block(&self) -> Result<Arc<Block>> {
        // Check if we have an active block
        {
            let active_block = self.active_block.read().await;
            if let Some(ref block) = *active_block {
                // Check if block needs rotation
                let should_rotate = block.should_rotate(&self.config.block_rotation).await;
                if !should_rotate {
                    return Ok(block.clone());
                }
            }
        }
        
        // Need to create a new block or rotate existing one
        self.rotate_block().await
    }
    
    /// Rotate to a new active block
    async fn rotate_block(&self) -> Result<Arc<Block>> {
        // Seal current active block if exists
        {
            let mut active_block = self.active_block.write().await;
            if let Some(ref block) = *active_block {
                block.seal().await?;
                
                // Move to sealed blocks cache
                let block_metadata = block.metadata().await;
                self.sealed_blocks.write().await.insert(block_metadata.id.clone(), block.clone());
            }
            *active_block = None;
        }
        
        // Create new active block
        let block_id = Uuid::new_v4().to_string();
        let block_path = self.path.join(format!("{}.block", block_id));
        
        let block = Block::create(block_id.clone(), block_path, self.config.clone()).await?;
        let block_arc = Arc::new(block);
        
        // Update metadata
        {
            let mut metadata = self.metadata.write().await;
            metadata.block_ids.push(block_id.clone());
            metadata.active_block_id = Some(block_id.clone());
            metadata.modified_at = Utc::now();
        }
        
        // Save metadata
        self.save_metadata().await?;
        
        // Set as active block
        *self.active_block.write().await = Some(block_arc.clone());
        
        log::info!("Rotated to new block: {}", block_id);
        
        Ok(block_arc)
    }
    
    /// Append a log entry to the partition
    pub async fn append(&self, entry: LogEntry) -> Result<u64> {
        // Get or create active block
        let block = self.get_or_create_active_block().await?;
        
        // Append to block
        let local_entry_id = block.append(entry).await?;
        
        // Generate global entry ID
        let global_entry_id = {
            let mut next_id = self.next_entry_id.write().await;
            let id = *next_id;
            *next_id += 1;
            id
        };
        
        // Update entry mapping
        {
            let block_metadata = block.metadata().await;
            self.entry_mapping.write().await.insert(
                global_entry_id,
                (block_metadata.id, local_entry_id),
            );
        }
        
        // Update partition metadata
        {
            let mut metadata = self.metadata.write().await;
            metadata.total_entries += 1;
            let block_metadata = block.metadata().await;
            metadata.total_size = block_metadata.uncompressed_size;
            metadata.modified_at = Utc::now();
        }
        
        Ok(global_entry_id)
    }
    
    /// Get a log entry by global ID
    pub async fn get_entry(&self, entry_id: u64) -> Result<LogEntry> {
        // Find the block containing this entry
        let (block_id, local_entry_id) = {
            let mapping = self.entry_mapping.read().await;
            mapping
                .get(&entry_id)
                .cloned()
                .ok_or_else(|| Error::EntryNotFound(self.id().to_string(), entry_id))?
        };
        
        // Try active block first
        {
            let active_block = self.active_block.read().await;
            if let Some(ref block) = *active_block {
                let block_metadata = block.metadata().await;
                if block_metadata.id == block_id {
                    return block.read_entry(local_entry_id).await;
                }
            }
        }
        
        // Try sealed blocks cache
        {
            let sealed_blocks = self.sealed_blocks.read().await;
            if let Some(block) = sealed_blocks.get(&block_id) {
                return block.read_entry(local_entry_id).await;
            }
        }
        
        // Load block from disk
        let block_path = self.path.join(format!("{}.block", block_id));
        let block = Block::open(block_path, self.config.clone()).await?;
        let entry = block.read_entry(local_entry_id).await?;
        
        // Cache the block
        self.sealed_blocks.write().await.insert(block_id, Arc::new(block));
        
        Ok(entry)
    }
    
    /// Get entries in a time range
    pub async fn get_entries_in_range(
        &self,
        start: DateTime<Utc>,
        end: DateTime<Utc>,
        limit: Option<usize>,
    ) -> Result<Vec<LogEntry>> {
        let mut results = Vec::new();
        let metadata = {
            let metadata_guard = self.metadata.read().await;
            metadata_guard.clone()
        };
        
        // Search through blocks in reverse chronological order (newest first)
        for block_id in metadata.block_ids.iter().rev() {
            if let Some(limit) = limit {
                if results.len() >= limit {
                    break;
                }
            }
            
            // Load block
            let block = {
                let active_block = self.active_block.read().await;
                if let Some(ref active) = *active_block {
                    let active_metadata = active.metadata().await;
                    if active_metadata.id == *block_id {
                        active.clone()
                    } else {
                        self.load_block_for_search(block_id).await?
                    }
                } else {
                    self.load_block_for_search(block_id).await?
                }
            };
            
            // Search entries in this block
            let block_metadata = block.metadata().await;
            for local_entry_id in (0..block_metadata.entry_count).rev() {
                if let Some(limit) = limit {
                    if results.len() >= limit {
                        break;
                    }
                }
                
                match block.read_entry(local_entry_id).await {
                    Ok(entry) => {
                        if entry.timestamp >= start && entry.timestamp <= end {
                            results.push(entry);
                        } else if entry.timestamp < start {
                            // Since we're going in reverse chronological order,
                            // we can stop searching this block
                            break;
                        }
                    }
                    Err(_) => continue, // Skip corrupted entries
                }
            }
        }
        
        // Sort results by timestamp (newest first)
        results.sort_by(|a, b| b.timestamp.cmp(&a.timestamp));
        
        Ok(results)
    }
    
    /// Load a block for searching
    async fn load_block_for_search(&self, block_id: &str) -> Result<Arc<Block>> {
        // Check sealed blocks cache first
        {
            let sealed_blocks = self.sealed_blocks.read().await;
            if let Some(block) = sealed_blocks.get(block_id) {
                return Ok(block.clone());
            }
        }
        
        // Load from disk
        let block_path = self.path.join(format!("{}.block", block_id));
        let block = Block::open(block_path, self.config.clone()).await?;
        let block_arc = Arc::new(block);
        
        // Cache it
        self.sealed_blocks.write().await.insert(block_id.to_string(), block_arc.clone());
        
        Ok(block_arc)
    }
    
    /// Get partition info
    pub async fn info(&self) -> Result<PartitionInfo> {
        let metadata = {
            let metadata_guard = self.metadata.read().await;
            metadata_guard.clone()
        };
        
        Ok(PartitionInfo {
            id: metadata.id.clone(),
            name: metadata.name.clone(),
            created_at: metadata.created_at,
            modified_at: metadata.modified_at,
            total_entries: metadata.total_entries,
            total_size: metadata.total_size,
            block_count: metadata.block_ids.len(),
            active_block_id: metadata.active_block_id.clone(),
        })
    }
    
    /// Get partition ID
    pub fn id(&self) -> String {
        // We need to make this synchronous, so we'll use try_read
        // If it fails, we'll return a placeholder
        self.metadata.try_read()
            .map(|m| m.id.clone())
            .unwrap_or_else(|_| "unknown".to_string())
    }
    
    /// Check if active block needs rotation
    pub async fn check_rotation(&self) -> Result<()> {
        let active_block = self.active_block.read().await;
        if let Some(ref block) = *active_block {
            let should_rotate = block.should_rotate(&self.config.block_rotation).await;
            if should_rotate {
                drop(active_block);
                self.rotate_block().await?;
            }
        }
        Ok(())
    }
    
    /// Apply retention policy
    pub async fn apply_retention(&self, retention_days: u32) -> Result<()> {
        let cutoff = Utc::now() - chrono::Duration::days(retention_days as i64);
        let mut blocks_to_remove = Vec::new();
        
        let metadata = {
            let metadata_guard = self.metadata.read().await;
            metadata_guard.clone()
        };
        
        for block_id in &metadata.block_ids {
            // Skip active block
            if Some(block_id) == metadata.active_block_id.as_ref() {
                continue;
            }
            
            let block_path = self.path.join(format!("{}.block", block_id));
            if let Ok(block) = Block::open(block_path, self.config.clone()).await {
                let block_metadata = block.metadata().await;
                
                // Check if block is older than retention period
                if block_metadata.created_at < cutoff {
                    blocks_to_remove.push(block_id.clone());
                }
            }
        }
        
        // Remove old blocks
        for block_id in blocks_to_remove {
            self.remove_block(&block_id).await?;
        }
        
        Ok(())
    }
    
    /// Remove a block from the partition
    async fn remove_block(&self, block_id: &str) -> Result<()> {
        // Remove from sealed blocks cache
        self.sealed_blocks.write().await.remove(block_id);
        
        // Remove block file
        let block_path = self.path.join(format!("{}.block", block_id));
        if block_path.exists() {
            fs::remove_file(&block_path).await?;
        }
        
        // Update metadata
        {
            let mut metadata = self.metadata.write().await;
            metadata.block_ids.retain(|id| id != block_id);
            metadata.modified_at = Utc::now();
        }
        
        self.save_metadata().await?;
        
        // Rebuild entry mapping
        self.build_entry_mapping().await?;
        
        log::info!("Removed block: {}", block_id);
        
        Ok(())
    }
    
    /// Flush all pending writes
    pub async fn flush(&self) -> Result<()> {
        // Flush active block
        let active_block = self.active_block.read().await;
        if let Some(ref block) = *active_block {
            block.flush().await?;
        }
        drop(active_block);
        
        // Save metadata
        self.save_metadata().await?;
        
        Ok(())
    }
}